import collections
import copy

import torch
from torch import nn
from torch.nn import functional as F
import torch.utils.checkpoint as cp
import numpy as np
import math
from collections import defaultdict

from opencood.models.sub_modules.box_attention import Box3dAttention
from opencood.models.sub_modules.torch_transformation_utils import warp_affine_simple
from opencood.utils import box_utils
from opencood.pcdet_utils.roiaware_pool3d import roiaware_pool3d_utils
from scipy.optimize import linear_sum_assignment
from opencood.models.comm_modules.target_assigner.hungarian_assigner import HungarianMatcher3d, generalized_box3d_iou, \
    box_cxcyczlwh_to_xyxyxy
class MLP(nn.Module):
    """Very simple multi-layer perceptron (also called FFN)"""

    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):
        super().__init__()
        self.num_layers = num_layers # 3
        h = [hidden_dim] * (num_layers - 1) # [256, 256]
        self.layers = nn.ModuleList(nn.Linear(n, k) for n, k in zip([input_dim] + h, h + [output_dim]))

    def forward(self, x):
        for i, layer in enumerate(self.layers):
            x = F.relu(layer(x)) if i < self.num_layers - 1 else layer(x)
        return x
    
class FeatureMagnet(nn.Module):
    def __init__(self, d_model=256, nhead=8,  dim_feedforward=1024, dropout=0.1, activation="relu"):
        super().__init__()

        self.query_fusion = MLP(d_model*2, d_model, d_model, 3)

        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)
        self.linear1 = nn.Linear(d_model, dim_feedforward)
        self.linear2 = nn.Linear(dim_feedforward, d_model)
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)

        self.dropout = nn.Dropout(dropout)

        self.activation = get_activation_fn(activation)
    
    def forward(self, x, pos_1d, ego_idx=0, ref_windows=None):
        '''
        x: [(1, L1, C), (1, L2, C)...] egoå’Œå…¶ä»–agentçš„query, è¿™äº›queryå·²ç»è¢«CDAæ¨¡å—å¤„ç†è¿‡äº†
        pos_1d: [(1, L1, 1), (1, L2, 1)...] æ ‡è®°äº†åœ¨ç»Ÿä¸€åæ ‡ç³»ä¸‹æ¯ä¸ªå¯¹åº”queryçš„ä½ç½®, è¿™ä¸ªä½ç½®å…·æœ‰å”¯ä¸€æ€§ ä½†æ˜¯ç”±äºå…¶ä»–agentæ—‹è½¬åå–æ•´, å¯èƒ½é€ æˆ1dç¼–ç ç›¸åŒ
        ref_windows: [(1, L1, 7), (1, L2, 7)...]  # å‚è€ƒæ¡†, ç”¨æ¥BoxAttention
        '''
        B_N = x[0].shape[0]  # Batch size
        final_queries = []  # To hold final queries
        
        # Process each agent and the ego agent separately
        ego_queries = x[ego_idx] # (1, L1, C)
        ego_positions = pos_1d[ego_idx] # (1, L1, 1)
        
        # Collect all other agents' queries and positions
        other_agents_queries = x[:ego_idx] + x[ego_idx+1:]
        other_agents_positions = pos_1d[:ego_idx] + pos_1d[ego_idx+1:]
        
        # 1. For the ego agent, we want to collect the queries based on position matching
        ego_position_queries = {}  # Dictionary to hold queries by position
        for i in range(ego_queries.shape[1]): # éå†æ¯ä¸ªå‘é‡
            pos = ego_positions[0, i].item()  # Get the position (assuming batch_size=1 for simplicity)
            if pos not in ego_position_queries:
                ego_position_queries[pos] = []
            ego_position_queries[pos].append(ego_queries[:, i, :]) # poså’Œfeature æ˜¯å¯¹åº”çš„ï¼Œè¿™é‡Œç›´æ¥å°†(1,C)æ”¾å…¥
        
        # 2. For each other agent, we process its queries based on the positions
        for agent_queries, agent_positions in zip(other_agents_queries, other_agents_positions):
            agent_position_queries = {}  # Dictionary to hold queries by position
            for i in range(agent_queries.shape[1]):
                pos = agent_positions[0, i].item()  # Get the position
                if pos not in agent_position_queries:
                    agent_position_queries[pos] = []
                agent_position_queries[pos].append(agent_queries[:, i, :]) # åŒä¸€ä¸ªä½ç½®çš„æ”¾å…¥ä¸€ä¸ªåˆ—è¡¨é‡Œï¼Œæ³¨æ„è¿™é‡Œå¯èƒ½ç”±äºæ—‹è½¬é€ æˆä½ç½®é‡å 
            
            # 3. Fuse the agent's queries with the ego's queries at the same position
            for pos, agent_query_list in list(agent_position_queries.items()): # liståˆ›å»ºå‰¯æœ¬ 
                if pos in ego_position_queries: # å¦‚æœåœ¨egoä¸­ä¹Ÿæœ‰é‡å¤çš„ä½ç½® 
                    # Fuse the queries using MLP (aggregation of queries at the same position)
                    sum_tensor = sum(agent_query_list) # ä»¥é˜²æ‰­æ›²åçš„é‡å æŠ•å½±ï¼Œä½ç½®ç›¸åŒçš„å°±ç›´æ¥ç›¸åŠ åœ¨ä¸€èµ· TODO ç›´æ¥ç›¸åŠ æ˜¯å¦åˆç†ï¼Ÿå¦‚æœç”¨åæ ‡ç½‘æ ¼æ¥å®ç°TransIFFï¼Ÿ
                    ego_position_queries[pos] += [sum_tensor] # [(1,C), (1,C)]

                    agent_position_queries.pop(pos)

                    # agent_queries_fused = torch.cat(agent_query_list, dim=1)  # Concatenate queries for the same position
                    ego_queries_fused = torch.cat(ego_position_queries[pos], dim=1)  # Concatenate ego queries for the same position (1, C*2)
                    # Perform fusion
                    fused_queries = self.query_fusion(ego_queries_fused)  # MLP fusion (1, C)
                    # Update the ego's query with the fused result
                    ego_position_queries[pos] = [fused_queries]  # Update with the fused queries
                else: # å¦‚æœæ²¡æœ‰é‡å ä¹Ÿè¦ä¿è¯æ‰€æœ‰æŠ•å½±åçš„ä½ç½®å”¯ä¸€ï¼Œé‡å çš„queryå°±ç›¸åŠ åœ¨ä¸€èµ·
                    sum_tensor = sum(agent_query_list)
                    agent_position_queries[pos] = [sum_tensor]
        
        # Now combine the final queries for ego and other agents é‡æ–°æ¢å¤æˆ (1, l1, C)
        final_ego_queries = torch.cat([val[0] for val in ego_position_queries.values()], dim=0).unsqueeze(0)  # Concatenate all position-based fused queries
        final_queries.append(final_ego_queries)  # Add Ego's final queries

        agent_remain_queries = torch.cat([val[0] for val in agent_position_queries.values()], dim=0).unsqueeze(0) # (1, l2', C)
        final_queries.append(agent_remain_queries)  # Add Ego's final queries

        # Stack all the final queries together
        final_queries = torch.cat(final_queries, dim=1)  # Concatenate queries from ego and agents (1, l1+l2', C) è¿™ä¸ªä¹Ÿå°±æ˜¯paperä¸­æåˆ°çš„ optimal Q
        # print("final_queries shape is ", final_queries.shape)

        k = v =  torch.cat(x, dim=1) # åŸå§‹çš„ æ‰€æœ‰agent ç­›é€‰çš„query feature å…¨éƒ¨concat åœ¨ä¸€èµ·ï¼Œå½¢æˆ(1, l1+l2, C)
        # print("k shape is ", k.shape)

        outputs = self.self_attn(final_queries, k, v)[0]
        final_queries = final_queries + self.dropout(outputs)
        final_queries = self.norm1(final_queries)
        outputs = self.linear2(self.dropout(self.activation(self.linear1(final_queries))))
        final_queries = final_queries + self.dropout(outputs)
        final_queries = self.norm2(final_queries)

        return final_queries # (1, L, C) æœ€ç»ˆå°±æ˜¯è¾“å‡ºè¿™ä¸ªLä¸ªquery


class CrossDomainAdaption(nn.Module):
    def __init__(self, d_model=256, nhead=8,  dim_feedforward=1024, dropout=0.1, activation="relu"):
        super().__init__()
        self.self_attn_ego = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)
        self.self_attn_inf = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)
        self.ego_linear1 = nn.Linear(d_model, dim_feedforward)
        self.ego_linear2 = nn.Linear(dim_feedforward, d_model)
        self.ego_norm1 = nn.LayerNorm(d_model)
        self.ego_norm2 = nn.LayerNorm(d_model)

        self.inf_linear1 = nn.Linear(d_model, dim_feedforward)
        self.inf_linear2 = nn.Linear(dim_feedforward, d_model)
        self.inf_norm1 = nn.LayerNorm(d_model)
        self.inf_norm2 = nn.LayerNorm(d_model)

        self.dropout = nn.Dropout(dropout)

        self.activation = get_activation_fn(activation)

    @staticmethod
    def with_pos_embed(tensor, pos):
        return tensor if pos is None else tensor + pos
    
    def forward(self, x, pos):
        '''
        x: [(1, L1, C), (1, L2, C)...] egoå’Œå…¶ä»–agentçš„ç­›é€‰è¿‡çš„query egoæœ‰L1ä¸ª agent1æœ‰L2ä¸ª ä»¥æ­¤ç±»æ¨
        pos: [(1, L1, C), (1, L2, C)...] ä½ç½®ç¼–ç , ç”¨çš„æ˜¯ç©ºé—´å˜æ¢è¿‡çš„ä½ç½®ç¼–ç 
        é¦–å…ˆæ˜¯åŠ ä½ç½®ç¼–ç , åŠ äº†ä½ç½®ç¼–ç åconcatåœ¨ä¸€èµ·å½¢æˆ
        '''
        features = []
        for i, feat in enumerate(x):
            feat = self.with_pos_embed(feat, pos[i])
            features.append(feat)
        k =v = torch.cat(features, dim=1) # (1, L1+L2+..., C)
        assert len(x) == 2 # TransIFF æ˜¯ä¸“é—¨é¢å‘V2Iè®¾è®¡
        q_ego, q_inf = features[0], features[1]

        # two-stream
        q_ego_2 = self.self_attn_ego(q_ego, k, v)[0]
        q_ego = q_ego + self.dropout(q_ego_2)
        q_ego = self.ego_norm1(q_ego)
        q_ego_2 = self.ego_linear2(self.dropout(self.activation(self.ego_linear1(q_ego))))
        q_ego = q_ego + self.dropout(q_ego_2)
        q_ego = self.ego_norm2(q_ego)

        q_inf_2 = self.self_attn_inf(q_inf, k, v)[0]
        q_inf = q_inf + self.dropout(q_inf_2)
        q_inf = self.inf_norm1(q_inf)
        q_inf_2 = self.inf_linear2(self.dropout(self.activation(self.inf_linear1(q_inf))))
        q_inf = q_inf + self.dropout(q_inf_2)
        q_inf = self.ego_norm2(q_inf)

        return [q_ego, q_inf]


class TransIFFEncoder(nn.Module):
    def __init__(
        self,
        d_model=256,
        nhead=8,
        nlevel=1,
        num_encoder_layers=1,
        num_decoder_layers=1,
        dim_feedforward=1024,
        dropout=0.1,
        activation="relu",
        num_queries=300,
        num_classes=1,
        mom=0.999,
        cp_flag=False,
    ):
        super().__init__()

        self.num_queries = num_queries
        self.num_classes = num_classes
        self.m = mom

        encoder_layer = TransformerEncoderLayer(d_model, nhead, nlevel, dim_feedforward, dropout, activation)
        self.encoder = TransformerEncoder(d_model, encoder_layer, num_encoder_layers)
        # decoder_layer = TransformerDecoderLayer(d_model, nhead, nlevel, dim_feedforward, dropout, activation)
        # self.decoder = TransformerDecoder(d_model, decoder_layer, num_decoder_layers)

    def _generate_relative_position_encoding(self, H, W):
        # åˆ›å»ºä¸€ä¸ªç½‘æ ¼ï¼Œå…¶ä¸­æ¯ä¸ªä½ç½®çš„ (i, j) åæ ‡
        grid_x, grid_y = torch.meshgrid(torch.arange(H), torch.arange(W))
        
        # å°†ä½ç½®ç¼–ç å †å æˆ (H, W, 2) çš„å½¢çŠ¶
        position_encoding = torch.stack((grid_x, grid_y), dim=-1)
        
        return position_encoding

    def _transform_position_matrix(self, position_matrix, transform_matrix):
        # position_matrix æ˜¯ H x W x 2 çš„ç›¸å¯¹ä½ç½®çŸ©é˜µ
        # transform_matrix æ˜¯ 4 x 4 çš„å˜æ¢çŸ©é˜µ
        
        H, W, _ = position_matrix.shape
        transformed_positions = torch.zeros_like(position_matrix)
        
        # å¯¹æ¯ä¸ªä½ç½®è¿›è¡Œå˜æ¢
        for i in range(H):
            for j in range(W):
                # åŸå§‹ç›¸å¯¹ä½ç½®åæ ‡ (x, y)
                x, y = position_matrix[i, j]
                
                # å°† (x, y) è½¬æ¢ä¸ºé½æ¬¡åæ ‡ (x, y, 0, 1)
                original_coords = torch.tensor([x, y, 0, 1.0])  # é½æ¬¡åæ ‡
                
                # åº”ç”¨å˜æ¢çŸ©é˜µ
                transformed_coords = torch.matmul(transform_matrix, original_coords.float())
                
                # è·å–å˜æ¢åçš„åæ ‡ï¼ˆä¸å†éœ€è¦é½æ¬¡åæ ‡ï¼‰
                transformed_positions[i, j] = transformed_coords[:2]  # åªå– x, y
        
        return transformed_positions


    def _create_ref_windows(self, tensor_list):
        device = tensor_list[0].device

        ref_windows = []
        for tensor in tensor_list:
            B, _, H, W = tensor.shape
            ref_y, ref_x = torch.meshgrid(
                torch.linspace(0.5, H - 0.5, H, dtype=torch.float32, device=device),
                torch.linspace(0.5, W - 0.5, W, dtype=torch.float32, device=device),
                indexing="ij",
            ) # ä¸¤ä¸ªshape éƒ½æ˜¯(H,W)

            ref_y = ref_y.reshape(-1)[None] / H
            ref_x = ref_x.reshape(-1)[None] / W
            ref_xy = torch.stack((ref_x, ref_y), -1) # (HW,2)
            ref_wh = torch.ones_like(ref_xy) * 0.025  # 0.01 - 0.05 w.r.t. Deform-DETR
            placeholder = torch.zeros_like(ref_xy)[..., :1]
            ref_box = torch.cat((ref_xy, placeholder + 0.5, ref_wh, placeholder + 0.5, placeholder), -1).expand(
                B, -1, -1
            )

            ref_windows.append(ref_box)
        ref_windows = torch.cat(ref_windows, dim=1)

        return ref_windows

    def _get_enc_proposals(self, enc_embed, ref_windows, indexes=None):
        '''
        è¿™ä¸ªå‡½æ•°ä¸»è¦æ˜¯è´Ÿè´£ç­›é€‰å‡ºåˆé€‚çš„query, ä¹Ÿå°±æ˜¯queryé€‰æ‹©. åŒæ—¶è¦å°†ä½ç½®ç¼–ç è¿›è¡Œæ—‹è½¬ï¼Œ ç»Ÿä¸€åˆ°egoçš„ä½ç½®ç¼–ç 
        '''
        B, L = enc_embed.shape[:2]
        out_logits, out_ref_windows = self.proposal_head(enc_embed, ref_windows) # ç”Ÿæˆproposal åˆ†ä¸º åˆ†ç±»logits(B, H * W, 1)  ã€boxes å®šä½ (B, H * W, 7)

        out_probs = out_logits[..., 0].sigmoid()
        topk_probs, indexes = torch.topk(out_probs, self.num_queries, dim=1, sorted=False) # é€‰å‡ºç½®ä¿¡åº¦è¾ƒé«˜çš„
        topk_probs = topk_probs.unsqueeze(-1)
        indexes = indexes.unsqueeze(-1)

        out_ref_windows = torch.gather(out_ref_windows, 1, indexes.expand(-1, -1, out_ref_windows.shape[-1]))
        out_ref_windows = torch.cat(
            (
                out_ref_windows.detach(),
                topk_probs.detach().expand(-1, -1, out_logits.shape[-1]),
            ),
            dim=-1,
        )

        out_pos = None
        out_embed = None

        return out_embed, out_pos, out_ref_windows, indexes

    @torch.no_grad()
    def _momentum_update_gt_decoder(self):
        """
        Momentum update of the key encoder
        """
        for param_q, param_k in zip(self.decoder.parameters(), self.decoder_gt.parameters()):
            param_k.data = param_k.data * self.m + param_q.data * (1.0 - self.m)

    def forward(self, src, pos, noised_gt_box=None, noised_gt_onehot=None, attn_mask=None, targets=None):
        assert pos is not None, "position encoding is required!"
        src_anchors = self._create_ref_windows(src)
        src, _, src_shape = flatten_with_shape(src, None)
        src_pos = []
        for pe in pos:
            B, C = pe.shape[:2]
            pe = pe.view(B, C, -1).transpose(1, 2) # (B, HW, C)
            src_pos.append(pe)
        src_pos = torch.cat(src_pos, dim=1) # (B, H*W, C)
        src_start_index = torch.cat([src_shape.new_zeros(1), src_shape.prod(1).cumsum(0)[:-1]]) # è¿™ä¸ªæ˜¯ç”¨äºä¸€æ¬¡å¤„ç†å¤šä¸ªå°ºåº¦çš„featureçš„ï¼Œåœ¨æˆ‘ä»¬è¿™é‡Œå°±æ˜¯(0,)

        memory = self.encoder(src, src_pos, src_shape, src_start_index, src_anchors) # (B, H*W, 256) é€šè¿‡BoxAttentionè¿›è¡Œäº†äº¤äº’
        query_embed, query_pos, topk_proposals, topk_indexes = self._get_enc_proposals(memory, src_anchors)# è¿”å›Noneï¼ŒNoneï¼Œ(B, query_num, 8)ï¼Œ(B, query_num, 1)

        select_memory = torch.gather(memory, 1, topk_indexes.expand(-1, -1, memory.shape[-1])) # (B, query_num, 256)

        return select_memory, topk_proposals, None, memory, src_anchors, topk_indexes
        if noised_gt_box is not None:
            noised_gt_proposals = torch.cat(
                (
                    noised_gt_box,
                    noised_gt_onehot,
                ),
                dim=-1,
            )
            topk_proposals = torch.cat(
                (
                    noised_gt_proposals,
                    topk_proposals,
                ),
                dim=1,
            )
        init_reference_out = topk_proposals[..., :7]

        # hs, inter_references = self.decoder_gt(
        hs, inter_references = self.decoder(
            query_embed,
            query_pos,
            memory,
            src_shape,
            src_start_index,
            topk_proposals,
            attn_mask,
        )

        # optional gt forward
        if targets is not None:
            batch_size = len(targets)
            per_gt_num = [tgt["gt_boxes"].shape[0] for tgt in targets]
            max_gt_num = max(per_gt_num)
            batched_gt_boxes_with_score = memory.new_zeros(batch_size, max_gt_num, 8)
            for bi in range(batch_size):
                batched_gt_boxes_with_score[bi, : per_gt_num[bi], :7] = targets[bi]["gt_boxes"]
                batched_gt_boxes_with_score[bi, : per_gt_num[bi], 7:] = F.one_hot(
                    targets[bi]["labels"], num_classes=self.num_classes
                )

            with torch.no_grad():
                self._momentum_update_gt_decoder()
                if noised_gt_box is not None:
                    dn_group_num = noised_gt_proposals.shape[1] // (max_gt_num * 2)
                    pos_idxs = list(range(0, dn_group_num * 2, 2))
                    pos_noised_gt_proposals = torch.cat(
                        [noised_gt_proposals[:, pi * max_gt_num : (pi + 1) * max_gt_num] for pi in pos_idxs],
                        dim=1,
                    )
                    gt_proposals = torch.cat((batched_gt_boxes_with_score, pos_noised_gt_proposals), dim=1)
                    # create attn_mask for gt groups
                    gt_attn_mask = memory.new_ones(
                        (dn_group_num + 1) * max_gt_num, (dn_group_num + 1) * max_gt_num
                    ).bool()
                    for di in range(dn_group_num + 1):
                        gt_attn_mask[
                            di * max_gt_num : (di + 1) * max_gt_num,
                            di * max_gt_num : (di + 1) * max_gt_num,
                        ] = False
                else:
                    gt_proposals = batched_gt_boxes_with_score
                    gt_attn_mask = None

                hs_gt, inter_references_gt = self.decoder_gt(
                    None,
                    None,
                    memory,
                    src_shape,
                    src_start_index,
                    gt_proposals,
                    gt_attn_mask,
                )

            init_reference_out = torch.cat(
                (
                    init_reference_out,
                    gt_proposals[..., :7],
                ),
                dim=1,
            )

            hs = torch.cat(
                (
                    hs,
                    hs_gt,
                ),
                dim=2,
            )
            inter_references = torch.cat(
                (
                    inter_references,
                    inter_references_gt,
                ),
                dim=2,
            )

        inter_references_out = inter_references
        return hs, init_reference_out, inter_references_out, memory, src_anchors, topk_indexes

class MaxFusion(nn.Module):
    def __init__(self):
        super(MaxFusion, self).__init__()

    def forward(self, x):
        return torch.max(x, dim=0, keepdim=True)[0]

# simple fusion use Scaled Dot Product Attention
class AttenQueryFusion(nn.Module):
    def __init__(self, feature_dim):
        super(AttenQueryFusion, self).__init__()
        self.sqrt_dim = np.sqrt(feature_dim)

    def forward(self, x):
        # x : 1, k, C
        if x.size(1) == 1:
            return x
        query = key = value = x
        score = torch.bmm(query, key.transpose(1, 2)) / self.sqrt_dim
        attn = F.softmax(score, -1)
        context = torch.bmm(attn, value) # (1,k,C)
        x = context[:,0:1,:]
        return x

class SimpleGatingFusion(nn.Module):
    """
    å¯¹ç‰¹å¾è¿›è¡Œèåˆçš„æ¨¡å—:
    è¾“å…¥:
        x: (1, k, C) åŒä¸€ä½ç½®kä¸ªAgentç‰¹å¾, k<=4
    å®ç°:
        1. Flattenæˆä¸º (1, k*C)
        2. é€šè¿‡MLPè¾“å‡º(k,)ç»´æƒé‡å‘é‡
        3. ä½¿ç”¨softmaxå½’ä¸€åŒ–ååŠ æƒæ±‚å’Œ
    """
    def __init__(self, d_model=256, max_agents=2, hidden_dim=128):
        super(SimpleGatingFusion, self).__init__()
        self.max_agents = max_agents
        self.d_model = d_model
        self.mlp = nn.Sequential(
            nn.Linear(d_model * max_agents, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, max_agents)
        )

    def forward(self, x):
        # x: (1, k, C), k <= self.max_agents
        k = x.size(1)
        if k == 0:
            # æ²¡æœ‰ç‰¹å¾å¯èåˆï¼Œç›´æ¥è¿”å›ç©º
            return x
        if k == 1:
            # åªæœ‰ä¸€ä¸ªç‰¹å¾ï¼Œç›´æ¥è¿”å›
            return x

        # å¦‚æœå®é™…k < max_agentsï¼Œç”¨0å¡«å……
        pad_num = self.max_agents - k
        if pad_num > 0:
            pad = x.new_zeros((1, pad_num, self.d_model))
            x_padded = torch.cat([x, pad], dim=1) # (1, max_agents, C)
        else:
            x_padded = x

        flattened = x_padded.view(1, -1)  # (1, max_agents*C)
        weights = self.mlp(flattened)     # (1, max_agents)
        weights = weights[:, :k]          # åªå–å‰kä¸ªæƒé‡
        weights = F.softmax(weights, dim=-1)  # (1, k)
        
        # åŠ æƒæ±‚å’Œ
        fused = torch.sum(x * weights.unsqueeze(-1), dim=1, keepdim=True) # (1,1,C)
        return fused

class BoxGatingFusion(nn.Module):
    """
    å¯¹å‚è€ƒæ¡†è¿›è¡Œèåˆçš„æ¨¡å—:
    è¾“å…¥:
        boxes: (1, k, 8) åŒä¸€ä½ç½®kä¸ªAgentæä¾›çš„boxå‚æ•°, k<=4
    å®ç°:
        ä¸ç‰¹å¾ç±»ä¼¼ï¼Œç”¨MLPå¯¹kä¸ªboxæ‰“åˆ†å¹¶åŠ æƒå¹³å‡ã€‚
    å‡è®¾8ç»´boxä¸º [cx, cy, cz, w, l, h, rot, score]
    """
    def __init__(self, box_dim=8, max_agents=2, hidden_dim=64):
        super(BoxGatingFusion, self).__init__()
        self.max_agents = max_agents
        self.box_dim = box_dim
        self.mlp = nn.Sequential(
            nn.Linear(box_dim * max_agents, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, max_agents)
        )

    def forward(self, boxes):
        # boxes: (1, k, 8)
        k = boxes.size(1)
        if k == 0:
            return boxes
        if k == 1:
            return boxes

        pad_num = self.max_agents - k
        if pad_num > 0:
            pad = boxes.new_zeros((1, pad_num, self.box_dim))
            boxes_padded = torch.cat([boxes, pad], dim=1) # (1, max_agents, 8)
        else:
            boxes_padded = boxes

        flattened = boxes_padded.view(1, -1) # (1, max_agents*8)
        weights = self.mlp(flattened) # (1, max_agents)
        weights = weights[:, :k] 
        weights = F.softmax(weights, dim=-1) # (1, k)

        # å–ç©ºé—´å‚æ•°7ç»´åŠ æƒå¹³å‡ï¼Œå†å¯¹scoreç»´åº¦ä¹ŸåŠ æƒå¹³å‡
        space_params = boxes[..., :7] # (1,k,7)
        fused_space = torch.sum(space_params * weights.unsqueeze(-1), dim=1, keepdim=True) # (1,1,7)

        score = boxes[..., 7:8] # (1,k,1)
        fused_score = torch.sum(score * weights.unsqueeze(-1), dim=1, keepdim=True) # (1,1,1)

        fused_box = torch.cat([fused_space, fused_score], dim=-1) # (1,1,8)
        return fused_box


class Transformer(nn.Module):
    def __init__(
        self,
        d_model=256,
        nhead=8,
        nlevel=1,
        num_encoder_layers=6,
        num_decoder_layers=6,
        dim_feedforward=1024,
        dropout=0.1,
        activation="relu",
        num_queries=300,
        num_classes=1,
        mom=0.999,
        cp_flag=False,
        box_encode_func=None, 
        box_decode_func=None, 
        get_sparse_features_func=None
    ):
        super().__init__()

        self.num_queries = num_queries
        self.num_classes = num_classes
        self.m = mom
        self.extra_query_num = 200 # é¢å¤–çš„queryæ•°é‡ï¼Œç”¨äºéé‡å ä½ç½®çš„è¡¥å……

        self.box_encode_func=box_encode_func
        self.box_decode_func=box_decode_func
        self.get_sparse_features_func=get_sparse_features_func

        encoder_layer = TransformerEncoderLayer(d_model, nhead, nlevel, dim_feedforward, dropout, activation)
        self.encoder = TransformerEncoder(d_model, encoder_layer, num_encoder_layers)
        self.trans_adapter = TransAdapt(d_model, nhead, nlevel, dim_feedforward, dropout, activation)
        # self.query_fusion = AttenQueryFusion(d_model)
        # self.ref_fusion = AttenQueryFusion(8)
        self.query_fusion = SimpleGatingFusion()
        self.ref_fusion = BoxGatingFusion()
        self.foreground_fusion = MaxFusion()
        decoder_layer = TransformerDecoderLayer(d_model, nhead, nlevel, dim_feedforward, dropout, activation)
        self.decoder = TransformerDecoder(d_model, decoder_layer, num_decoder_layers, cp_flag)
        self.sample_idx = 0

    def _create_ref_windows(self, tensor_list):
        device = tensor_list[0].device

        ref_windows = []
        for tensor in tensor_list:
            B, _, H, W = tensor.shape
            ref_y, ref_x = torch.meshgrid(
                torch.linspace(0.5, H - 0.5, H, dtype=torch.float32, device=device),
                torch.linspace(0.5, W - 0.5, W, dtype=torch.float32, device=device),
                indexing="ij",
            )

            ref_y = ref_y.reshape(-1)[None] / H
            ref_x = ref_x.reshape(-1)[None] / W
            ref_xy = torch.stack((ref_x, ref_y), -1)
            ref_wh = torch.ones_like(ref_xy) * 0.025  # 0.01 - 0.05 w.r.t. Deform-DETR
            placeholder = torch.zeros_like(ref_xy)[..., :1]
            ref_box = torch.cat((ref_xy, placeholder + 0.5, ref_wh, placeholder + 0.5, placeholder), -1).expand(
                B, -1, -1
            )

            ref_windows.append(ref_box)
        ref_windows = torch.cat(ref_windows, dim=1)

        return ref_windows

    def _get_enc_proposals(self, enc_embed, ref_windows, indexes=None):
        B, L = enc_embed.shape[:2]
        out_logits, out_ref_windows = self.proposal_head(enc_embed, ref_windows)

        out_probs = out_logits[..., 0].sigmoid()
        topk_probs, indexes = torch.topk(out_probs, self.num_queries + self.extra_query_num, dim=1, sorted=True)
        topk_probs = topk_probs.unsqueeze(-1)
        indexes = indexes.unsqueeze(-1)
        # print("out_probs  is ", [round(x, 3) for x in out_probs[0][:1000].tolist()])

        out_ref_windows = torch.gather(out_ref_windows, 1, indexes.expand(-1, -1, out_ref_windows.shape[-1]))
        out_ref_windows = torch.cat(
            (
                out_ref_windows.detach(),
                topk_probs.detach().expand(-1, -1, out_logits.shape[-1]),
            ),
            dim=-1,
        )

        out_pos = None
        out_embed = None

        return out_embed, out_pos, out_ref_windows, indexes

    @torch.no_grad()
    def _momentum_update_gt_decoder(self):
        """
        Momentum update of the key encoder
        """
        for param_q, param_k in zip(self.decoder.parameters(), self.decoder_gt.parameters()):
            param_k.data = param_k.data * self.m + param_q.data * (1.0 - self.m)

    def regroup(self, x, record_len):
        cum_sum_len = torch.cumsum(record_len, dim=0)
        split_x = torch.tensor_split(x, cum_sum_len[:-1].cpu())
        return split_x

    def forward(self, src, pos, noised_gt_box=None, noised_gt_onehot=None, attn_mask=None, targets=None, valid_bboxes_single = None, record_len=None, pairwise_t_matrix=None, pairwise_t_matrix_ref=None):
        '''
        src: [(B_n, 256, H, W)]
        pos: [(B_n, 256, H, W)]
        noised_gt_box: (B, pad_size, 7)  è¿™é‡Œç”¨çš„åº”è¯¥æ˜¯ååŒgt
        noised_gt_onehot: (B, pad_size, num_classes)
        attn_mask: (1000+pad_size, 1000+pad_size)
        targets: [{'gt_boxes': (N, 7), 'labels': (N, )}, ...]
        '''
        assert pos is not None, "position encoding is required!"
        src_anchors = self._create_ref_windows(src) # åˆ›é€ å‚è€ƒæ¡†ï¼Œè¿™ä¸ªæ˜¯BoxAttentionå¿…é¡»çš„ (B_n, HW, 7)
        src, _, src_shape = flatten_with_shape(src, None)# å±•å¹³ç‰¹å¾å›¾ï¼Œè¿”å›çš„æ˜¯ (B_n, H*W, 256), None, (1, 2) æœ€åä¸€é¡¹è®°å½•ç€Hï¼ŒW å³feature shape
        src_pos = []
        for pe in pos:
            B, C = pe.shape[:2]
            pe = pe.view(B, C, -1).transpose(1, 2) # b, h*w, c
            src_pos.append(pe)
        src_pos = torch.cat(src_pos, dim=1) # (B_n, H*W, C)
        src_start_index = torch.cat([src_shape.new_zeros(1), src_shape.prod(1).cumsum(0)[:-1]]) # è¿™æ˜¯ä¸ºäº†ç”Ÿæˆåˆ’åˆ†çš„ç´¢å¼•ï¼ŒåŒºåˆ†æ¯ä¸ªç‰¹å¾å›¾çš„ä½ç½®ï¼Œç”±äºåªæœ‰ä¸€ä¸ªç‰¹å¾å›¾ï¼Œæ‰€ä»¥ç»“æœæ˜¯(0,)

        memory = self.encoder(src, src_pos, src_shape, src_start_index, src_anchors) # BoxAttention æå–ç‰¹å¾ ç»“æœä¸º(B_n, H*W, 256)
        query_embed, query_pos, topk_proposals, topk_indexes = self._get_enc_proposals(memory, src_anchors) # è¿”å›Noneï¼ŒNoneï¼Œ(B_n, query_num+extra_num, 8)ï¼Œ(B_n, query_num+extra_num, 1)
        
        ego_topk_proposals = topk_proposals[:, :self.num_queries, :] # (B_n, query_num, 8)
        ego_topk_indexes = topk_indexes[:, :self.num_queries, :] # (B_n, query_num, 1) NOTE singleç›‘ç£åªç›‘ç£å‰300ä¸ª
        extra_topk_proposals = topk_proposals[:, self.num_queries:, :]  # (B_n, extra_num, 8)
        extra_topk_indexes = topk_indexes[:, self.num_queries:, :]  # (B_n, extra_num, 1)

        fined_query = torch.gather(memory, 1, ego_topk_indexes.expand(-1, -1, memory.shape[-1])) # (B_n, query_num, C) refineçš„query
        extra_query = torch.gather(memory, 1, extra_topk_indexes.expand(-1, -1, memory.shape[-1])) # (B_n, extra_num, C) refineçš„query

        H, W = src_shape[0,0], src_shape[0,1]
        memory_discrete = torch.zeros_like(memory) # (B_n, H*W, 256) 
        memory_discrete = memory_discrete.scatter(1, ego_topk_indexes.repeat(1, 1, memory_discrete.size(-1)), fined_query) # (B_n, H*W, 256) å°†queryæ”¾å…¥åˆ°ä¸€ä¸ªç©ºçš„memoryä¸­
        memory_discrete = memory_discrete.permute(0, 2, 1).reshape(memory.shape[0], memory.shape[-1], H, W) # (B_n, C, H, W) å½¢æˆç¨€ç–çš„ç‰¹å¾å›¾

        # æ–°å»ºä¸€ä¸ªé»˜è®¤å‚è€ƒæ¡†ï¼Œç„¶åå°†encoderé¢„æµ‹çš„å†…å®¹å¡«å……è¿›å»ï¼Œè¿™ä¸ªå°†ä¼šåœ¨ç©ºé—´å˜æ¢åä½œä¸º
        ref_boxes_before_trans = copy.deepcopy(src_anchors)
        ref_probs_before_trans = torch.zeros(ref_boxes_before_trans.size(0), ref_boxes_before_trans.size(1), 1).to(ref_boxes_before_trans)
        ref_boxes_before_trans = torch.cat([ref_boxes_before_trans, ref_probs_before_trans], dim=-1)
        fined_ref_boxes = ego_topk_proposals # (B_n, query_num, 8) è¿™ä¸ªæ˜¯å‚è€ƒæ¡† è¦è·Ÿç€é‡‡æ ·
        ref_boxes_before_trans = ref_boxes_before_trans.scatter(1, ego_topk_indexes.repeat(1, 1, ref_boxes_before_trans.size(-1)), fined_ref_boxes) # (B_n, H*W, 8) å°†queryæ”¾å…¥åˆ°ä¸€ä¸ªç©ºçš„memoryä¸­

        ref_boxes_before_trans = ref_boxes_before_trans.permute(0, 2, 1).reshape(memory.shape[0], 8, H, W) # (B_n, 8, H, W) å½¢æˆç¨€ç–çš„ç‰¹å¾å›¾

        # åˆ›é€ maskæ ‡è®°fined query
        valid_flag = torch.ones(fined_query.shape[0], fined_query.shape[1], 1).to(fined_query) # (B_n, query_num, 1) å…¨1
        memory_mask = torch.zeros(memory.shape[0], memory.shape[1], 1).to(memory) # (B_n, HW, 1)
        memory_mask = memory_mask.scatter(1, ego_topk_indexes.repeat(1, 1, memory_mask.size(-1)), valid_flag) # (B_n, HW, 1)  å°†fined queryç»™æ ‡è®°
        memory_mask = memory_mask.permute(0, 2, 1).reshape(memory_mask.shape[0], 1, H, W) # (B_n, 1, H, W)

        # è·å–ç¨€ç–ç‰¹å¾å›¾ï¼Œè®­ç»ƒæ—¶ä½¿ç”¨GTæ¥æˆªå–ï¼Œæ¨ç†æ—¶ä½¿ç”¨singleæ£€æµ‹ç»“æœæˆªå–
        memory_sparse = memory.permute(0, 2, 1).reshape(memory.shape[0], memory.shape[-1], H, W) # (B_n, 256, H, W) 
        if valid_bboxes_single is not None:
            rois_lst = valid_bboxes_single # [N1, N2, N3, N4] æ¯ä¸ªåœºæ™¯ä¸­æ¯ä¸ªsingleçš„bbx
        memory_sparse = self.get_sparse_features_func(memory_sparse, rois_lst) # (B_n, 256, H, W) 
        # memory_sparse = memory_sparse.flatten(2).permute(0, 2, 1) # (B_n, HW, C) 
        # print("memory_sparse shape is ", memory_sparse.shape)

        memory_batch_lst = self.regroup(memory, record_len)
        memory_discrete_batch_lst = self.regroup(memory_discrete, record_len)
        ref_boxes_before_trans_batch_lst = self.regroup(ref_boxes_before_trans, record_len)
        memory_mask_batch_lst = self.regroup(memory_mask, record_len)

        ego_topk_indexes_batch_lst = self.regroup(ego_topk_indexes, record_len)
        extra_topk_indexes_batch_lst = self.regroup(extra_topk_indexes, record_len)
        extra_query_batch_lst = self.regroup(extra_query, record_len)
        extra_topk_proposals_batch_lst = self.regroup(extra_topk_proposals, record_len) #  [(N1, extra_num, 8), (N2, extra_num, 8)...]

        memory_sparse_batch_lst =  self.regroup(memory_sparse, record_len)

        fused_queries = []
        fused_ref_windows = []
        fused_indicies = []
        ego_features = []
        # å°†å…¶ä»–çš„agentçš„feature æŠ•å½±åˆ°egoåæ ‡ç³»
        for bid in range(len(memory_batch_lst)):
            N = record_len[bid] # number of valid agent
            
            memory_b = memory_batch_lst[bid] # (N, H*W, C) å•ç‹¬ä¸€ä¸ªæ ·æœ¬ä¸‹çš„Nä¸ªagentï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªä¸ºegoçš„feature
            memory_sparse_b = memory_sparse_batch_lst[bid] # (N, C, H, W) ç¨€ç–ç‰¹å¾å›¾
            memory_discrete_b = memory_discrete_batch_lst[bid] # (N, C, H, W) Encoderç­›é€‰è¿‡çš„ç•™ä¸‹æ¥ï¼Œå…¶ä½™å…¨éƒ¨ä¸ºç©º
            ref_boxes_trans_b = ref_boxes_before_trans_batch_lst[bid][:,:7,:,:] # (N, 7, H, W) Encoderç­›é€‰è¿‡çš„ç•™ä¸‹æ¥ï¼Œå…¶ä½™å…¨éƒ¨ä¸ºç©º
            ref_probs_trans_b = ref_boxes_before_trans_batch_lst[bid][:,7:,:,:] # (N, 1, H, W) Encoderç­›é€‰è¿‡çš„ç•™ä¸‹æ¥ï¼Œå…¶ä½™å…¨éƒ¨ä¸ºç©º
            memory_mask_b = memory_mask_batch_lst[bid] # (N, 1, H, W)
            t_matrix = pairwise_t_matrix[bid][:N, :N, :, :] # (N, N, 2, 3)
            t_matrix_ref = pairwise_t_matrix_ref[bid][:N, :N, :, :] # (N, N, 4, 4)
            
            neighbor_memory = warp_affine_simple(memory_discrete_b, t_matrix[0, :, :, :], (H, W), mode='nearest') # (N, C, H, W)
            ref_boxes_trans_b = warp_affine_simple(ref_boxes_trans_b, t_matrix[0, :, :, :], (H, W), mode='nearest') # (N, 7, H, W)
            neighbor_memory_mask = warp_affine_simple(memory_mask_b, t_matrix[0, :, :, :], (H, W), mode='nearest') # (N, 1, H, W)

            neighbor_memory_sparse_b = warp_affine_simple(memory_sparse_b, t_matrix[0, :, :, :], (H, W), mode='bilinear') # (N, C, H, W)

            # import matplotlib.pyplot as plt
            # import os
            # if self.sample_idx % 20 == 0:
            #     save_dir = "./feature_visualizations"
            #     os.makedirs(save_dir, exist_ok=True)
            #     for b in range(N):
            #         feature_map = neighbor_memory_sparse_b[b]
            #         feature_map = feature_map.mean(dim=0)

            #         # å°†ç‰¹å¾å›¾å½’ä¸€åŒ–åˆ° [0, 255]
            #         def normalize_to_image(tensor):
            #             tensor = tensor - tensor.min()
            #             tensor = tensor / tensor.max()
            #             return (tensor * 255).byte()
                    
            #         dense_feature = normalize_to_image(feature_map)

            #         # è½¬ä¸º NumPy æ ¼å¼
            #         dense_feature_np = dense_feature.cpu().numpy()

            #         # åˆ›å»ºå¯è§†åŒ–ç”»å¸ƒ
            #         plt.figure(figsize=(20, 10))
            #         plt.imshow(dense_feature_np, cmap="viridis")
            #         plt.axis("off")

            #         # ä¿å­˜åˆ°æ–‡ä»¶
            #         plt.savefig(os.path.join(save_dir, f"trans_feature_map_{self.sample_idx}_{b}.png"), dpi=300, bbox_inches="tight", pad_inches=0)
            #         plt.close() 
            # self.sample_idx += 1

            neighbor_memory_sparse_b = neighbor_memory_sparse_b.flatten(2).permute(0, 2, 1) # (N, HW, C) 
            if memory_b.size(0) != 1: # æ³¨é‡Šæ‰åˆ™ä¸ä½¿ç”¨foreground fusion
                memory_b = torch.cat([memory_b[:1], neighbor_memory_sparse_b[1:]], dim=0)
                memory_b = self.foreground_fusion(memory_b) # (1, H*W, C)

            ref_boxes_trans_b = torch.cat([ref_boxes_trans_b, ref_probs_trans_b], dim=1) # (N, 8, H, W)
            neighbor_memory = neighbor_memory.flatten(2).permute(0, 2, 1) # (N, HW, C)
            ref_boxes_trans_b = ref_boxes_trans_b.flatten(2).permute(0, 2, 1) # (N, HW, 8)
            neighbor_memory_mask = neighbor_memory_mask.flatten(2).permute(0, 2, 1) # (N, HW, 1) è¿™ä¸ªé‡Œé¢æœ‰0æœ‰1, 1çš„åœ°æ–¹å°±æ˜¯å¯¹åº”å…¶æœ‰æ•ˆçš„queryï¼Œè¿™äº›queryè¦å…ˆåœ¨ego featureä¸ŠåšLocal Attention
            # pos_b = src_pos[0:N] # (N, HW, C) NOTE ä½ç½®ç¼–ç æ¯ä¸ªfeatureåœ¨ä¸€å¼€å§‹æ˜¯å®Œå…¨ä¸€æ ·çš„ æ‰€ä»¥å¯ä»¥ç›´æ¥å–éœ€è¦çš„ä¸ªæ•°

            neighbor_mask = neighbor_memory_mask.squeeze(-1).bool() # (N, HW)
            valid_features_lst = [neighbor_memory[i][neighbor_mask[i]].unsqueeze(0) for i in range(N)] # [(1, n1, C), (1, n2, C)...]
            valid_ref_lst = [ref_boxes_trans_b[i][neighbor_mask[i]].unsqueeze(0) for i in range(N)] # [(1, n1, 8), (1, n2, 8)...]
            record_query_num = torch.tensor([v.size(1) for v in valid_ref_lst]) # [n1, n2, ...]
            # valid_pos_lst = [pos_b[i][neighbor_mask[i]] for i in range(N)] # [(n1, C), (n2, C)...]

            none_ego_features_lst = valid_features_lst[1:] # [(1, n2, C), ...]
            none_ego_ref = valid_ref_lst[1:] # [(1, n2, 8), ...]
            # none_ego_pos = valid_pos_lst[1:]

            none_ego_ref_trans_lst = []
            # æ—‹è½¬å‚è€ƒæ¡†ï¼Œæš‚æ—¶æ²¡æç©ºé—´å˜æ¢çŸ©é˜µçš„ç¼©æ”¾ï¼Œå¦‚æœç›´æ¥ç¼©æ”¾ç©ºé—´å˜æ¢çŸ©é˜µåˆ™ä¸ç”¨encodeå’Œdecode boxï¼Œä½†æ˜¯ç›®å‰å…ˆä»¥è¿™æ ·çš„æ–¹å¼éªŒè¯é€»è¾‘ TODO åé¢è¦æ”¹
            for id, nef in enumerate(none_ego_ref):
                none_ego_bbox_center = self.box_decode_func(nef[..., :7].squeeze(0)) # (n, 7) åå½’ä¸€åŒ–

                none_ego_bbox_corner = box_utils.boxes_to_corners_3d(none_ego_bbox_center, 'lwh') # (n, 8, 3)
                projected_none_ego_bbox_corner = box_utils.project_box3d(none_ego_bbox_corner.float(), t_matrix_ref[0,id+1].float())
                projected_none_ego_bbox_center = box_utils.corners_to_boxes_3d(projected_none_ego_bbox_corner, 'lwh') # (n, 7)
                projected_none_ego_bbox_center = self.box_encode_func(projected_none_ego_bbox_center) # é‡æ–°å½’ä¸€åŒ–
                projected_none_ego_bbox_center = torch.cat([projected_none_ego_bbox_center, nef[0, :, 7:]], dim=-1) # # (n, 8)
                none_ego_ref_trans_lst.append(projected_none_ego_bbox_center.unsqueeze(0))

                # è¿˜è¦å°†å˜æ¢åçš„æ”¾å…¥åˆ° valid_ref_lst
                valid_ref_lst[id+1] = none_ego_ref_trans_lst[-1]

            if len(none_ego_features_lst) > 0:
                none_ego_features = torch.cat(none_ego_features_lst, dim=1) # (1, n2+n3+..., C)
                none_ego_ref_trans = torch.cat(none_ego_ref_trans_lst, dim=1) # (1, n2+n3+..., 8)
                # none_ego_pos = torch.cat(none_ego_pos, dim=0) # (n2+n3+..., C) # XXX è€ƒè™‘ä¸€ä¸‹posæ˜¯ä½¿ç”¨refè¿˜æ˜¯ç”¨egoçš„ä½ç½®ç¼–ç ï¼Œ ç›®å‰ä½¿ç”¨refä½œä¸ºposç¼–ç  æ‰€ä»¥è¿™ä¸ªæš‚æ—¶ä¸éœ€è¦
            
                # TODO è¿™é‡Œä»…ä»…å¯¹queryåšäº† Local Attentionï¼Œä½†å¹¶æ²¡æœ‰æ®æ­¤å»æ›´æ–°æ—‹è½¬è¿‡æ¥çš„å‚è€ƒæ¡† æ„Ÿè§‰æ˜¯éœ€è¦æ›´æ–°çš„ 
                query_adapt = self.trans_adapter(none_ego_features, memory_b[0:1], src_shape, src_start_index, none_ego_ref_trans) # (1, n2+n3+..., C) å…¶ä»–agentçš„queryåœ¨ego featureä¸Šè¿›è¡ŒLocal Attention

                query_adapt_lst = self.regroup(query_adapt.squeeze(0), record_query_num[1:]) # [(n2, C), ...]

                query_lst = [q.unsqueeze(0) for q in query_adapt_lst]  # [(1, n2, C), ...]
            else: # å¯èƒ½çš„æƒ…å†µ: 1. è·ç¦»åŸå› å¯¼è‡´åªæœ‰egoä¸€ä¸ªfeature 2. agentæŠ•å½±è¿‡æ¥æ— query
                query_lst = []

            query_lst = valid_features_lst[0:1] + query_lst  # [(1, n1, C), (1, n2, C)...]

            all_indices = [] # [(1, n1, 1), (1, n2, 1), (1, n3, 1)...] ä¸€å…±N-1 ä¸ª, è¡¨ç¤ºåœºæ™¯ä¸­çš„æ‰€æœ‰æœ‰æ•ˆqueryçš„ç´¢å¼• å…¶ä¸­egoæˆ‘ä»¬ä¸ç”¨
            for i in range(N):
                neighbor_index = torch.nonzero(neighbor_memory_mask[i].squeeze(-1), as_tuple=False) # (n, 1)
                if neighbor_index.size(0) > 0:
                    all_indices.append(neighbor_index.unsqueeze(0))
            all_indices[0] = ego_topk_indexes_batch_lst[bid][0:1] # (N, query_num, 1)ä¸­é€‰æ‹©å‡ºegoçš„ å³(1, query_num, 1)

            ego_feature = memory_b[0:1] # (1, HW, C)

            # æ¥ä¸‹æ¥å¯¹ç›¸åŒä½ç½®çš„queryè¿›è¡Œèåˆï¼Œagentæä¾›çš„é¢å¤–ä¿¡æ¯åˆ™æ”¾ç½®åœ¨extraçš„ä½ç½®
            if len(all_indices) > 1:
                fused_query, fused_indices = self.fuse_features_by_index(all_indices, query_lst, self.query_fusion, extra_query_batch_lst[bid][0:1], extra_topk_indexes_batch_lst[bid][0:1]) # (1, 300+200, C), (1, 300+200, 1)
                fused_ref, _ = self.fuse_features_by_index(all_indices, valid_ref_lst, self.ref_fusion, extra_topk_proposals_batch_lst[bid][0:1], extra_topk_indexes_batch_lst[bid][0:1]) # (1, 300+200, 8)
                ego_feature = ego_feature.scatter(1, fused_indices.repeat(1, 1, ego_feature.size(-1)), fused_query)
            else: # å¦‚æœåˆ°è¿™é‡Œï¼Œå¯èƒ½æ˜¯: 1.è·ç¦»è¿‡è¿œå¯¼è‡´åªæœ‰ä¸€ä¸ªego 2.agentæŠ•å½±è¿‡æ¥æ— query
                fused_query = torch.cat([query_lst[0], extra_query_batch_lst[bid][0:1]], dim=1)
                fused_indices = torch.cat([all_indices[0], extra_topk_indexes_batch_lst[bid][0:1]], dim=1)
                fused_ref = torch.cat([valid_ref_lst[0], extra_topk_proposals_batch_lst[bid][0:1]], dim=1)
                # print("crazy, without overlap! ")
                
            fused_queries.append(fused_query)
            fused_indicies.append(fused_indices)
            fused_ref_windows.append(fused_ref)
            ego_features.append(ego_feature)
        fused_queries = torch.cat(fused_queries, dim=0) # (B, query_num+extra_num, C)
        fused_indicies = torch.cat(fused_indicies, dim=0) # (B, query_num+extra_num, 1)
        fused_ref_windows = torch.cat(fused_ref_windows, dim=0) # (B, query_num+extra_num, 8)
        ego_features = torch.cat(ego_features, dim=0) # (B, HW, C)
        # print("fused_indicies first is ", fused_indicies[0].tolist())
        # print("ego_topk_indexes is ", ego_topk_indexes[0].tolist())
        # print("record_query_num is ", record_query_num)
        # if self.debug < 100:
        #     self.debug += 1
        # else:
        #     xxx
        # åŠ å™ªå£°gtï¼Œå‡†å¤‡ä¸€èµ·å‚ä¸decoderè®­ç»ƒå»å™ª
        if noised_gt_box is not None:
            noised_gt_proposals = torch.cat(
                (
                    noised_gt_box,
                    noised_gt_onehot,
                ),
                dim=-1,
            ) # (B, pad_size, 8)
            fused_ref_windows = torch.cat(
                (
                    noised_gt_proposals,
                    fused_ref_windows,
                ),
                dim=1,
            ) # (B, pad_size + all_query_num, 8) while: all_query_num == query_num+extra_num
        init_reference_out = fused_ref_windows[..., :7]

        # hs, inter_references = self.decoder_gt(
        hs, inter_references = self.decoder(
            query_embed, # None
            query_pos, # None
            ego_features, # BoxAttention æå–ç‰¹å¾åç»“åˆå¤šagentåçš„Feature Map ç»“æœä¸º(B, H*W, 256)
            src_shape, # (1, 2)
            src_start_index, # (0,)
            fused_ref_windows, # (B, all_query_num, 8)
            attn_mask,
        ) # (3, B, pad_size + all_query_num, 256) æ¯ä¸€å±‚çš„è¾“å‡ºçš„queryç‰¹å¾ï¼Œ (3ï¼Œ B, pad_size + all_query_num, 7) æ¯ä¸€å±‚çš„æ£€æµ‹ç»“æœ

        # optional gt forward å¯¹æ¯”å­¦ä¹ éœ€è¦ç”¨åˆ°çš„åŠ¨é‡æ›´æ–°æ¨¡å‹ç”¨åŠ å™ªgtæ¥åšå¯¹æ¯”å­¦ä¹ çš„
        if targets is not None:
            batch_size = len(targets) # è¿™é‡Œæ˜¯ååŒæ ‡ç­¾
            per_gt_num = [tgt["gt_boxes"].shape[0] for tgt in targets] # [N1, N2, N3, N4] æ­¤ä¸ºB=4æ—¶çš„å„ä¸ªæ ·æœ¬çš„GTæ•°
            max_gt_num = max(per_gt_num)
            batched_gt_boxes_with_score = memory.new_zeros(batch_size, max_gt_num, 8) # (B, max_gt_num, 8)
            for bi in range(batch_size):
                batched_gt_boxes_with_score[bi, : per_gt_num[bi], :7] = targets[bi]["gt_boxes"] # æ”¾å…¥gtçš„box å’Œ one-hot åˆ†ç±»ç¼–ç 
                batched_gt_boxes_with_score[bi, : per_gt_num[bi], 7:] = F.one_hot(
                    targets[bi]["labels"], num_classes=self.num_classes
                )

            with torch.no_grad():
                self._momentum_update_gt_decoder() # åŠ¨é‡æ›´æ–°è¾…åŠ©æ¨¡å‹ï¼Œå…¶å‚æ•°æ›´æ–°é€Ÿåº¦éå¸¸ç¼“æ…¢ï¼Œä½†ä¸€ç›´è¿½éšdecoder
                if noised_gt_box is not None:
                    dn_group_num = noised_gt_proposals.shape[1] // (max_gt_num * 2) # å¾—åˆ°å»å™ªgtç»„æ•° == 3  2æŒ‡çš„æ˜¯æ¯ä¸€ç»„åˆåˆ†æ­£è´Ÿæ ·æœ¬
                    pos_idxs = list(range(0, dn_group_num * 2, 2))
                    pos_noised_gt_proposals = torch.cat(
                        [noised_gt_proposals[:, pi * max_gt_num : (pi + 1) * max_gt_num] for pi in pos_idxs],
                        dim=1,
                    ) # æ¯ä¸€ç»„æŠ½å–max_gt_numä¸ª (B, 3*max_gt_num, 8) è¿™æ˜¯ç›¸å½“äºå»å™ªæ­£æ ·æœ¬æŠ½å–å‡ºæ¥
                    gt_proposals = torch.cat((batched_gt_boxes_with_score, pos_noised_gt_proposals), dim=1)
                    # create attn_mask for gt groups
                    gt_attn_mask = memory.new_ones(
                        (dn_group_num + 1) * max_gt_num, (dn_group_num + 1) * max_gt_num
                    ).bool()  # ï¼ˆ4*max_gt_numï¼Œ4*max_gt_numï¼‰å…¨True
                    for di in range(dn_group_num + 1): # å¯¹è§’éƒ¨åˆ†mask å…¨éƒ¨è®¾ç½®ä¸ºFalseï¼Œç›¸å½“äºè¯´åªå…³æ³¨è‡ªå·±ï¼Œå³æ¯ä¸€æ‰¹gtï¼Œæ— è®ºæœ‰æ— å™ªå£°ï¼Œä»…å…³æ³¨è‡ªèº«ï¼Œå±è”½ç»„ä¹‹é—´çš„å¯è§æ€§
                        gt_attn_mask[
                            di * max_gt_num : (di + 1) * max_gt_num,
                            di * max_gt_num : (di + 1) * max_gt_num,
                        ] = False
                else:
                    gt_proposals = batched_gt_boxes_with_score
                    gt_attn_mask = None

                hs_gt, inter_references_gt = self.decoder_gt( # è¾…åŠ©æ¨¡å‹è¿›è¡Œå¯¹æ¯”å­¦ä¹ ï¼Œç¼“æ…¢è¿½éšdecoderã€‚ è¿”å› (3ï¼ŒB, 4*max_gt_num, 256) ä¸ (3ï¼ŒB, 4*max_gt_num, 8)
                    None,
                    None,
                    ego_features, # BoxAttention æå–ç‰¹å¾åç»“åˆå¤šagentåçš„Feature Map ç»“æœä¸º(B, H*W, 256)
                    src_shape, # (1, 2)
                    src_start_index, # (0,)
                    gt_proposals, # (B, 4*max_gt_num, 8)
                    gt_attn_mask, #ï¼ˆ4*max_gt_numï¼Œ4*max_gt_numï¼‰
                )

            init_reference_out = torch.cat(
                (
                    init_reference_out,
                    gt_proposals[..., :7],
                ),
                dim=1,
            ) # (B, pad_size + all_query_num + 4*max_gt_num, 8) while: all_query_num == query_num+extra_num è¾“å…¥decoderå‰çš„ref window

            hs = torch.cat(
                (
                    hs,
                    hs_gt,
                ),
                dim=2,
            ) # (3, B, pad_size + all_query_num + 4*max_gt_num, 256) æ¯ä¸€å±‚Decoder layerçš„è¾“å‡ºquery
            inter_references = torch.cat(
                (
                    inter_references,
                    inter_references_gt,
                ),
                dim=2,
            ) # (3ï¼Œ B, pad_size + all_query_num + 4*max_gt_num, 7) æ¯ä¸€å±‚Decoder layerçš„å¯¹åº”æ£€æµ‹ç»“æœ

        inter_references_out = inter_references
        '''
        ä»å‰å¾€åä¾æ¬¡è¿”å›: Decoder layeræ¯ä¸€å±‚çš„query, è¾“å…¥Decoderçš„å‚è€ƒæ¡†, Decoder layeræ¯ä¸€å±‚çš„æ£€æµ‹ç»“æœ, Encoderè¾“å‡ºçš„ç‰¹å¾å›¾, åˆå§‹åŒ–çš„å‚è€ƒæ¡†, egoçš„æœ€é«˜query_numçš„ç´¢å¼•
        TODO Encoderè¾“å‡ºçš„ç‰¹å¾å›¾ä¿¡æ¯ä¼šä¸ä¼šä¸è¶³? è¦ä¸è¦è€ƒè™‘å°†queryèåˆåçš„ä¿¡æ¯æ”¾å›å» ğŸŒŸUpdated: Done, å…ˆçœ‹çœ‹æ€§èƒ½
        '''
        return hs, init_reference_out, inter_references_out, memory, src_anchors, ego_topk_indexes

    def fuse_features_by_index(self, index_list, feature_list, fusion_func, extra_future, extra_index):
        """
        æ ¹æ®ç´¢å¼•å¯¹ç‰¹å¾è¿›è¡Œèåˆã€‚

        å‚æ•°:
        - index_list: list of torch.Tensor, å½¢çŠ¶ä¸º (1, n, 1) çš„ç´¢å¼•å¼ é‡åˆ—è¡¨ï¼Œæ¯ä¸ªè¡¨ç¤ºæœ‰æ•ˆçš„ç´¢å¼•ä½ç½®ã€‚ eg. [(1,300,1), (1,62,1)...]
        - feature_list: list of torch.Tensor, å½¢çŠ¶ä¸º (1, n, C) çš„ç‰¹å¾å›¾å¼ é‡åˆ—è¡¨ã€‚  eg. [(1,300,C), (1,62,C)...]
        - fusion_func: Callable, è‡ªå®šä¹‰èåˆå‡½æ•°, æ¥å—è¾“å…¥ (n, k, C)ï¼Œè¿”å›èåˆåçš„å¼ é‡ (n, 1, C),
                    å…¶ä¸­ k è¡¨ç¤ºå‚ä¸èåˆçš„ç‰¹å¾æ•°é‡ã€‚
        - extra_future: (1, 200, C), egoè‡ªèº«refineäº†500ä¸ªquery, å…¶ä¸­300ä¸ªå‚ä¸èåˆ, å200ä¸ªç”¨äºä»å‰åˆ°åå¡«å……ä¸é‡å çš„å…¶ä»–agentçš„query 
        - extra_index: (1, 200, 1)

        è¿”å›:
        - fused_features: torch.Tensor, èåˆåçš„ç‰¹å¾å¼ é‡, å½¢çŠ¶ä¸º (1, ego_query_num + extra_query_num, C)ã€‚  eg. (1, 300+200, C)
        """
        # æ£€æŸ¥è¾“å…¥åˆæ³•æ€§
        assert len(index_list) == len(feature_list), "ç´¢å¼•åˆ—è¡¨å’Œç‰¹å¾å›¾åˆ—è¡¨é•¿åº¦ä¸ä¸€è‡´"
        
        # ç»Ÿä¸€å¤„ç†ç´¢å¼•ï¼Œè·å–æ‰€æœ‰å”¯ä¸€ç´¢å¼•
        all_indices = torch.cat([idx.squeeze(0) for idx in index_list], dim=0)  # (sum(n), 1)
        # ç›¸åŒçš„ç´¢å¼•æ„å‘³ç€ç›¸åŒçš„ä½ç½®, (n_unique, ) å’Œé€†æ˜ å°„ (sum(n),) è¡¨ç¤ºæ¯ä¸ªå…ƒç´ åœ¨unique_indicesä¸­çš„ä½ç½®
        # FIXME ä»€ä¹ˆæƒ…å†µ? å³ä½¿è®¾ç½®ä¸ç”¨æ’åºï¼Œä½†æ˜¯æœ€åç»“æœä¾ç„¶æ’åºï¼Œæƒ³è¦ç¨³å®šå»é‡ï¼Œåªèƒ½è‡ªå·±å†™æ±‚unique
        # unique_indices, inverse_indices = torch.unique(all_indices, sorted=False, return_inverse=True) 

        seen = set()
        unique_vals = []
        for val in all_indices:
            scalar_val = val.item() # è¿™é‡Œdebugäº†å¥½ä¹…ï¼Œtensorå¯¹è±¡æ˜¯ä¸å¯å“ˆå¸Œçš„ï¼Œæ²¡ææ˜ç™½ç›´æ¥å¯¼è‡´è¿™é‡Œå»é‡å¤±è´¥ï¼Œè¿˜ä¼šå‡ºç°é‡å¤ï¼Œå› æ­¤å¿…é¡»è½¬ä¸ºpythonæ ‡é‡
            if scalar_val not in seen:
                seen.add(scalar_val)
                unique_vals.append(scalar_val)
        unique_indices = torch.tensor(unique_vals).to(all_indices)

        # æ„å»ºæ¯ä¸ªç´¢å¼•å¯¹åº”çš„ç‰¹å¾åˆ—è¡¨
        feature_map = {idx.item(): [] for idx in unique_indices} # eg. {id: [(1, C), ...]}
        for idx, features in zip(index_list, feature_list):
            for i, ind in enumerate(idx.squeeze(0).squeeze(-1)): # éå†æ¯ä¸ªagentçš„ç´¢å¼•
                feature_map[ind.item()].append(features[:, i, :])  # æŒ‰ç´¢å¼•å­˜å…¥ç‰¹å¾ (1, C)

        # å¯¹æ¯ä¸ªå”¯ä¸€ç´¢å¼•è¿›è¡Œèåˆ ç„¶åé‡æ–°æ”¾å›å» å½¢æˆ{unique_id: [feature]}
        fused_features = []  # å­˜å‚¨èåˆåçš„ç‰¹å¾
        for idx in unique_indices:
            features_to_fuse = torch.stack(feature_map[idx.item()], dim=1)  # (1, k, C) åŒä¸€ä¸ªç©ºé—´ä½ç½®æœ‰å¤šä¸ªfeature, å¯èƒ½æ˜¯egoå’Œå…¶ä»–agentï¼Œä¹Ÿå¯èƒ½æ˜¯agentä¹‹é—´
            fused_features.append(fusion_func(features_to_fuse)) # èåˆè¿”å›çš„åº”è¯¥æ˜¯(1, 1, C)
        fused_features = torch.cat(fused_features, dim=1)  # (1, n_unique, C)

        # ä» fused_features ä¸­æå–å±äº ego çš„ç‰¹å¾
        ego_indices = index_list[0].squeeze(0).squeeze(-1)  # ego çš„ç´¢å¼• ï¼ˆn1,ï¼‰ egoçš„ç´¢å¼•ä¸ªæ•°æ˜¯å›ºå®šçš„ï¼Œå°±ç­‰äºquery_num
        ego_mask = torch.isin(unique_indices, ego_indices)  # æ‰¾åˆ°å±äº ego çš„ç´¢å¼• (n_unique, ) egoå¯¹åº”çš„ç´¢å¼•å°±ä¸º True
        ego_features = fused_features[:, ego_mask, :]  # æå–å±äº ego çš„éƒ¨åˆ† (1, ego_query_size, C)

        non_overlap_features = []
        for idx, features in zip(index_list[1:], feature_list[1:]): # å¿½ç•¥ ego
            mask = ~torch.isin(idx.squeeze(0), index_list[0].squeeze(0)) # éé‡å éƒ¨åˆ† (n_unique, 1) XXX é¦–å…ˆå®Œå…¨é‡å ä¸å¯èƒ½ï¼Œé‚£åªæœ‰ä¸€ç§å¯èƒ½ï¼Œé‚£å°±æ˜¯agentå’Œegoæ„ŸçŸ¥èŒƒå›´éƒ½ä¸é‡åˆï¼Œæ‰€ä»¥æ ¹æœ¬å°±æ˜¯ç©º
            selected_features = features[:, mask.squeeze(), :] # æå–éé‡å ç‰¹å¾ (1, k', C)
            if selected_features.size(1) > 0:
                non_overlap_features.append(selected_features)

        # å°†éé‡å ç‰¹å¾æŒ‰åˆ†æ•°æˆªæ–­å¹¶å¡«å……åˆ°æœ€ç»ˆç»“æœä¸­
        if len(non_overlap_features) > 0:
            non_overlap_features = torch.cat(non_overlap_features, dim=1)  # (1, k_all, C)
            append_num = min(non_overlap_features.size(1), self.extra_query_num) # æœ€å¤§ä¸è¶…è¿‡ extra_query_num
            extra_future[:, :append_num, :] = non_overlap_features[:,:append_num,:]
        # else: # é¦–å…ˆèƒ½è¿›å…¥èåˆå‡½æ•°å°±è¯´æ˜æœ‰æŠ•å½±çš„queryå­˜åœ¨ï¼Œç»“æœéé‡å çš„ç‰¹å¾æ˜¯0ï¼Œè¿™å°±è¯´æ˜å…¨éƒ¨æ˜¯é‡å çš„ç‰¹å¾, ç»è¿‡éªŒè¯ï¼Œæ­¤æ—¶æŠ•å½±è¿‡æ¥çš„ç‰¹å¾æ•°é‡å¾ˆå°‘ï¼Œä¸€èˆ¬æ˜¯ä¸ªä½æ•°ï¼Œæå°‘æ•°æ—¶å€™æ˜¯å‡ å
        #     print("------------------------------------------------")
        #     print("Oops! All overlap???")
        #     print("unique_indices shape is ", unique_indices.shape)
        #     print("agent 1 shape is ", index_list[1].shape)
        #     print("------------------------------------------------")

        # æœ€ç»ˆç‰¹å¾: ego + extra_future
        final_features = torch.cat([ego_features, extra_future], dim=1)  # (1, ego_query_size + etra_query_num, C)

        unique_indices = unique_indices.unsqueeze(0).unsqueeze(-1) # (1, n_unique, 1)
        index_num = min(unique_indices.size(1), self.num_queries + self.extra_query_num)
        assert unique_indices.size(1) >= self.num_queries
        remain_start = index_num - self.num_queries
        final_indices = torch.cat([unique_indices[:, :index_num, :], extra_index[:, remain_start:, :]], dim = 1) # 500
        return final_features, final_indices

class TransformerEncoderLayer(nn.Module):
    def __init__(self, d_model, nhead, nlevel, dim_feedforward, dropout, activation):
        super().__init__()
        self.self_attn = Box3dAttention(d_model, nlevel, nhead, with_rotation=False)
        self.linear1 = nn.Linear(d_model, dim_feedforward)
        self.dropout = nn.Dropout(dropout)
        self.linear2 = nn.Linear(dim_feedforward, d_model)
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)

        self.dropout1 = nn.Dropout(dropout)
        self.dropout2 = nn.Dropout(dropout)

        self.activation = get_activation_fn(activation)

    @staticmethod
    def with_pos_embed(tensor, pos):
        return tensor if pos is None else tensor + pos

    def forward(self, src, pos, src_shape, src_start_idx, ref_windows):
        src2 = self.self_attn(
            self.with_pos_embed(src, pos),
            src,
            src_shape,
            None,
            src_start_idx,
            None,
            ref_windows,
        )

        src = src + self.dropout1(src2[0])
        src = self.norm1(src)

        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))
        src = src + self.dropout2(src2)
        src = self.norm2(src)

        return src


class TransformerEncoder(nn.Module):
    def __init__(self, d_model, encoder_layer, num_layers):
        super().__init__()
        self.layers = get_clones(encoder_layer, num_layers)

    def forward(self, src, pos, src_shape, src_start_idx, ref_windows):
        output = src
        for layer in self.layers:
            output = layer(output, pos, src_shape, src_start_idx, ref_windows)
        return output


class TransformerDecoderLayer(nn.Module):
    def __init__(self, d_model, nhead, nlevel, dim_feedforward, dropout, activation):
        super().__init__()
        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)
        self.multihead_attn = Box3dAttention(d_model, nlevel, nhead, with_rotation=True)

        self.pos_embed_layer = MLP(8, d_model, d_model, 3)

        self.linear1 = nn.Linear(d_model, dim_feedforward)
        self.linear2 = nn.Linear(dim_feedforward, d_model)
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.norm3 = nn.LayerNorm(d_model)

        self.dropout = nn.Dropout(dropout)
        self.dropout = nn.Dropout(dropout)
        self.dropout1 = nn.Dropout(dropout)
        self.dropout2 = nn.Dropout(dropout)
        self.dropout3 = nn.Dropout(dropout)

        self.activation = get_activation_fn(activation)

    @staticmethod
    def with_pos_embed(tensor, pos):
        return tensor if pos is None else tensor + pos

    def forward(self, idx, query, query_pos, memory, memory_shape, memory_start_idx, ref_windows, attn_mask=None):
        if idx == 0:
            query = self.pos_embed_layer(ref_windows)
            q = k = query
        elif query_pos is None:
            query_pos = self.pos_embed_layer(ref_windows)
            q = k = self.with_pos_embed(query, query_pos)

        q = q.transpose(0, 1)
        k = k.transpose(0, 1)
        v = query.transpose(0, 1)

        query2 = self.self_attn(q, k, v, attn_mask=attn_mask)[0]
        query2 = query2.transpose(0, 1)
        query = query + self.dropout1(query2)
        query = self.norm1(query)

        query2 = self.multihead_attn(
            self.with_pos_embed(query, query_pos),
            memory,
            memory_shape,
            None,
            memory_start_idx,
            None,
            ref_windows[..., :7],
        )[0]

        query = query + self.dropout2(query2)
        query = self.norm2(query)

        query2 = self.linear2(self.dropout(self.activation(self.linear1(query))))
        query = query + self.dropout3(query2)
        query = self.norm3(query)

        return query


class TransformerDecoder(nn.Module):
    def __init__(self, d_model, decoder_layer, num_layers, cp_flag):
        super().__init__()

        self.layers = get_clones(decoder_layer, num_layers)
        self.cp_flag = cp_flag # True
        if self.cp_flag:
            print("===ä½¿ç”¨checkpointä¼˜åŒ–å†…å­˜, ä½†æ˜¯ä¼šé™ä½è®­ç»ƒé€Ÿåº¦===")

    def forward(self, query, query_pos, memory, memory_shape, memory_start_idx, ref_windows, attn_mask=None, return_bboxes=False):
        output = query
        intermediate = []
        intermediate_ref_windows = []
        bboxes_per_layer = []
        for idx, layer in enumerate(self.layers):
            if self.cp_flag:
                output = cp.checkpoint(layer, idx, output, query_pos, memory, memory_shape, memory_start_idx, ref_windows, attn_mask)
            else:
                output = layer(idx, output, query_pos, memory, memory_shape, memory_start_idx, ref_windows, attn_mask)
            new_ref_logits, new_ref_windows = self.detection_head(output, ref_windows[..., :7], idx)
            new_ref_probs = new_ref_logits.sigmoid()
            ref_windows = torch.cat(
                (
                    new_ref_windows.detach(),
                    new_ref_probs.detach(),
                ),
                dim=-1,
            )
            intermediate.append(output)
            intermediate_ref_windows.append(new_ref_windows)
            if return_bboxes:
                res_boxes = torch.cat(
                    (
                        new_ref_windows.detach(),
                        new_ref_probs.detach(),
                    ),
                    dim=-1,
                )
                bboxes_per_layer.append(res_boxes)
        if return_bboxes:
            return torch.stack(intermediate), torch.stack(intermediate_ref_windows), torch.stack(bboxes_per_layer)
        return torch.stack(intermediate), torch.stack(intermediate_ref_windows)

class TransAdapt(nn.Module):
    def __init__(self, d_model, nhead, nlevel, dim_feedforward, dropout, activation):
        super().__init__()
        self.multihead_attn = Box3dAttention(d_model, nlevel, nhead, with_rotation=True)

        self.pos_embed_layer = MLP(8, d_model, d_model, 3)

        self.linear1 = nn.Linear(d_model, dim_feedforward)
        self.linear2 = nn.Linear(dim_feedforward, d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.norm3 = nn.LayerNorm(d_model)

        self.dropout = nn.Dropout(dropout)
        self.dropout2 = nn.Dropout(dropout)
        self.dropout3 = nn.Dropout(dropout)

        self.activation = get_activation_fn(activation)

    @staticmethod
    def with_pos_embed(tensor, pos):
        return tensor if pos is None else tensor + pos

    def forward(self, query, memory, memory_shape, memory_start_idx, ref_windows):
        '''
        query: (1, n, C)
        memory: (1, HW, C)
        memory_shape: (1,2)
        memory_start_idx: (0,)
        ref_windows: (1, n, 8)
        '''
        if query.size(1) == 0: # å¦‚æœå…¶ä»–agentçš„queryæ•°æ˜¯0ï¼Œé‚£å°±ç›´æ¥returnå³å¯
            return query
        query_pos = self.pos_embed_layer(ref_windows)

        query2 = self.multihead_attn(
            self.with_pos_embed(query, query_pos),
            memory,
            memory_shape,
            None,
            memory_start_idx,
            None,
            ref_windows[..., :7],
        )[0]

        query = query + self.dropout2(query2)
        query = self.norm2(query)

        query2 = self.linear2(self.dropout(self.activation(self.linear1(query))))
        query = query + self.dropout3(query2)
        query = self.norm3(query)

        return query


def get_clones(module, N):
    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])


def get_activation_fn(activation):
    """Return an activation function given a string"""
    if activation == "relu":
        return F.relu
    if activation == "gelu":
        return F.gelu
    if activation == "glu":
        return F.glu
    raise RuntimeError(f"activation should be relu/gelu, not {activation}.")


def flatten_with_shape(tensor_list, mask_list):
    """
    Params:
    :tensor_list: [(B, C, H1, W1), ..., (B, C, HN, WN)]
    :mask_list: [(B, H1, W1), ..., (B, HN, WN)]

    Return:
    :tensor_flatten: (B, L, C)
    :mask_flatten: (B, L)
    :tensor_shape: (N, 2)
    """
    assert isinstance(tensor_list, collections.abc.Sequence)
    assert len(tensor_list) > 0

    N = len(tensor_list) # 1
    tensor_shape = torch.zeros(N, 2, dtype=torch.int64, device=tensor_list[0].device) # (1, 2)
    tensor_flatten = []

    if mask_list is not None:
        mask_flatten = []

    for i, tensor in enumerate(tensor_list):
        new_tensor = tensor.flatten(2).permute(0, 2, 1) # å±•å¹³æˆï¼ˆBï¼ŒH*Wï¼ŒCï¼‰
        tensor_flatten.append(new_tensor)

        if mask_list is not None:
            mask = mask_list[i]
            new_mask = mask.flatten(1)
            mask_flatten.append(new_mask)
            assert tensor.shape[2] == mask.shape[1]
            assert tensor.shape[3] == mask.shape[2]
        tensor_shape[i, 0] = tensor.shape[2]
        tensor_shape[i, 1] = tensor.shape[3]

    mask_flatten = torch.cat(mask_flatten, dim=1) if mask_list is not None else None # (B, L)
    tensor_flatten = torch.cat(tensor_flatten, dim=1)

    return tensor_flatten, mask_flatten, tensor_shape

class TransformerFeature(nn.Module):
    def __init__(
        self,
        d_model=256,
        nhead=8,
        nlevel=1,
        num_encoder_layers=6,
        num_decoder_layers=6,
        dim_feedforward=1024,
        dropout=0.1,
        activation="relu",
        num_queries=300,
        num_classes=1,
        mom=0.999,
        cp_flag=False,
        box_encode_func=None, 
        box_decode_func=None, 
        get_sparse_features_func=None
    ):
        super().__init__()

        self.num_queries = num_queries
        self.num_classes = num_classes
        self.m = mom

        self.box_encode_func=box_encode_func
        self.box_decode_func=box_decode_func
        self.get_sparse_features_func=get_sparse_features_func

        encoder_layer = TransformerEncoderLayer(d_model, nhead, nlevel, dim_feedforward, dropout, activation)
        self.encoder = TransformerEncoder(d_model, encoder_layer, num_encoder_layers)
        self.fused_encoder = TransformerEncoder(d_model, encoder_layer, num_encoder_layers)
        self.foreground_fusion = MaxFusion()
        decoder_layer = TransformerDecoderLayer(d_model, nhead, nlevel, dim_feedforward, dropout, activation)
        self.decoder = TransformerDecoder(d_model, decoder_layer, num_decoder_layers, cp_flag)
        self.sample_idx = 0

    def _create_ref_windows(self, tensor_list):
        device = tensor_list[0].device

        ref_windows = []
        for tensor in tensor_list:
            B, _, H, W = tensor.shape
            ref_y, ref_x = torch.meshgrid(
                torch.linspace(0.5, H - 0.5, H, dtype=torch.float32, device=device),
                torch.linspace(0.5, W - 0.5, W, dtype=torch.float32, device=device),
                indexing="ij",
            )

            ref_y = ref_y.reshape(-1)[None] / H
            ref_x = ref_x.reshape(-1)[None] / W
            ref_xy = torch.stack((ref_x, ref_y), -1)
            ref_wh = torch.ones_like(ref_xy) * 0.025  # 0.01 - 0.05 w.r.t. Deform-DETR
            placeholder = torch.zeros_like(ref_xy)[..., :1]
            ref_box = torch.cat((ref_xy, placeholder + 0.5, ref_wh, placeholder + 0.5, placeholder), -1).expand(
                B, -1, -1
            )

            ref_windows.append(ref_box)
        ref_windows = torch.cat(ref_windows, dim=1)

        return ref_windows

    def _get_enc_proposals(self, enc_embed, ref_windows, indexes=None):
        B, L = enc_embed.shape[:2]
        out_logits, out_ref_windows = self.proposal_head(enc_embed, ref_windows)

        out_probs = out_logits[..., 0].sigmoid()
        topk_probs, indexes = torch.topk(out_probs, self.num_queries, dim=1, sorted=False) # ä¸æ’åºï¼Œæ‹…å¿ƒè¿™æˆä¸ºä¸€ç§å…ˆéªŒçŸ¥è¯†è¢«å­¦åˆ°
        topk_probs = topk_probs.unsqueeze(-1)
        indexes = indexes.unsqueeze(-1)
        # print("out_probs  is ", [round(x, 3) for x in out_probs[0][:1000].tolist()])

        out_ref_windows = torch.gather(out_ref_windows, 1, indexes.expand(-1, -1, out_ref_windows.shape[-1]))
        out_ref_windows = torch.cat(
            (
                out_ref_windows.detach(),
                topk_probs.detach().expand(-1, -1, out_logits.shape[-1]),
            ),
            dim=-1,
        )

        out_pos = None
        out_embed = None

        return out_embed, out_pos, out_ref_windows, indexes

    @torch.no_grad()
    def _momentum_update_gt_decoder(self):
        """
        Momentum update of the key encoder
        """
        for param_q, param_k in zip(self.decoder.parameters(), self.decoder_gt.parameters()):
            param_k.data = param_k.data * self.m + param_q.data * (1.0 - self.m)

    def regroup(self, x, record_len):
        cum_sum_len = torch.cumsum(record_len, dim=0)
        split_x = torch.tensor_split(x, cum_sum_len[:-1].cpu())
        return split_x

    def forward(self, src, pos, noised_gt_box=None, noised_gt_onehot=None, attn_mask=None, targets=None, valid_bboxes_single = None, record_len=None, pairwise_t_matrix=None, pairwise_t_matrix_ref=None, score_mask=None):
        '''
        é€šä¿¡ä½¿ç”¨ç¨€ç–ç‰¹å¾å›¾,å…ˆåšèåˆå†èµ°ConQueRçš„pipeline, æµç¨‹ä¸º:
        âš¡ï¸æ–¹æ¡ˆä¸€ éœ€è¦é¢å¤–å»ºç«‹ç¬¬äºŒæ¬¡Encoderçš„æŸå¤± undo
        1ï¸âƒ£ æ‰€æœ‰Featureä¸€èµ·ç»è¿‡Encoder å¾—åˆ°åˆæ­¥ROIåŒºåŸŸ 2ï¸âƒ£ åˆ©ç”¨ROIåŒºåŸŸå½¢æˆä¼ªå›¾å»æˆªå–åˆå§‹çš„Feature å†åˆ©ç”¨MaxFusionèåˆå…¥Ego Feature è¿™å°±å½¢æˆäº†ååŒFeature
        3ï¸âƒ£ åŸºäºååŒFeature é‡æ–°èµ° ConQueR
        âš¡ï¸ æ–¹æ¡ˆäºŒ éœ€è¦ç›‘ç£mask
        1ï¸âƒ£ æ‰€æœ‰çš„Featureå…¨éƒ¨é¢„æµ‹å‰æ™¯Mask 2ï¸âƒ£ åˆ©ç”¨maskæ¥å½¢æˆç¨€ç–çš„Featureå¹¶ç”¨MAXFusionåˆå…¥ego 3ï¸âƒ£ ç›‘ç£è‡ªè½¦
        src: [(B_n, 256, H, W)]
        pos: [(B_n, 256, H, W)]
        noised_gt_box: (B, pad_size, 7)  è¿™é‡Œç”¨çš„åº”è¯¥æ˜¯ååŒgt
        noised_gt_onehot: (B, pad_size, num_classes)
        attn_mask: (1000+pad_size, 1000+pad_size)
        targets: [{'gt_boxes': (N, 7), 'labels': (N, )}, ...]
        '''
        assert pos is not None, "position encoding is required!"
        src_anchors = self._create_ref_windows(src) # åˆ›é€ å‚è€ƒæ¡†ï¼Œè¿™ä¸ªæ˜¯BoxAttentionå¿…é¡»çš„ (B_n, HW, 7)
        src, _, src_shape = flatten_with_shape(src, None)# å±•å¹³ç‰¹å¾å›¾ï¼Œè¿”å›çš„æ˜¯ (B_n, H*W, 256), None, (1, 2) æœ€åä¸€é¡¹è®°å½•ç€Hï¼ŒW å³feature shape
        src_pos = []
        for pe in pos:
            B, C = pe.shape[:2]
            pe = pe.view(B, C, -1).transpose(1, 2) # b, h*w, c
            src_pos.append(pe)
        src_pos = torch.cat(src_pos, dim=1) # (B_n, H*W, C)
        src_start_index = torch.cat([src_shape.new_zeros(1), src_shape.prod(1).cumsum(0)[:-1]]) # è¿™æ˜¯ä¸ºäº†ç”Ÿæˆåˆ’åˆ†çš„ç´¢å¼•ï¼ŒåŒºåˆ†æ¯ä¸ªç‰¹å¾å›¾çš„ä½ç½®ï¼Œç”±äºåªæœ‰ä¸€ä¸ªç‰¹å¾å›¾ï¼Œæ‰€ä»¥ç»“æœæ˜¯(0,)
        score_mask = score_mask.flatten(-2) # (B_n, H*W)
        
        thresholds = torch.quantile(score_mask, 0.7, dim=1, keepdim=True) # æ±‚70%çš„åˆ†ä½æ•°
        # thresholds = 0.1
        score_mask = score_mask >= thresholds
        score_mask = score_mask.unsqueeze(-1).expand_as(src)
        src_sparse = src * score_mask # (B_n, H*W, C)

        H, W = src_shape[0,0], src_shape[0,1]
        src_sparse = src_sparse.permute(0, 2, 1).reshape(src.shape[0], src.shape[-1], H, W) # (B_n, C, H, W)

        src_batch_lst = self.regroup(src, record_len)
        src_sparse_batch_lst = self.regroup(src_sparse, record_len)
        fused_features = []
        for b_i in range(len(src_batch_lst)):
            N = record_len[b_i] # number of valid agent
            src_b = src_batch_lst[b_i] # (N, HW, C)
            src_sparse_b = src_sparse_batch_lst[b_i] # (N, C, H, W)
            t_matrix = pairwise_t_matrix[b_i][:N, :N, :, :] # (N, N, 2, 3)
            neighbor_src_sparse_b = warp_affine_simple(src_sparse_b, t_matrix[0, :, :, :], (H, W), mode='bilinear') # (N, C, H, W)
            neighbor_src_sparse_b = neighbor_src_sparse_b.flatten(2).permute(0, 2, 1) # (N, HW, C) 
            early_features = torch.cat([src_b[:1], neighbor_src_sparse_b[1:]], dim=0)
            early_ego_features = self.foreground_fusion(early_features) # (1, H*W, C)
            fused_features_b = torch.cat([early_ego_features[:1], src_b[1:]], dim=0) # TODO è¿™é‡Œæœ‰é—®é¢˜ ä¸åº”è¯¥cat æŠ•å½±åçš„ç‰¹å¾ NOTE ğŸŒŸDone
            fused_features.append(fused_features_b)
        fused_features = torch.cat(fused_features, dim=0)
        memory = self.encoder(fused_features, src_pos, src_shape, src_start_index, src_anchors) # BoxAttention æå–ç‰¹å¾ ç»“æœä¸º(B_n, H*W, 256)
        query_embed, query_pos, topk_proposals, topk_indexes = self._get_enc_proposals(memory, src_anchors) # è¿”å›Noneï¼ŒNoneï¼Œ(B_n, query_num+extra_num, 8)ï¼Œ(B_n, query_num+extra_num, 1)

        memory_batch_lst = self.regroup(memory, record_len)
        topk_proposals_batch_lst = self.regroup(topk_proposals, record_len)
        # memory_batch_lst = self.regroup(memory, record_len)
        ego_memory = []
        ego_topk_proposals = []
        for b_i in range(len(memory_batch_lst)):
            ego_memory.append(memory_batch_lst[b_i][0:1])
            ego_topk_proposals.append(topk_proposals_batch_lst[b_i][0:1])
        ego_memory = torch.cat(ego_memory, dim=0) # (B, HW, C)
        ego_topk_proposals = torch.cat(ego_topk_proposals, dim=0) # (B, query_numï¼Œ 8)
        
        # H, W = src_shape[0,0], src_shape[0,1]

        # src_sparse = src # (B_n, H*W, 256)
        # if valid_bboxes_single is not None:
        #     rois_lst = valid_bboxes_single # [N1, N2, N3, N4] æ¯ä¸ªåœºæ™¯ä¸­æ¯ä¸ªsingleçš„bbx
        #     src_raw = src.permute(0, 2, 1).reshape(memory.shape[0], memory.shape[-1], H, W)
        #     src_sparse = self.get_sparse_features_func(src_raw, rois_lst) # (B_n, 256, H, W)
        #     # src_sparse = src_sparse.flatten(2).permute(0, 2, 1)

        # early_feature_lst = self.regroup(src, record_len)
        # src_sparse_lst = self.regroup(src_sparse, record_len)
        # src_anchors_lst = self.regroup(src_anchors, record_len)
        # src_pos_lst = self.regroup(src_pos, record_len)
        # early_feature = []
        # ego_anchors = []
        # ego_pos = []
        # for b_i in range(len(early_feature_lst)):
        #     N = record_len[b_i] # number of valid agent
            

        #     t_matrix = pairwise_t_matrix[b_i][:N, :N, :, :] # (N, N, 2, 3)
        #     early_feature_b = early_feature_lst[b_i] # (N, H*W, 256)
        #     src_sparse_b = src_sparse_lst[b_i] # (N, 256, H, W)
        #     src_anchors_b = src_anchors_lst[b_i]
        #     src_pos_b = src_pos_lst[b_i] # (N, H*W, 256)

        #     neighbor_src_sparse_b = warp_affine_simple(src_sparse_b, t_matrix[0, :, :, :], (H, W), mode='bilinear') # (N, C, H, W)
        #     neighbor_src_sparse_b = neighbor_src_sparse_b.flatten(2).permute(0, 2, 1) # (N, HW, C) 

        #     if early_feature_b.size(0) != 1: # å°†å…¶ä»–agentçš„featureè½¬ä¸ºç¨€ç–
        #         early_feature_ego_b = torch.cat([early_feature_b[:1], neighbor_src_sparse_b[1:]], dim=0)
        #         early_feature_ego_b = self.foreground_fusion(early_feature_ego_b) # (1, H*W, C)
        #     else:
        #         early_feature_ego_b = early_feature_b

        #     early_feature.append(early_feature_ego_b)
        #     ego_anchors.append(src_anchors_b[0:1])
        #     ego_pos.append(src_pos_b[0:1])
        # early_feature = torch.cat(early_feature, dim=0) # (B,  H*W, 256)  åªæœ‰egoçš„feature èåˆäº†æ¥è‡ªå…¶ä»–agentçš„feature
        # ego_anchors = torch.cat(ego_anchors, dim=0) # (B, HW, 7)  åªæœ‰egoçš„feature èåˆäº†æ¥è‡ªå…¶ä»–agentçš„feature
        # ego_pos = torch.cat(ego_pos, dim=0) # (B, HW, 256)  åªæœ‰egoçš„feature èåˆäº†æ¥è‡ªå…¶ä»–agentçš„feature

        # ego_memory = self.encoder(early_feature, ego_pos, src_shape, src_start_index, ego_anchors) # BoxAttention æå–ç‰¹å¾ ç»“æœä¸º(B, H*W, 256)
        # query_embed, query_pos, ego_topk_proposals, ego_topk_indexes = self._get_enc_proposals(ego_memory, ego_anchors) # è¿”å›Noneï¼ŒNoneï¼Œ(B, query_num+extra_num, 8)ï¼Œ(B, query_num+extra_num, 1)
     
        # åŠ å™ªå£°gtï¼Œå‡†å¤‡ä¸€èµ·å‚ä¸decoderè®­ç»ƒå»å™ª
        if noised_gt_box is not None:
            noised_gt_proposals = torch.cat(
                (
                    noised_gt_box,
                    noised_gt_onehot,
                ),
                dim=-1,
            ) # (B, pad_size, 8)
            ego_topk_proposals = torch.cat(
                (
                    noised_gt_proposals,
                    ego_topk_proposals,
                ),
                dim=1,
            ) # (B, pad_size + all_query_num, 8) while: all_query_num == query_num+extra_num
        init_reference_out = ego_topk_proposals[..., :7]

        # hs, inter_references = self.decoder_gt(
        hs, inter_references = self.decoder(
            query_embed, # None
            query_pos, # None
            ego_memory, # BoxAttention æå–ç‰¹å¾åç»“åˆå¤šagentåçš„Feature Map ç»“æœä¸º(B, H*W, 256)
            src_shape, # (1, 2)
            src_start_index, # (0,)
            ego_topk_proposals, # (B, all_query_num, 8)
            attn_mask,
        ) # (3, B, pad_size + all_query_num, 256) æ¯ä¸€å±‚çš„è¾“å‡ºçš„queryç‰¹å¾ï¼Œ (3ï¼Œ B, pad_size + all_query_num, 7) æ¯ä¸€å±‚çš„æ£€æµ‹ç»“æœ

        # optional gt forward å¯¹æ¯”å­¦ä¹ éœ€è¦ç”¨åˆ°çš„åŠ¨é‡æ›´æ–°æ¨¡å‹ç”¨åŠ å™ªgtæ¥åšå¯¹æ¯”å­¦ä¹ çš„
        if targets is not None:
            batch_size = len(targets) # è¿™é‡Œæ˜¯ååŒæ ‡ç­¾
            per_gt_num = [tgt["gt_boxes"].shape[0] for tgt in targets] # [N1, N2, N3, N4] æ­¤ä¸ºB=4æ—¶çš„å„ä¸ªæ ·æœ¬çš„GTæ•°
            max_gt_num = max(per_gt_num)
            batched_gt_boxes_with_score = memory.new_zeros(batch_size, max_gt_num, 8) # (B, max_gt_num, 8)
            for bi in range(batch_size):
                batched_gt_boxes_with_score[bi, : per_gt_num[bi], :7] = targets[bi]["gt_boxes"] # æ”¾å…¥gtçš„box å’Œ one-hot åˆ†ç±»ç¼–ç 
                batched_gt_boxes_with_score[bi, : per_gt_num[bi], 7:] = F.one_hot(
                    targets[bi]["labels"], num_classes=self.num_classes
                )

            with torch.no_grad():
                self._momentum_update_gt_decoder() # åŠ¨é‡æ›´æ–°è¾…åŠ©æ¨¡å‹ï¼Œå…¶å‚æ•°æ›´æ–°é€Ÿåº¦éå¸¸ç¼“æ…¢ï¼Œä½†ä¸€ç›´è¿½éšdecoder
                if noised_gt_box is not None:
                    dn_group_num = noised_gt_proposals.shape[1] // (max_gt_num * 2) # å¾—åˆ°å»å™ªgtç»„æ•° == 3  2æŒ‡çš„æ˜¯æ¯ä¸€ç»„åˆåˆ†æ­£è´Ÿæ ·æœ¬
                    pos_idxs = list(range(0, dn_group_num * 2, 2))
                    pos_noised_gt_proposals = torch.cat(
                        [noised_gt_proposals[:, pi * max_gt_num : (pi + 1) * max_gt_num] for pi in pos_idxs],
                        dim=1,
                    ) # æ¯ä¸€ç»„æŠ½å–max_gt_numä¸ª (B, 3*max_gt_num, 8) è¿™æ˜¯ç›¸å½“äºå»å™ªæ­£æ ·æœ¬æŠ½å–å‡ºæ¥
                    gt_proposals = torch.cat((batched_gt_boxes_with_score, pos_noised_gt_proposals), dim=1)
                    # create attn_mask for gt groups
                    gt_attn_mask = memory.new_ones(
                        (dn_group_num + 1) * max_gt_num, (dn_group_num + 1) * max_gt_num
                    ).bool()  # ï¼ˆ4*max_gt_numï¼Œ4*max_gt_numï¼‰å…¨True
                    for di in range(dn_group_num + 1): # å¯¹è§’éƒ¨åˆ†mask å…¨éƒ¨è®¾ç½®ä¸ºFalseï¼Œç›¸å½“äºè¯´åªå…³æ³¨è‡ªå·±ï¼Œå³æ¯ä¸€æ‰¹gtï¼Œæ— è®ºæœ‰æ— å™ªå£°ï¼Œä»…å…³æ³¨è‡ªèº«ï¼Œå±è”½ç»„ä¹‹é—´çš„å¯è§æ€§
                        gt_attn_mask[
                            di * max_gt_num : (di + 1) * max_gt_num,
                            di * max_gt_num : (di + 1) * max_gt_num,
                        ] = False
                else:
                    gt_proposals = batched_gt_boxes_with_score
                    gt_attn_mask = None

                hs_gt, inter_references_gt = self.decoder_gt( # è¾…åŠ©æ¨¡å‹è¿›è¡Œå¯¹æ¯”å­¦ä¹ ï¼Œç¼“æ…¢è¿½éšdecoderã€‚ è¿”å› (3ï¼ŒB, 4*max_gt_num, 256) ä¸ (3ï¼ŒB, 4*max_gt_num, 8)
                    None,
                    None,
                    ego_memory, # BoxAttention æå–ç‰¹å¾åç»“åˆå¤šagentåçš„Feature Map ç»“æœä¸º(B, H*W, 256)
                    src_shape, # (1, 2)
                    src_start_index, # (0,)
                    gt_proposals, # (B, 4*max_gt_num, 8)
                    gt_attn_mask, #ï¼ˆ4*max_gt_numï¼Œ4*max_gt_numï¼‰
                )

            init_reference_out = torch.cat(
                (
                    init_reference_out,
                    gt_proposals[..., :7],
                ),
                dim=1,
            ) # (B, pad_size + all_query_num + 4*max_gt_num, 8) while: all_query_num == query_num+extra_num è¾“å…¥decoderå‰çš„ref window

            hs = torch.cat(
                (
                    hs,
                    hs_gt,
                ),
                dim=2,
            ) # (3, B, pad_size + all_query_num + 4*max_gt_num, 256) æ¯ä¸€å±‚Decoder layerçš„è¾“å‡ºquery
            inter_references = torch.cat(
                (
                    inter_references,
                    inter_references_gt,
                ),
                dim=2,
            ) # (3ï¼Œ B, pad_size + all_query_num + 4*max_gt_num, 7) æ¯ä¸€å±‚Decoder layerçš„å¯¹åº”æ£€æµ‹ç»“æœ

        inter_references_out = inter_references
        '''
        ä»å‰å¾€åä¾æ¬¡è¿”å›: Decoder layeræ¯ä¸€å±‚çš„query, è¾“å…¥Decoderçš„å‚è€ƒæ¡†, Decoder layeræ¯ä¸€å±‚çš„æ£€æµ‹ç»“æœ, Encoderè¾“å‡ºçš„ç‰¹å¾å›¾, åˆå§‹åŒ–çš„å‚è€ƒæ¡†, egoçš„æœ€é«˜query_numçš„ç´¢å¼•
        TODO Encoderè¾“å‡ºçš„ç‰¹å¾å›¾ä¿¡æ¯ä¼šä¸ä¼šä¸è¶³? è¦ä¸è¦è€ƒè™‘å°†queryèåˆåçš„ä¿¡æ¯æ”¾å›å» ğŸŒŸUpdated: Done, å…ˆçœ‹çœ‹æ€§èƒ½
        '''
        return hs, init_reference_out, inter_references_out, memory, src_anchors, topk_indexes
    

class TransformerInstance(nn.Module):
    def __init__(
        self,
        d_model=256,
        nhead=8,
        nlevel=1,
        num_encoder_layers=6,
        num_decoder_layers=6,
        dim_feedforward=1024,
        dropout=0.1,
        activation="relu",
        num_queries=300,
        num_classes=1,
        mom=0.999,
        cp_flag=False,
        box_encode_func=None, 
        box_decode_func=None, 
        get_sparse_features_func=None,
    ):
        super().__init__()

        self.num_queries = num_queries
        self.num_classes = num_classes
        self.m = mom

        self.box_encode_func=box_encode_func
        self.box_decode_func=box_decode_func
        self.get_sparse_features_func=get_sparse_features_func

        encoder_layer = TransformerEncoderLayer(d_model, nhead, nlevel, dim_feedforward, dropout, activation)
        self.encoder = TransformerEncoder(d_model, encoder_layer, num_encoder_layers)
        # self.trans_adapter = TransAdapt(d_model, nhead, nlevel, dim_feedforward, dropout, activation)
        # self.query_fusion = SimpleGatingFusion()
        # self.ref_fusion = BoxGatingFusion()
        # self.foreground_fusion = MaxFusion()
        decoder_layer = TransformerDecoderLayer(d_model, nhead, nlevel, dim_feedforward, dropout, activation)
        self.decoder = TransformerDecoder(d_model, decoder_layer, num_decoder_layers, cp_flag)
        self.group_atten = GroupAttention(d_model)

        self.agent_embed = nn.Parameter(torch.Tensor(2, d_model))
        self.pos_embed_layer = MLP(8, d_model, d_model, 3)
        self.sample_idx = 0
        self.parameters_fix()

    def parameters_fix(self):
        for p in self.encoder.parameters():
            p.requires_grad = False
        for p in self.decoder.parameters():
            p.requires_grad = False


    def _create_ref_windows(self, tensor_list):
        device = tensor_list[0].device

        ref_windows = []
        for tensor in tensor_list:
            B, _, H, W = tensor.shape
            ref_y, ref_x = torch.meshgrid(
                torch.linspace(0.5, H - 0.5, H, dtype=torch.float32, device=device),
                torch.linspace(0.5, W - 0.5, W, dtype=torch.float32, device=device),
                indexing="ij",
            )

            ref_y = ref_y.reshape(-1)[None] / H
            ref_x = ref_x.reshape(-1)[None] / W
            ref_xy = torch.stack((ref_x, ref_y), -1)
            ref_wh = torch.ones_like(ref_xy) * 0.025  # 0.01 - 0.05 w.r.t. Deform-DETR
            placeholder = torch.zeros_like(ref_xy)[..., :1]
            ref_box = torch.cat((ref_xy, placeholder + 0.5, ref_wh, placeholder + 0.5, placeholder), -1).expand(
                B, -1, -1
            )

            ref_windows.append(ref_box)
        ref_windows = torch.cat(ref_windows, dim=1)

        return ref_windows

    def _get_enc_proposals(self, enc_embed, ref_windows, indexes=None, heatmap=None):
        B, L = enc_embed.shape[:2]
        out_logits, out_ref_windows = self.proposal_head(enc_embed, ref_windows)

        out_probs = out_logits[..., 0].sigmoid()
        topk_probs, indexes = torch.topk(out_probs, self.num_queries, dim=1, sorted=False)
        topk_probs = topk_probs.unsqueeze(-1)
        indexes = indexes.unsqueeze(-1)
        # print("out_probs  is ", [round(x, 3) for x in out_probs[0][:1000].tolist()])

        out_ref_windows = torch.gather(out_ref_windows, 1, indexes.expand(-1, -1, out_ref_windows.shape[-1]))
        out_ref_windows = torch.cat(
            (
                out_ref_windows.detach(),
                topk_probs.detach().expand(-1, -1, out_logits.shape[-1]),
            ),
            dim=-1,
        )

        out_pos = None
        out_embed = None

        return out_embed, out_pos, out_ref_windows, indexes

    # def _get_enc_proposals(self, enc_embed, ref_windows, indexes=None, heatmap=None):
    #     """
    #     æ ¹æ® heatmap é¢„å…ˆç­›é€‰ proposalsï¼Œå¹¶ä» logits ä¸­é€‰å–æœ€ç»ˆçš„ queriesï¼Œè¿”å›åŸå§‹ heatmap çš„ HW ç´¢å¼•ã€‚

    #     Args:
    #         enc_embed: ç¼–ç çš„åµŒå…¥å‘é‡ï¼Œå½¢çŠ¶ä¸º [B, L, C]
    #         ref_windows: å‚è€ƒçª—å£ï¼Œå½¢çŠ¶ä¸º [B, L, 4]
    #         indexes: ç”¨äºæ ‡è¯†æŸäº›å…ƒç´ çš„ç´¢å¼•ï¼ˆå¯é€‰ï¼‰
    #         heatmap: çƒ­å›¾ï¼Œå½¢çŠ¶ä¸º [B, 1, H, W]

    #     Returns:
    #         out_embed: ç­›é€‰åçš„åµŒå…¥å‘é‡ï¼ˆæœªè®¾ç½®é€»è¾‘ï¼Œè¿”å› Noneï¼‰
    #         out_pos: ç­›é€‰åçš„ä½ç½®ç¼–ç ï¼ˆæœªè®¾ç½®é€»è¾‘ï¼Œè¿”å› Noneï¼‰
    #         out_ref_windows: ç­›é€‰åçš„å‚è€ƒçª—å£
    #         hw_indexes: ç­›é€‰åçš„åŸå§‹ heatmap HW ç´¢å¼•
    #     """
    #     B, L = enc_embed.shape[:2]
    #     H, W = heatmap.shape[-2:]

    #     # é€šè¿‡ proposal_head è·å–é¢„æµ‹ logits å’Œå‚è€ƒçª—å£
    #     out_logits, out_ref_windows = self.proposal_head(enc_embed, ref_windows)

    #     # Step 1: ä» heatmap ä¸­ç­›é€‰å‡ºé«˜æ¦‚ç‡åŒºåŸŸï¼Œå¹¶ä¿ç•™ HW ç´¢å¼•
    #     heatmap_flat = heatmap.view(B, -1)  # [B, H*W]
    #     top_proposals = heatmap_flat.argsort(dim=-1, descending=True)[..., :self.num_queries * 2]  # ä¿ç•™ 2 å€æ•°é‡
    #     hw_indexes = top_proposals  # ä¿å­˜åŸå§‹ HW ç´¢å¼• (B, 2*num_queries)

    #     # åˆ©ç”¨ HW ç´¢å¼•ä» heatmap_flat æå–æ¦‚ç‡ï¼Œç­›é€‰ logits å’Œ ref_windows
    #     filtered_logits = torch.gather(out_logits, 1, top_proposals.unsqueeze(-1).expand(-1, -1, out_logits.shape[-1]))
    #     filtered_ref_windows = torch.gather(ref_windows, 1, top_proposals.unsqueeze(-1).expand(-1, -1, ref_windows.shape[-1]))

    #     # Step 2: åœ¨ç­›é€‰åçš„ proposals ä¸­ï¼Œè¿›ä¸€æ­¥ç­›é€‰ num_queries ä¸ª
    #     out_probs = filtered_logits[..., 0].sigmoid()
    #     topk_probs, indexes = torch.topk(out_probs, self.num_queries, dim=1, sorted=False) # (B, num_queries)  both shape

    #     # è·å–æœ€ç»ˆçš„ HW ç´¢å¼•
    #     final_hw_indexes = torch.gather(hw_indexes, 1, indexes)  # ä»åŸå§‹ HW ç´¢å¼•ä¸­æå–æœ€ç»ˆçš„ topk
    #     topk_probs = topk_probs.unsqueeze(-1)  # å¢åŠ æœ€åä¸€ç»´

    #     # print("filtered_ref_windows shape is ", filtered_ref_windows.shape)
    #     # print("indexes shape is ", indexes.shape)
    #     # è·å–å‚è€ƒçª—å£çš„æœ€ç»ˆå†…å®¹
    #     out_ref_windows = torch.gather(filtered_ref_windows, 1, indexes.unsqueeze(-1).expand(-1, -1, filtered_ref_windows.shape[-1]))
    #     out_ref_windows = torch.cat(
    #         (
    #             out_ref_windows.detach(),
    #             topk_probs.detach().expand(-1, -1, filtered_logits.shape[-1]),
    #         ),
    #         dim=-1,
    #     )

    #     # è¾“å‡ºçš„åµŒå…¥å’Œä½ç½®ä¿¡æ¯æš‚æ—¶ä¸º None
    #     out_pos = None
    #     out_embed = None

    #     return out_embed, out_pos, out_ref_windows, final_hw_indexes.unsqueeze(-1)


    @torch.no_grad()
    def _momentum_update_gt_decoder(self):
        """
        Momentum update of the key encoder
        """
        for param_q, param_k in zip(self.decoder.parameters(), self.decoder_gt.parameters()):
            param_k.data = param_k.data * self.m + param_q.data * (1.0 - self.m)

    def regroup(self, x, record_len):
        cum_sum_len = torch.cumsum(record_len, dim=0)
        split_x = torch.tensor_split(x, cum_sum_len[:-1].cpu())
        return split_x

    def forward(self, src, pos, noised_gt_box=None, noised_gt_onehot=None, attn_mask=None, targets=None, record_len=None, pairwise_t_matrix=None, pairwise_t_matrix_ref=None, heatmap=None):
        '''
        âš¡ å…ˆè‡ªè½¦æ£€æµ‹ï¼Œ è·å¾—é«˜è´¨é‡queryåä¼ è¾“
        src: [(B_n, 256, H, W)]
        pos: [(B_n, 256, H, W)]
        noised_gt_box: (B_n, pad_size, 7)  è¿™é‡Œç”¨çš„åº”è¯¥æ˜¯single gt å› ä¸ºè¿™ä¸ªè¦å…ˆrefineå•è½¦ å½¢æˆä¼˜è´¨query
        noised_gt_onehot: (B_n, pad_size, num_classes)
        attn_mask: (1000+pad_size, 1000+pad_size)
        targets: [{'gt_boxes': (N, 7), 'labels': (N, )}, ...]
        '''
        assert pos is not None, "position encoding is required!"
        src_anchors = self._create_ref_windows(src) # åˆ›é€ å‚è€ƒæ¡†ï¼Œè¿™ä¸ªæ˜¯BoxAttentionå¿…é¡»çš„ (B_n, HW, 7)
        src, _, src_shape = flatten_with_shape(src, None)# å±•å¹³ç‰¹å¾å›¾ï¼Œè¿”å›çš„æ˜¯ (B_n, H*W, 256), None, (1, 2) æœ€åä¸€é¡¹è®°å½•ç€Hï¼ŒW å³feature shape
        src_pos = []
        for pe in pos:
            B, C = pe.shape[:2]
            pe = pe.view(B, C, -1).transpose(1, 2) # b, h*w, c
            src_pos.append(pe)
        src_pos = torch.cat(src_pos, dim=1) # (B_n, H*W, C)
        src_start_index = torch.cat([src_shape.new_zeros(1), src_shape.prod(1).cumsum(0)[:-1]]) # è¿™æ˜¯ä¸ºäº†ç”Ÿæˆåˆ’åˆ†çš„ç´¢å¼•ï¼ŒåŒºåˆ†æ¯ä¸ªç‰¹å¾å›¾çš„ä½ç½®ï¼Œç”±äºåªæœ‰ä¸€ä¸ªç‰¹å¾å›¾ï¼Œæ‰€ä»¥ç»“æœæ˜¯(0,)

        memory = self.encoder(src, src_pos, src_shape, src_start_index, src_anchors) # BoxAttention æå–ç‰¹å¾ ç»“æœä¸º(B_n, H*W, 256)
        query_embed, query_pos, topk_proposals, topk_indexes = self._get_enc_proposals(memory, src_anchors, heatmap=heatmap) # è¿”å›Noneï¼ŒNoneï¼Œ(B_n, query_num, 8)ï¼Œ(B_n, query_num, 1)
        
        pad_size = 0
        # åŠ å™ªå£°gtï¼Œå‡†å¤‡ä¸€èµ·å‚ä¸decoderè®­ç»ƒå»å™ª
        if noised_gt_box is not None:
            noised_gt_proposals = torch.cat(
                (
                    noised_gt_box,
                    noised_gt_onehot,
                ),
                dim=-1,
            ) # (B_n, pad_size, 8)
            pad_size = noised_gt_proposals.size(1)
            topk_proposals = torch.cat(
                (
                    noised_gt_proposals,
                    topk_proposals,
                ),
                dim=1,
            ) # (B_n, pad_size + query_num, 8) 
        init_reference_out = topk_proposals[..., :7]

        # hs, inter_references = self.decoder_gt(
        hs, inter_references, bboxes_per_layer = self.decoder(
            query_embed, # None 
            query_pos, # None
            memory, # BoxAttention æå–ç‰¹å¾åç»“åˆå¤šagentåçš„Feature Map ç»“æœä¸º(B_n, H*W, 256)
            src_shape, # (1, 2)
            src_start_index, # (0,)
            topk_proposals, # (B, query_num, 8)
            attn_mask,
            return_bboxes=True
        ) # (3, B_n, pad_size + query_num, 256) æ¯ä¸€å±‚çš„è¾“å‡ºçš„queryç‰¹å¾ï¼Œ (3ï¼Œ B_n, pad_size + all_query_num, 7) æ¯ä¸€å±‚çš„æ£€æµ‹ç»“æœ 

        # optional gt forward å¯¹æ¯”å­¦ä¹ éœ€è¦ç”¨åˆ°çš„åŠ¨é‡æ›´æ–°æ¨¡å‹ç”¨åŠ å™ªgtæ¥åšå¯¹æ¯”å­¦ä¹ çš„
        if targets is not None:
            batch_size = len(targets) # è¿™é‡Œæ˜¯single æ ‡ç­¾
            per_gt_num = [tgt["gt_boxes"].shape[0] for tgt in targets] # [N1, N2, N3, N4] æ­¤ä¸ºB=4æ—¶çš„å„ä¸ªæ ·æœ¬çš„GTæ•°
            max_gt_num = max(per_gt_num)
            batched_gt_boxes_with_score = memory.new_zeros(batch_size, max_gt_num, 8) # (B, max_gt_num, 8)
            for bi in range(batch_size):
                batched_gt_boxes_with_score[bi, : per_gt_num[bi], :7] = targets[bi]["gt_boxes"] # æ”¾å…¥gtçš„box å’Œ one-hot åˆ†ç±»ç¼–ç 
                batched_gt_boxes_with_score[bi, : per_gt_num[bi], 7:] = F.one_hot(
                    targets[bi]["labels"], num_classes=self.num_classes
                )

            with torch.no_grad():
                self._momentum_update_gt_decoder() # åŠ¨é‡æ›´æ–°è¾…åŠ©æ¨¡å‹ï¼Œå…¶å‚æ•°æ›´æ–°é€Ÿåº¦éå¸¸ç¼“æ…¢ï¼Œä½†ä¸€ç›´è¿½éšdecoder
                if noised_gt_box is not None:
                    dn_group_num = noised_gt_proposals.shape[1] // (max_gt_num * 2) # å¾—åˆ°å»å™ªgtç»„æ•° == 3  2æŒ‡çš„æ˜¯æ¯ä¸€ç»„åˆåˆ†æ­£è´Ÿæ ·æœ¬
                    pos_idxs = list(range(0, dn_group_num * 2, 2))
                    pos_noised_gt_proposals = torch.cat(
                        [noised_gt_proposals[:, pi * max_gt_num : (pi + 1) * max_gt_num] for pi in pos_idxs],
                        dim=1,
                    ) # æ¯ä¸€ç»„æŠ½å–max_gt_numä¸ª (B_n, 3*max_gt_num, 8) è¿™æ˜¯ç›¸å½“äºå»å™ªæ­£æ ·æœ¬æŠ½å–å‡ºæ¥
                    gt_proposals = torch.cat((batched_gt_boxes_with_score, pos_noised_gt_proposals), dim=1)
                    # create attn_mask for gt groups
                    gt_attn_mask = memory.new_ones(
                        (dn_group_num + 1) * max_gt_num, (dn_group_num + 1) * max_gt_num
                    ).bool()  # ï¼ˆ4*max_gt_numï¼Œ4*max_gt_numï¼‰å…¨True
                    for di in range(dn_group_num + 1): # å¯¹è§’éƒ¨åˆ†mask å…¨éƒ¨è®¾ç½®ä¸ºFalseï¼Œç›¸å½“äºè¯´åªå…³æ³¨è‡ªå·±ï¼Œå³æ¯ä¸€æ‰¹gtï¼Œæ— è®ºæœ‰æ— å™ªå£°ï¼Œä»…å…³æ³¨è‡ªèº«ï¼Œå±è”½ç»„ä¹‹é—´çš„å¯è§æ€§
                        gt_attn_mask[
                            di * max_gt_num : (di + 1) * max_gt_num,
                            di * max_gt_num : (di + 1) * max_gt_num,
                        ] = False
                else:
                    gt_proposals = batched_gt_boxes_with_score
                    gt_attn_mask = None

                hs_gt, inter_references_gt = self.decoder_gt( # è¾…åŠ©æ¨¡å‹è¿›è¡Œå¯¹æ¯”å­¦ä¹ ï¼Œç¼“æ…¢è¿½éšdecoderã€‚ è¿”å› (3ï¼ŒB_n, 4*max_gt_num, 256) ä¸ (3ï¼ŒB_n, 4*max_gt_num, 8)
                    None,
                    None,
                    memory, # BoxAttention æå–ç‰¹å¾åç»“åˆå¤šagentåçš„Feature Map ç»“æœä¸º(B_n, H*W, 256)
                    src_shape, # (1, 2)
                    src_start_index, # (0,)
                    gt_proposals, # (B_n, 4*max_gt_num, 8)
                    gt_attn_mask, #ï¼ˆ4*max_gt_numï¼Œ4*max_gt_numï¼‰
                )

            init_reference_out = torch.cat(
                (
                    init_reference_out,
                    gt_proposals[..., :7],
                ),
                dim=1,
            ) # (B_n, pad_size + query_num + 4*max_gt_num, 7)  è¾“å…¥decoderå‰çš„ref window

            hs = torch.cat(
                (
                    hs,
                    hs_gt,
                ),
                dim=2,
            ) # (3, B_n, pad_size + query_num + 4*max_gt_num, 256) æ¯ä¸€å±‚Decoder layerçš„è¾“å‡ºquery
            inter_references = torch.cat(
                (
                    inter_references,
                    inter_references_gt,
                ),
                dim=2,
            ) # (3ï¼ŒB_n, pad_size + query_num + 4*max_gt_num, 7) æ¯ä¸€å±‚Decoder layerçš„å¯¹åº”æ£€æµ‹ç»“æœ

        inter_references_out = inter_references
        '''
        ä»å‰å¾€åä¾æ¬¡è¿”å›: Decoder layeræ¯ä¸€å±‚çš„query, è¾“å…¥Decoderçš„å‚è€ƒæ¡†, Decoder layeræ¯ä¸€å±‚çš„æ£€æµ‹ç»“æœ, Encoderè¾“å‡ºçš„ç‰¹å¾å›¾, åˆå§‹åŒ–çš„å‚è€ƒæ¡†, egoçš„æœ€é«˜query_numçš„ç´¢å¼•
        TODO Encoderè¾“å‡ºçš„ç‰¹å¾å›¾ä¿¡æ¯ä¼šä¸ä¼šä¸è¶³? è¦ä¸è¦è€ƒè™‘å°†queryèåˆåçš„ä¿¡æ¯æ”¾å›å» ğŸŒŸUpdated: Done, å…ˆçœ‹çœ‹æ€§èƒ½
        '''
        result = {
            'hs':hs, # (3, B_n, pad_size + query_num + 4*max_gt_num, 256) æ¯ä¸€å±‚Decoder layerçš„è¾“å‡ºquery
            'init_reference_out': init_reference_out,  # (B_n, pad_size + query_num + 4*max_gt_num, 8)  è¾“å…¥decoderå‰çš„ref window
            'inter_references_out': inter_references_out,  # (3ï¼ŒB_n, pad_size + query_num + 4*max_gt_num, 7) æ¯ä¸€å±‚Decoder layerçš„å¯¹åº”æ£€æµ‹ç»“æœ
            'memory': memory, # åŒ…æ‹¬æ­¤é¡¹çš„ä»¥ä¸‹ä¸‰é¡¹éƒ½æ˜¯ç”¨æ¥ç›‘ç£encoderæ—¶æ‰ä¼šç”¨åˆ°çš„
            'src_anchors': src_anchors,
            'topk_indexes': topk_indexes, # (B_n, query_num, 1) ç´¢å¼•
        }

        fined_query = hs[-1, :, pad_size:pad_size+self.num_queries,:] # (B_n, query_num, 256) æœ€åä¸€å±‚Decoder layerçš„è¾“å‡ºquery
        H, W = src_shape[0,0], src_shape[0,1]

        bboxes_per_layer = bboxes_per_layer[-1, :, pad_size:pad_size+self.num_queries, :] # (B_n, query_num, 8)

        memory_discrete = torch.zeros_like(memory) # (B_n, H*W, 256) 

        memory_discrete = memory_discrete.scatter(1, topk_indexes.repeat(1, 1, memory_discrete.size(-1)), fined_query) # (B_n, H*W, 256) å°†queryæ”¾å…¥åˆ°ä¸€ä¸ªç©ºçš„memoryä¸­
        memory_discrete = memory_discrete.permute(0, 2, 1).reshape(memory.shape[0], memory.shape[-1], H, W) # (B_n, C, H, W) å½¢æˆç¨€ç–çš„ç‰¹å¾å›¾

        # æ–°å»ºä¸€ä¸ªé»˜è®¤å‚è€ƒæ¡†ï¼Œç„¶åå°†decoderæœ€åä¸€æ¬¡é¢„æµ‹çš„å†…å®¹å¡«å……è¿›å»ï¼Œè¿™ä¸ªå°†ä¼šåœ¨ç©ºé—´å˜æ¢åä½œä¸ºåˆ†ç»„ä¾æ®
        boxes_before_trans = copy.deepcopy(src_anchors) # (B_n, HW, 7)
        probs_before_trans = torch.zeros(boxes_before_trans.size(0), boxes_before_trans.size(1), 1).to(boxes_before_trans)
        boxes_before_trans = torch.cat([boxes_before_trans, probs_before_trans], dim=-1) # (B_n, HW, 8)
        boxes_before_trans = boxes_before_trans.scatter(1, topk_indexes.repeat(1, 1, boxes_before_trans.size(-1)), bboxes_per_layer) # (B_n, H*W, 8) å°†bboxæ”¾å…¥åˆ°ä¸€ä¸ªç©ºçš„ç‰¹å¾å›¾ä¸­
        boxes_before_trans = boxes_before_trans.permute(0, 2, 1).reshape(memory.shape[0], 8, H, W) # (B_n, 8, H, W) å½¢æˆç¨€ç–çš„ç‰¹å¾å›¾

        # åˆ›é€ maskæ ‡è®°fined query
        valid_flag = torch.ones(fined_query.shape[0], fined_query.shape[1], 1).to(fined_query) # (B_n, query_num, 1) å…¨1
        memory_mask = torch.zeros(memory.shape[0], memory.shape[1], 1).to(memory) # (B_n, HW, 1)
        memory_mask = memory_mask.scatter(1, topk_indexes.repeat(1, 1, memory_mask.size(-1)), valid_flag) # (B_n, HW, 1)  å°†fined queryç»™æ ‡è®°
        memory_mask = memory_mask.permute(0, 2, 1).reshape(memory_mask.shape[0], 1, H, W) # (B_n, 1, H, W)

        """ # æ‰€æœ‰singleå…ˆå¡ç½®ä¿¡åº¦é˜ˆå€¼, å¾—åˆ°ç­›é€‰åçš„ç»“æœ å› æ­¤éœ€è¦è¿”å›ä¸€ä¸ªç´¢å¼• èƒ½ä»query_numä¸­ç´¢å¼•å‡ºç­›é€‰åçš„query
        # filter_bbox: [(n1,8), (n2,8) ...],  filter_indice: [(n1,), (n2,)...] ç­›é€‰å¯¹åº”çš„ç´¢å¼•
        filter_bbox, filter_indice = self.get_bboxes(bboxes_per_layer)

        memory_discrete = []
        valid_flag = torch.ones(1, fined_query.shape[1], 1).to(fined_query) # (1, query_num, 1) å…¨1
        memory_mask = []
        select_bbox = []
        for bn_i in range(len(memory_discrete)): # 
            memory_discrete_bn_i = torch.zeros(1, memory.shape[-2], memory.shape[-1]).to(memory) # (1, H*W, 256) 
            memory_mask_bn_i = torch.zeros(1, memory.shape[1], 1).to(memory) # (1, HW, 1)
            bbox_bn_i = memory_discrete_bn_i.new_zeros(1, memory.shape[-2], 8) # (1, HW, 8)

            filter_indice_bn_i = filter_indice[bn_i].unsqueeze(-1) # (n, 1) é’ˆå¯¹query_num çš„ç´¢å¼•
            filter_bbox_bn_i = filter_bbox[bn_i].unsqueeze(0) # (1, n, 8)

            select_indexes_bn_i = torch.gather(topk_indexes[bn_i], 0, filter_indice_bn_i.expand(-1, 1)) # ä»(query_num, 1)çš„queryä¸­å–å‡ºç­›é€‰å‡ºæ¥çš„é‚£éƒ¨åˆ† (n, 1) è¿™å°±æ˜¯å…¨å±€ç´¢å¼•äº†
            select_indexes_bn_i = select_indexes_bn_i.unsqueeze(0) # (1, n, 1)
            fined_query_bn_i = torch.gather(fined_query[bn_i], 0, filter_indice_bn_i.expand(-1, fined_query[bn_i].shape[-1])) # (query_num, 256) ä¸­é€‰å‡º n, 256

            bbox_bn_i = bbox_bn_i.scatter(1, select_indexes_bn_i.repeat(1, 1, bbox_bn_i.size(-1)), filter_bbox_bn_i) # å°†(1, n, 8) æ”¾å…¥åˆ° ï¼ˆ1ï¼Œ HWï¼Œ 8ï¼‰
            bbox_bn_i = bbox_bn_i.permute(0, 2, 1).reshape(1, bbox_bn_i.shape[-1], H, W) # (1, 8, H, W) å½¢æˆç¨€ç–çš„ç‰¹å¾å›¾

            memory_discrete_bn_i = memory_discrete_bn_i.scatter(1, select_indexes_bn_i.repeat(1, 1, memory_discrete_bn_i.size(-1)), fined_query_bn_i.unsqueeze(0)) 
            memory_discrete_bn_i = memory_discrete_bn_i.permute(0, 2, 1).reshape(1, memory.shape[-1], H, W) # (1, C, H, W) å½¢æˆç¨€ç–çš„ç‰¹å¾å›¾

            memory_mask_bn_i = memory_mask_bn_i.scatter(1, select_indexes_bn_i.repeat(1, 1, memory_mask_bn_i.size(-1)), valid_flag) # (1, HW, 1)  å°†fined queryç»™æ ‡è®°
            memory_mask_bn_i = memory_mask_bn_i.permute(0, 2, 1).reshape(memory_mask_bn_i.shape[0], 1, H, W) # (1, 1, H, W)

            select_bbox.append(bbox_bn_i)
            memory_discrete.append(memory_discrete_bn_i)
            memory_mask.append(memory_mask_bn_i) 

        select_bbox = torch.cat(select_bbox, dim=0) # (B_n, 8, H, W) ç­›é€‰åçš„é«˜è´¨é‡queryå¯¹åº”çš„bbox
        memory_discrete = torch.cat(memory_discrete, dim=0) # (B_n, C, H, W) ç­›é€‰åçš„é«˜è´¨é‡queryå·²ç»æ”¾å…¥è¿™ä¸ªmemoryä¸­
        memory_mask = torch.cat(memory_mask, dim=0) # (B_n, 1, H, W) è¢«æ”¾å…¥çš„ä½ç½®æ ‡è®°ä¸º1 """

        # åˆ°è¿™é‡Œï¼Œå‡†å¤‡äº† 1ï¸âƒ£ç¦»æ•£ç‰¹å¾å›¾ 2ï¸âƒ£ ç¦»æ•£ç‰¹å¾å›¾å¯¹åº”çš„maskï¼Œç”¨æ¥ç´¢å¼•å’Œæ ‡è®° 3ï¸âƒ£ ç­›é€‰å‡ºæ¥çš„å¯¹åº”bbox
        memory_discrete_batch_lst = self.regroup(memory_discrete, record_len)
        memory_mask_batch_lst = self.regroup(memory_mask, record_len)
        boxes_before_trans_batch_lst = self.regroup(boxes_before_trans, record_len)

        # memory_batch_lst = self.regroup(memory, record_len)
        all_queries = []
        ref_bboxes = []
        for bid in range(len(record_len)):
            N = record_len[bid] # number of valid agent
            t_matrix = pairwise_t_matrix[bid][:N, :N, :, :] # (N, N, 2, 3)
            t_matrix_ref = pairwise_t_matrix_ref[bid][:N, :N, :, :] # (N, N, 4, 4)
            select_bbox_b = boxes_before_trans_batch_lst[bid] # (N, 8, Hï¼ŒW) 
            memory_discrete_b = memory_discrete_batch_lst[bid] # (N, C, H, W)
            memory_mask_b = memory_mask_batch_lst[bid] # (N, 1, H, W)

            # memory_b = memory_batch_lst[bid] # (N, HW, C)
            # memory_b = memory_b.permute(0, 2, 1).reshape(memory_b.shape[0], memory_b.shape[-1], H, W) 

            # neighbor_memory_dense = warp_affine_simple(memory_b, t_matrix[0, :, :, :], (H, W), mode='bilinear') # (N, C, H, W)


            neighbor_memory = warp_affine_simple(memory_discrete_b, t_matrix[0, :, :, :], (H, W), mode='nearest') # (N, C, H, W)
            neighbor_memory_mask = warp_affine_simple(memory_mask_b, t_matrix[0, :, :, :], (H, W), mode='nearest') # (N, 1, H, W)
            neighbor_select_bbox_b = warp_affine_simple(select_bbox_b, t_matrix[0, :, :, :], (H, W), mode='nearest') # (N, 8, Hï¼ŒW) 

            # import matplotlib.pyplot as plt
            # import os
            # if self.sample_idx % 20 == 0:
            #     save_dir = "./feature_vis_heatmap"
            #     os.makedirs(save_dir, exist_ok=True)
            #     for b in range(N):
            #         confidence = neighbor_select_bbox_b[b, 7, :, :] # (H, W)
            #         mask = (confidence > 0.25).float()
            #         # mask = mask.unsqueeze(1)
            #         feature_map = neighbor_memory[b]
            #         feature_map = feature_map.mean(dim=0)
            #         feature_mask = neighbor_memory_mask[b]
            #         feature_mask = mask

            #         # å°†ç‰¹å¾å›¾å½’ä¸€åŒ–åˆ° [0, 255]
            #         def normalize_to_image(tensor):
            #             tensor = tensor - tensor.min()
            #             tensor = tensor / tensor.max()
            #             return (tensor * 255).byte()
                    
            #         dense_feature = normalize_to_image(feature_map)
            #         feature_mask = normalize_to_image(feature_mask)
            #         # è½¬ä¸º NumPy æ ¼å¼
            #         dense_feature_np = dense_feature.cpu().numpy()
            #         feature_mask_np = feature_mask.cpu().numpy()

            #         # åˆ›å»ºå¯è§†åŒ–ç”»å¸ƒ
            #         fig, axes = plt.subplots(1, 2, figsize=(20, 10))
            #         axes[0].imshow(dense_feature_np, cmap="viridis")
            #         axes[0].set_title("Dense Feature")
            #         axes[0].axis("off")
            #         axes[1].imshow(feature_mask_np, cmap="viridis")
            #         axes[1].set_title("Sparse Mask")
            #         axes[1].axis("off")

            #         # plt.figure(figsize=(20, 10))
            #         # plt.imshow(dense_feature_np, cmap="viridis")
            #         # plt.axis("off")

            #         # ä¿å­˜åˆ°æ–‡ä»¶
            #         plt.savefig(os.path.join(save_dir, f"trans_feature_map_{self.sample_idx}_{b}.png"), dpi=300, bbox_inches="tight", pad_inches=0)
            #         plt.close() 
            # self.sample_idx += 1
            
            neighbor_memory = neighbor_memory.flatten(2).permute(0, 2, 1) # (N, HW, C)
            neighbor_memory_mask = neighbor_memory_mask.flatten(2).permute(0, 2, 1) # (N, HW, 1) è¿™ä¸ªé‡Œé¢æœ‰0æœ‰1, 1çš„åœ°æ–¹å°±æ˜¯å¯¹åº”å…¶æœ‰æ•ˆçš„query
            neighbor_select_bbox_b = neighbor_select_bbox_b.flatten(2).permute(0, 2, 1) # (N, HW, 8) 

            neighbor_mask = neighbor_memory_mask.squeeze(-1).bool() # (N, HW)
            valid_query_lst = [neighbor_memory[i][neighbor_mask[i]] for i in range(N)] # [(n1, C), (n2, C)...]
            valid_bbox_lst = [neighbor_select_bbox_b[i][neighbor_mask[i]] for i in range(N)] # [(n1, 8), (n2, 8)...] 
            valid_bbox_norm_lst = [] # [(n1, 8), (n2, 8)...] 

            for id in range(len(valid_bbox_lst)):
                valid_box = valid_bbox_lst[id]
                valid_box_center = self.box_decode_func(valid_box[..., :7]) # (n, 7) åå½’ä¸€åŒ– å˜åˆ°ç‚¹äº‘åæ ‡ç³»ä¸­çš„åæ ‡
                valid_box_corner = box_utils.boxes_to_corners_3d(valid_box_center, 'lwh') # (n, 8, 3)
                projected_bbox_corner = box_utils.project_box3d(valid_box_corner.float(), t_matrix_ref[0, id].float())
                projected_bbox_center = box_utils.corners_to_boxes_3d(projected_bbox_corner, 'lwh') # (n, 7)
                projected_bbox_center_norm = self.box_encode_func(projected_bbox_center) # é‡æ–°å½’ä¸€åŒ–

                # projected_bbox_center = torch.cat([projected_bbox_center, valid_box[:, 7:]], dim=-1) # # (n, 8)
                projected_bbox_center_norm = torch.cat([projected_bbox_center_norm, valid_box[:, 7:]], dim=-1) # # (n, 8)

                # valid_bbox_lst[id] = projected_bbox_center # åˆ°è¿™é‡Œåæ‰€æœ‰çš„boxéƒ½ç»Ÿä¸€åˆ°egoåæ ‡ç³»äº† ä¸”æ‰€æœ‰çš„boxéƒ½æ˜¯çœŸå®åæ ‡ç³»ï¼Œéå½’ä¸€åŒ–æ•°å€¼
                valid_bbox_norm_lst.append(projected_bbox_center_norm)

            # neighbor_index = torch.nonzero(neighbor_mask, as_tuple=False) # (N, HW)
                
            # ç”Ÿæˆç½‘æ ¼ç´¢å¼•
            i_indices = torch.arange(H, device=neighbor_mask.device).repeat(W).view(1, -1)  # (1, HW) æ¯Hä¸ªå…ƒç´ å¤åˆ¶ä¸€éï¼Œå¤åˆ¶Wé
            j_indices = torch.arange(W, device=neighbor_mask.device).repeat_interleave(H).view(1, -1)  # (1, HW) # è¿™æ˜¯æ¯ä¸ªå…ƒç´ å¤åˆ¶Hé
            # æ‰©å±•ç´¢å¼•ä»¥åŒ¹é…æ‰¹æ¬¡å¤§å°
            i_indices = i_indices.expand(N, -1)  # (N, HW)
            j_indices = j_indices.expand(N, -1)  # (N, HW)

            # æå–æœ‰æ•ˆä½ç½®çš„ç´¢å¼•
            # valid_i = i_indices[neighbor_mask == 1]  
            # valid_j = j_indices[neighbor_mask == 1]  # æ‰€æœ‰æœ‰æ•ˆä½ç½®çš„ j åæ ‡

            query_info_lst = []
            for i in range(len(valid_query_lst)): # éå†æ¯ä¸ªagent
                n_q = valid_query_lst[i].size(0)
                agent_queries = valid_query_lst[i] # (n, 8)
                # agent_bboxes = valid_bbox_lst[i] # (n, 8)
                agent_bboxes_norm = valid_bbox_norm_lst[i] # (n,8)
                agent_pos_emb = self.pos_embed_layer(agent_bboxes_norm)
                
                valid_mask  = neighbor_mask[i] # (HW,)
                valid_i = i_indices[i][valid_mask == 1] # æ‰€æœ‰æœ‰æ•ˆä½ç½®çš„ i åæ ‡ (n, )
                valid_j = j_indices[i][valid_mask == 1] # æ‰€æœ‰æœ‰æ•ˆä½ç½®çš„ j åæ ‡
                valid_2d_pos = torch.stack([valid_i, valid_j], dim=-1) # (n, 2)
                # print("torch.sum(valid_mask) is ", torch.sum(valid_mask))
                # print("valid_mask is ", valid_mask)
                # print("valid_2d_pos is ", valid_2d_pos)
                for j in range(n_q): # éå†æ¯ä¸ªquery
                    query_info = {
                        "agent_id": i,
                        "box_norm": agent_bboxes_norm[j][:7], # ï¼ˆ7ï¼‰
                        "position": agent_bboxes_norm[j][:2], # (2) cx, cy
                        "bbox_size": agent_bboxes_norm[j][3:5], # (2) l, w
                        # "heading": agent_bboxes[j][6:7],
                        "2d_pos": valid_2d_pos[j], # (2,) 2dåæ ‡
                        "confidence": agent_bboxes_norm[j][7:],
                        "pos_emb": agent_pos_emb[j], # 256
                        "feature": agent_queries[j]
                    }
                    query_info_lst.append(query_info)
            clusters = self.build_local_groups_fast(query_info_lst)
            fused_query, norm_bboxes = self.fuse_group_features(query_info_lst, clusters, self.group_atten)

            # queries = [q['feature'].unsqueeze(0) for q in fused_query]

            # queries = torch.cat(queries, dim=0) # n_all, 256
            queries = fused_query # n_all, 256
            # print("queries shape is ", queries.shape)

            # ref_bbox = torch.cat(valid_bbox_norm_lst, dim=0)[..., :7] # n_all, 8
            ref_bbox = norm_bboxes # n_all, 8

            # print("clusters num is ", len(clusters))
            # print("queries.shape is ", queries.shape)
            # print("ref_bbox.shape is ", ref_bbox.shape)

            all_queries.append(queries)
            ref_bboxes.append(ref_bbox)
            

        return result, all_queries, ref_bboxes

   
    def build_local_groups(self, all_queries, dist_thresh=1.0, conf_thresh=0.25):
        """
        åŸºäº 3D è·ç¦» å’Œ ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œå¯¹ Query è¿›è¡Œç®€å•èšç±»ï¼Œå½¢æˆå¤šä¸ªç»„ (cluster)ã€‚
        all_queries: list of dict, æ¯ä¸ª dict å­˜å‚¨ Query ä¿¡æ¯
        dist_thresh: float, è¡¨ç¤ºä¸­å¿ƒç‚¹è·ç¦»å°äºè¯¥å€¼åˆ™è®¤ä¸ºæ˜¯â€œç›¸ä¼¼ç›®æ ‡â€
        conf_thresh: float, åªè€ƒè™‘ç½®ä¿¡åº¦é«˜äºæ­¤é˜ˆå€¼çš„ query è¿›è¡Œåˆ†ç»„
        
        return: list_of_groups, æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ª listï¼Œå­˜äº†è‹¥å¹² Query çš„ index
        """
        # å…ˆè¿‡æ»¤æ‰ç½®ä¿¡åº¦è¿‡ä½çš„
        valid_indices = [i for i, q in enumerate(all_queries) if q['confidence'] >= conf_thresh]
        valid_queries = [all_queries[i] for i in valid_indices] # æ‰€æœ‰ç¬¦åˆè¦æ±‚çš„query
        # print("valid_queries num is", len(valid_queries))
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„ queryï¼Œç›´æ¥è¿”å›ç©º
        if len(valid_queries) == 0:
            return []

        # ä¿å­˜èšç±»ç»“æœ
        clusters = []
        visited = [False] * len(valid_queries)

        for i in range(len(valid_queries)):
            if visited[i]:
                continue
            # BFS/DFS èšç±»
            queue = [i]
            visited[i] = True
            cluster = [valid_indices[i]]  # å­˜åŸå§‹çš„ index

            while queue: # ä»å…¶ä¸­æŸä¸ªèŠ‚ç‚¹å‡ºå‘ï¼Œéå†æ‰€æœ‰æœªéå†çš„èŠ‚ç‚¹ï¼Œ
                curr = queue.pop(0)
                # curr_pos = valid_queries[curr]['position']
                curr_box_norm = valid_queries[curr]['box_norm']
                # print("curr_box_norm shape is ", curr_box_norm.shape)
                # éå†å‰©ä½™çš„æœªè®¿é—®ç‚¹
                for j in range(len(valid_queries)):
                    if not visited[j]:
                        # candidate_pos = valid_queries[j]['position']
                        candidate_box_norm = valid_queries[j]['box_norm']
                        # è®¡ç®— 3D æ¬§å‡ é‡Œå¾—è·ç¦» è¿™é‡Œå¯ä»¥æœ‰å¾ˆå¤šåˆ†ç»„æ ‡å‡†
                        # dist = torch.norm(curr_pos - candidate_pos).item()
                        # if dist < dist_thresh:
                        #     visited[j] = True
                        #     queue.append(j)
                        #     cluster.append(valid_indices[j])
                        giou = generalized_box3d_iou(
                        box_cxcyczlwh_to_xyxyxy(curr_box_norm[:6]).unsqueeze(0),
                        box_cxcyczlwh_to_xyxyxy(candidate_box_norm[:6]).unsqueeze(0),
                        ) # (1, 1)
                        if giou[0,0] >  0.2:
                            visited[j] = True
                            queue.append(j)
                            cluster.append(valid_indices[j])

            # ä¸€ä¸ªå®Œæ•´çš„ç»„
            clusters.append(cluster)
        
        return clusters

    def build_local_groups_fast(self, all_queries, dist_thresh=1.5, conf_thresh=0.25, iou_thresh=0.2):
        """
        åŸºäº GIoU é˜ˆå€¼å¯¹ 3D box åšå¿«é€Ÿèšç±»ï¼Œå»æ‰é€å¯¹ BFS çš„æ˜¾å¼å¾ªç¯ã€‚
        all_queries: list[dict]ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«
        {
            'box_norm': (7,)  # è¿™é‡Œåªæ¼”ç¤ºåˆ° 7 ç»´ [cx, cy, cz, l, w, h, heading]
            'confidence': (1,) # å®é™…å¯æ ‡é‡
            ...
        }
        è¿”å›å€¼: clusters, å…¶ä¸­æ¯ä¸ªå…ƒç´ æ˜¯å¯¹åº”åˆ° all_queries çš„åŸ index åˆ—è¡¨ã€‚
        """
        # 1) å…ˆè¿‡æ»¤ç½®ä¿¡åº¦
        valid_indices = [i for i, q in enumerate(all_queries) if q['confidence'] >= conf_thresh]
        valid_queries = [all_queries[i] for i in valid_indices]
        # print("valid_queries num is", len(valid_queries))

        M = len(valid_indices)
        if M == 0:
            return []

        """ # 2) æŠŠæ‰€æœ‰ box_norm æ‹¼æˆ (M, 7) çš„å¼ é‡
        boxes_7d = torch.stack([q['box_norm'] for q in valid_queries], dim=0)  # (M, 7)

        # 3) å°† (cx,cy,cz,l,w,h,heading) è½¬ä¸º (x1,y1,z1, x2,y2,z2, ...) ä¹‹ç±»èƒ½ç»™ GIoU å‡½æ•°ç›´æ¥ç”¨çš„æ ¼å¼
        #    box_cxcyczlwh_to_xyxyxy(boxes_7d)ï¼Œè¾“å‡º (M, 6) æˆ– (M, 8) ...
        boxes_xyxyxy = box_cxcyczlwh_to_xyxyxy(boxes_7d[:, :6])  # (M, 6)
 
        # 4) ä¸€æ¬¡æ€§è®¡ç®— (M,M) GIoU çŸ©é˜µ
        #    generalized_box3d_iou éœ€è¦æ”¯æŒ (M,6) x (M,6) çš„æ‰¹é‡è¾“å…¥å¹¶è¿”å› (M,M)
        iou_matrix = generalized_box3d_iou(boxes_xyxyxy, boxes_xyxyxy)  # (M, M)ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ giou """
        
        coord_2d = torch.stack([q['2d_pos'] for q in valid_queries]).float() # (M,2)
        dist_2d = torch.cdist(coord_2d, coord_2d)
        # print("coord_2d is ", coord_2d)
        # print("dist_2d is ", dist_2d)
        adj = (dist_2d <= dist_thresh)

        # 5) æ ¹æ® iou_thresh æ„å»ºé‚»æ¥çŸ©é˜µ adj: (M, M)ï¼Œbool
        # adj = (iou_matrix > iou_thresh)

        # 6) æ‰¾æ‰€æœ‰è¿é€šåˆ†é‡ï¼šè¿™æ—¶å€™å¯ä»¥ç”¨â€œå¹¶æŸ¥é›†â€æ¥åš
        parents = list(range(M)) # [0,1,2,...,M-1]
        
        def find(x):
            if parents[x] != x: # ä¸€ç›´æ‰¾åˆ°èµ·å§‹èŠ‚ç‚¹
                parents[x] = find(parents[x])
            return parents[x]

        def union(x, y):
            rx = find(x) # æ‰¾parentsç»“ç‚¹
            ry = find(y)
            if rx != ry:
                parents[ry] = rx

        # ä¸¤é‡å¾ªç¯åˆå¹¶è¿é€šåˆ†é‡
        for i in range(M):
            for j in range(i + 1, M):
                if adj[i, j]: # ç¬¦åˆè¦æ±‚çš„åˆå¹¶
                    union(i, j)

        # 7) æŠŠåŒä¸€ä¸ª parent çš„ index æ”¾åˆ°åŒä¸€ä¸ª cluster é‡Œ
        clusters_dict = defaultdict(list)
        for i in range(M):
            root = find(i)  # æ‰¾å®ƒçš„èµ·å§‹èŠ‚ç‚¹
            clusters_dict[root].append(valid_indices[i])  # è¿™é‡Œæ”¾å›åŸå§‹ç´¢å¼•

        # 8) æœ€åè¿”å›ä¸€ä¸ª list of list
        clusters = list(clusters_dict.values()) # ç°‡ä¸­å­˜ç€æ»¡è¶³è¦æ±‚çš„è®¤ä¸ºå¯èƒ½æ˜¯è¿‘ä¼¼çš„id
        return clusters


    def fuse_group_features(self, all_queries, clusters, group_attn_module):
        """
        é’ˆå¯¹æ¯ä¸ªåˆ†ç»„ï¼Œå–å‡ºå…¶æ‰€æœ‰ query çš„ feature åšè‡ªæ³¨æ„åŠ›ï¼Œæ›´æ–° featureã€‚
        all_queries: list of dict (æ‰€æœ‰query)
        clusters: list of list, build_local_groups çš„è¾“å‡º
        group_attn_module: nn.Module, å¯ä»¥æ˜¯ GroupAttention å®ä¾‹
        """
        device = next(group_attn_module.parameters()).device

        # max_cluster_size = max(len(cluster) for cluster in clusters) if clusters else 0
        # if max_cluster_size == 0: # ä¸€ä¸ªç°‡éƒ½æ²¡æœ‰ï¼Œå‡ ä¹ä¸å¯èƒ½
        #     return torch.empty(0, self.d_model).to(device), torch.empty(0, 8).to(device)
        
        # batch_groups = []
        # for cluster in clusters:
        #     if len(cluster) == 1:
        #         idx = cluster[0]
        #         per_feature = all_queries[idx]['feature'] + all_queries[idx]['pos_emb'] + self.agent_embed[all_queries[idx]['agent_id']]
        #         batch_groups.append(per_feature.unsqueeze(0))
        #     else:
        #         feats = [all_queries[idx]['feature'] + all_queries[idx]['pos_emb'] + self.agent_embed[all_queries[idx]['agent_id']] for idx in cluster]
        #         feats = torch.stack(feats, dim=0)  # (K, D)
        #         batch_groups.append(feats.unsqueeze(0))

        # # å¡«å……
        # padded_groups = nn.utils.rnn.pad_sequence(batch_groups, batch_first=True, padding_value=0)  # (B, K_max, D)
        # mask = torch.zeros(padded_groups.size(0), padded_groups.size(1)).to(device)
        # for i, cluster in enumerate(clusters): # æ¯ä¸€ç°‡éå†ï¼Œè®¾ç½®æ©ç 
        #     mask[i, :len(cluster)] = 1

        # # æ³¨æ„åŠ›
        # fused_feats = group_attn_module(padded_groups)  # (B, K_max, D)
        # fused_feats = fused_feats * mask.unsqueeze(-1)

        # # ç§»é™¤å¡«å……
        # fused_feats = fused_feats[mask.bool()]

        # # æ”¶é›† bbox
        # new_all_bboxes = []
        # for cluster in clusters:
        #     for idx in cluster:
        #         new_all_bboxes.append(all_queries[idx]['box_norm'].unsqueeze(0))
        # new_all_bboxes = torch.cat(new_all_bboxes, dim=0).to(device)
        
        # return fused_feats, new_all_bboxes

        new_all_queries = []
        new_all_bboxes = []
        for cluster in clusters:
            if len(cluster) == 1:
                # åªæœ‰1ä¸ªå…ƒç´ ï¼Œä¸éœ€è¦èåˆï¼Œè·³è¿‡
                idx = cluster[0]
                per_feature = all_queries[idx]['feature'] + all_queries[idx]['pos_emb'] + self.agent_embed[all_queries[idx]['agent_id']]
                new_all_bboxes.append(all_queries[idx]['box_norm'].unsqueeze(0))
                new_all_queries.append(per_feature.unsqueeze(0))
                continue
            
            # ç»„å†…æ‰€æœ‰ç‰¹å¾æ”¶é›†
            feats = []
            for idx in cluster:
                per_feature = all_queries[idx]['feature'] + all_queries[idx]['pos_emb'] + self.agent_embed[all_queries[idx]['agent_id']]
                feats.append(per_feature.unsqueeze(0))  # [1, D]
            
            # æ‹¼åˆ°ç»´åº¦ä¸Š: (1, K, D)
            feats = torch.cat(feats, dim=0).unsqueeze(0).to(device)  # B=1, K=len(cluster)

            # åšä¸€æ¬¡è‡ªæ³¨æ„åŠ›
            fused_feats = group_attn_module(feats)  # (1, K, D)

            new_all_queries.append(fused_feats.squeeze(0))
            # å†™å›åˆ° all_queries
            for i, idx in enumerate(cluster):
                # all_queries[idx]['feature'] = fused_feats[0, i, :]
                new_all_bboxes.append(all_queries[idx]['box_norm'].unsqueeze(0))
        new_all_queries = torch.cat(new_all_queries, dim=0).to(device)
        new_all_bboxes = torch.cat(new_all_bboxes, dim=0).to(device)
        # print("new_all_bboxes shape is ", new_all_bboxes.shape)
        # print("new_all_queries shape is ", new_all_queries.shape)
        assert new_all_bboxes.size(0) == new_all_queries.size(0)
        return new_all_queries, new_all_bboxes
        return all_queries


class TransformerInstanceV1(nn.Module):
    def __init__(
        self,
        d_model=256,
        nhead=8,
        nlevel=1,
        num_encoder_layers=6,
        num_decoder_layers=6,
        dim_feedforward=1024,
        dropout=0.1,
        activation="relu",
        num_queries=300,
        num_classes=1,
        mom=0.999,
        cp_flag=False,
        box_encode_func=None, 
        box_decode_func=None, 
        get_sparse_features_func=None,
    ):
        super().__init__()

        self.num_queries = num_queries
        self.num_classes = num_classes
        self.m = mom

        self.box_encode_func=box_encode_func
        self.box_decode_func=box_decode_func
        self.get_sparse_features_func=get_sparse_features_func

        encoder_layer = TransformerEncoderLayer(d_model, nhead, nlevel, dim_feedforward, dropout, activation)
        self.encoder = TransformerEncoder(d_model, encoder_layer, num_encoder_layers)
        # self.trans_adapter = TransAdapt(d_model, nhead, nlevel, dim_feedforward, dropout, activation)
        # self.query_fusion = SimpleGatingFusion()
        # self.ref_fusion = BoxGatingFusion()
        # self.foreground_fusion = MaxFusion()
        decoder_layer = TransformerDecoderLayer(d_model, nhead, nlevel, dim_feedforward, dropout, activation)
        self.decoder = TransformerDecoder(d_model, decoder_layer, num_decoder_layers, cp_flag)
        self.fd_atten = Fusion_Decoder(d_model)

        self.agent_embed = nn.Parameter(torch.Tensor(2, d_model))
        self.pos_embed_layer = MLP(8, d_model, d_model, 3)
        self.sample_idx = 0
        self.parameters_fix()

    def parameters_fix(self):
        for p in self.encoder.parameters():
            p.requires_grad = False
        for p in self.decoder.parameters():
            p.requires_grad = False


    def _create_ref_windows(self, tensor_list):
        device = tensor_list[0].device

        ref_windows = []
        for tensor in tensor_list:
            B, _, H, W = tensor.shape
            ref_y, ref_x = torch.meshgrid(
                torch.linspace(0.5, H - 0.5, H, dtype=torch.float32, device=device),
                torch.linspace(0.5, W - 0.5, W, dtype=torch.float32, device=device),
                indexing="ij",
            )

            ref_y = ref_y.reshape(-1)[None] / H
            ref_x = ref_x.reshape(-1)[None] / W
            ref_xy = torch.stack((ref_x, ref_y), -1)
            ref_wh = torch.ones_like(ref_xy) * 0.025  # 0.01 - 0.05 w.r.t. Deform-DETR
            placeholder = torch.zeros_like(ref_xy)[..., :1]
            ref_box = torch.cat((ref_xy, placeholder + 0.5, ref_wh, placeholder + 0.5, placeholder), -1).expand(
                B, -1, -1
            )

            ref_windows.append(ref_box)
        ref_windows = torch.cat(ref_windows, dim=1)

        return ref_windows

    def _get_enc_proposals(self, enc_embed, ref_windows, indexes=None, heatmap=None):
        B, L = enc_embed.shape[:2]
        out_logits, out_ref_windows = self.proposal_head(enc_embed, ref_windows)

        out_probs = out_logits[..., 0].sigmoid()
        topk_probs, indexes = torch.topk(out_probs, self.num_queries, dim=1, sorted=False)
        topk_probs = topk_probs.unsqueeze(-1)
        indexes = indexes.unsqueeze(-1)
        # print("out_probs  is ", [round(x, 3) for x in out_probs[0][:1000].tolist()])

        out_ref_windows = torch.gather(out_ref_windows, 1, indexes.expand(-1, -1, out_ref_windows.shape[-1]))
        out_ref_windows = torch.cat(
            (
                out_ref_windows.detach(),
                topk_probs.detach().expand(-1, -1, out_logits.shape[-1]),
            ),
            dim=-1,
        )

        out_pos = None
        out_embed = None

        return out_embed, out_pos, out_ref_windows, indexes

    # def _get_enc_proposals(self, enc_embed, ref_windows, indexes=None, heatmap=None):
    #     """
    #     æ ¹æ® heatmap é¢„å…ˆç­›é€‰ proposalsï¼Œå¹¶ä» logits ä¸­é€‰å–æœ€ç»ˆçš„ queriesï¼Œè¿”å›åŸå§‹ heatmap çš„ HW ç´¢å¼•ã€‚

    #     Args:
    #         enc_embed: ç¼–ç çš„åµŒå…¥å‘é‡ï¼Œå½¢çŠ¶ä¸º [B, L, C]
    #         ref_windows: å‚è€ƒçª—å£ï¼Œå½¢çŠ¶ä¸º [B, L, 4]
    #         indexes: ç”¨äºæ ‡è¯†æŸäº›å…ƒç´ çš„ç´¢å¼•ï¼ˆå¯é€‰ï¼‰
    #         heatmap: çƒ­å›¾ï¼Œå½¢çŠ¶ä¸º [B, 1, H, W]

    #     Returns:
    #         out_embed: ç­›é€‰åçš„åµŒå…¥å‘é‡ï¼ˆæœªè®¾ç½®é€»è¾‘ï¼Œè¿”å› Noneï¼‰
    #         out_pos: ç­›é€‰åçš„ä½ç½®ç¼–ç ï¼ˆæœªè®¾ç½®é€»è¾‘ï¼Œè¿”å› Noneï¼‰
    #         out_ref_windows: ç­›é€‰åçš„å‚è€ƒçª—å£
    #         hw_indexes: ç­›é€‰åçš„åŸå§‹ heatmap HW ç´¢å¼•
    #     """
    #     B, L = enc_embed.shape[:2]
    #     H, W = heatmap.shape[-2:]

    #     # é€šè¿‡ proposal_head è·å–é¢„æµ‹ logits å’Œå‚è€ƒçª—å£
    #     out_logits, out_ref_windows = self.proposal_head(enc_embed, ref_windows)

    #     # Step 1: ä» heatmap ä¸­ç­›é€‰å‡ºé«˜æ¦‚ç‡åŒºåŸŸï¼Œå¹¶ä¿ç•™ HW ç´¢å¼•
    #     heatmap_flat = heatmap.view(B, -1)  # [B, H*W]
    #     top_proposals = heatmap_flat.argsort(dim=-1, descending=True)[..., :self.num_queries * 2]  # ä¿ç•™ 2 å€æ•°é‡
    #     hw_indexes = top_proposals  # ä¿å­˜åŸå§‹ HW ç´¢å¼• (B, 2*num_queries)

    #     # åˆ©ç”¨ HW ç´¢å¼•ä» heatmap_flat æå–æ¦‚ç‡ï¼Œç­›é€‰ logits å’Œ ref_windows
    #     filtered_logits = torch.gather(out_logits, 1, top_proposals.unsqueeze(-1).expand(-1, -1, out_logits.shape[-1]))
    #     filtered_ref_windows = torch.gather(ref_windows, 1, top_proposals.unsqueeze(-1).expand(-1, -1, ref_windows.shape[-1]))

    #     # Step 2: åœ¨ç­›é€‰åçš„ proposals ä¸­ï¼Œè¿›ä¸€æ­¥ç­›é€‰ num_queries ä¸ª
    #     out_probs = filtered_logits[..., 0].sigmoid()
    #     topk_probs, indexes = torch.topk(out_probs, self.num_queries, dim=1, sorted=False) # (B, num_queries)  both shape

    #     # è·å–æœ€ç»ˆçš„ HW ç´¢å¼•
    #     final_hw_indexes = torch.gather(hw_indexes, 1, indexes)  # ä»åŸå§‹ HW ç´¢å¼•ä¸­æå–æœ€ç»ˆçš„ topk
    #     topk_probs = topk_probs.unsqueeze(-1)  # å¢åŠ æœ€åä¸€ç»´

    #     # print("filtered_ref_windows shape is ", filtered_ref_windows.shape)
    #     # print("indexes shape is ", indexes.shape)
    #     # è·å–å‚è€ƒçª—å£çš„æœ€ç»ˆå†…å®¹
    #     out_ref_windows = torch.gather(filtered_ref_windows, 1, indexes.unsqueeze(-1).expand(-1, -1, filtered_ref_windows.shape[-1]))
    #     out_ref_windows = torch.cat(
    #         (
    #             out_ref_windows.detach(),
    #             topk_probs.detach().expand(-1, -1, filtered_logits.shape[-1]),
    #         ),
    #         dim=-1,
    #     )

    #     # è¾“å‡ºçš„åµŒå…¥å’Œä½ç½®ä¿¡æ¯æš‚æ—¶ä¸º None
    #     out_pos = None
    #     out_embed = None

    #     return out_embed, out_pos, out_ref_windows, final_hw_indexes.unsqueeze(-1)


    @torch.no_grad()
    def _momentum_update_gt_decoder(self):
        """
        Momentum update of the key encoder
        """
        for param_q, param_k in zip(self.decoder.parameters(), self.decoder_gt.parameters()):
            param_k.data = param_k.data * self.m + param_q.data * (1.0 - self.m)

    def regroup(self, x, record_len):
        cum_sum_len = torch.cumsum(record_len, dim=0)
        split_x = torch.tensor_split(x, cum_sum_len[:-1].cpu())
        return split_x

    def forward(self, src, pos, noised_gt_box=None, noised_gt_onehot=None, attn_mask=None, targets=None, record_len=None, pairwise_t_matrix=None, pairwise_t_matrix_ref=None, heatmap=None):
        '''
        âš¡ å…ˆè‡ªè½¦æ£€æµ‹ï¼Œ è·å¾—é«˜è´¨é‡queryåä¼ è¾“
        src: [(B_n, 256, H, W)]
        pos: [(B_n, 256, H, W)]
        noised_gt_box: (B_n, pad_size, 7)  è¿™é‡Œç”¨çš„åº”è¯¥æ˜¯single gt å› ä¸ºè¿™ä¸ªè¦å…ˆrefineå•è½¦ å½¢æˆä¼˜è´¨query
        noised_gt_onehot: (B_n, pad_size, num_classes)
        attn_mask: (1000+pad_size, 1000+pad_size)
        targets: [{'gt_boxes': (N, 7), 'labels': (N, )}, ...]
        '''
        assert pos is not None, "position encoding is required!"
        src_anchors = self._create_ref_windows(src) # åˆ›é€ å‚è€ƒæ¡†ï¼Œè¿™ä¸ªæ˜¯BoxAttentionå¿…é¡»çš„ (B_n, HW, 7)
        src, _, src_shape = flatten_with_shape(src, None)# å±•å¹³ç‰¹å¾å›¾ï¼Œè¿”å›çš„æ˜¯ (B_n, H*W, 256), None, (1, 2) æœ€åä¸€é¡¹è®°å½•ç€Hï¼ŒW å³feature shape
        src_pos = []
        for pe in pos:
            B, C = pe.shape[:2]
            pe = pe.view(B, C, -1).transpose(1, 2) # b, h*w, c
            src_pos.append(pe)
        src_pos = torch.cat(src_pos, dim=1) # (B_n, H*W, C)
        src_start_index = torch.cat([src_shape.new_zeros(1), src_shape.prod(1).cumsum(0)[:-1]]) # è¿™æ˜¯ä¸ºäº†ç”Ÿæˆåˆ’åˆ†çš„ç´¢å¼•ï¼ŒåŒºåˆ†æ¯ä¸ªç‰¹å¾å›¾çš„ä½ç½®ï¼Œç”±äºåªæœ‰ä¸€ä¸ªç‰¹å¾å›¾ï¼Œæ‰€ä»¥ç»“æœæ˜¯(0,)

        memory = self.encoder(src, src_pos, src_shape, src_start_index, src_anchors) # BoxAttention æå–ç‰¹å¾ ç»“æœä¸º(B_n, H*W, 256)
        query_embed, query_pos, topk_proposals, topk_indexes = self._get_enc_proposals(memory, src_anchors, heatmap=heatmap) # è¿”å›Noneï¼ŒNoneï¼Œ(B_n, query_num, 8)ï¼Œ(B_n, query_num, 1)
        
        pad_size = 0
        # åŠ å™ªå£°gtï¼Œå‡†å¤‡ä¸€èµ·å‚ä¸decoderè®­ç»ƒå»å™ª
        if noised_gt_box is not None:
            noised_gt_proposals = torch.cat(
                (
                    noised_gt_box,
                    noised_gt_onehot,
                ),
                dim=-1,
            ) # (B_n, pad_size, 8)
            pad_size = noised_gt_proposals.size(1)
            topk_proposals = torch.cat(
                (
                    noised_gt_proposals,
                    topk_proposals,
                ),
                dim=1,
            ) # (B_n, pad_size + query_num, 8) 
        init_reference_out = topk_proposals[..., :7]

        # hs, inter_references = self.decoder_gt(
        hs, inter_references, bboxes_per_layer = self.decoder(
            query_embed, # None 
            query_pos, # None
            memory, # BoxAttention æå–ç‰¹å¾åç»“åˆå¤šagentåçš„Feature Map ç»“æœä¸º(B_n, H*W, 256)
            src_shape, # (1, 2)
            src_start_index, # (0,)
            topk_proposals, # (B, query_num, 8)
            attn_mask,
            return_bboxes=True
        ) # (3, B_n, pad_size + query_num, 256) æ¯ä¸€å±‚çš„è¾“å‡ºçš„queryç‰¹å¾ï¼Œ (3ï¼Œ B_n, pad_size + all_query_num, 7) æ¯ä¸€å±‚çš„æ£€æµ‹ç»“æœ 

        # optional gt forward å¯¹æ¯”å­¦ä¹ éœ€è¦ç”¨åˆ°çš„åŠ¨é‡æ›´æ–°æ¨¡å‹ç”¨åŠ å™ªgtæ¥åšå¯¹æ¯”å­¦ä¹ çš„
        if targets is not None:
            batch_size = len(targets) # è¿™é‡Œæ˜¯single æ ‡ç­¾
            per_gt_num = [tgt["gt_boxes"].shape[0] for tgt in targets] # [N1, N2, N3, N4] æ­¤ä¸ºB=4æ—¶çš„å„ä¸ªæ ·æœ¬çš„GTæ•°
            max_gt_num = max(per_gt_num)
            batched_gt_boxes_with_score = memory.new_zeros(batch_size, max_gt_num, 8) # (B, max_gt_num, 8)
            for bi in range(batch_size):
                batched_gt_boxes_with_score[bi, : per_gt_num[bi], :7] = targets[bi]["gt_boxes"] # æ”¾å…¥gtçš„box å’Œ one-hot åˆ†ç±»ç¼–ç 
                batched_gt_boxes_with_score[bi, : per_gt_num[bi], 7:] = F.one_hot(
                    targets[bi]["labels"], num_classes=self.num_classes
                )

            with torch.no_grad():
                self._momentum_update_gt_decoder() # åŠ¨é‡æ›´æ–°è¾…åŠ©æ¨¡å‹ï¼Œå…¶å‚æ•°æ›´æ–°é€Ÿåº¦éå¸¸ç¼“æ…¢ï¼Œä½†ä¸€ç›´è¿½éšdecoder
                if noised_gt_box is not None:
                    dn_group_num = noised_gt_proposals.shape[1] // (max_gt_num * 2) # å¾—åˆ°å»å™ªgtç»„æ•° == 3  2æŒ‡çš„æ˜¯æ¯ä¸€ç»„åˆåˆ†æ­£è´Ÿæ ·æœ¬
                    pos_idxs = list(range(0, dn_group_num * 2, 2))
                    pos_noised_gt_proposals = torch.cat(
                        [noised_gt_proposals[:, pi * max_gt_num : (pi + 1) * max_gt_num] for pi in pos_idxs],
                        dim=1,
                    ) # æ¯ä¸€ç»„æŠ½å–max_gt_numä¸ª (B_n, 3*max_gt_num, 8) è¿™æ˜¯ç›¸å½“äºå»å™ªæ­£æ ·æœ¬æŠ½å–å‡ºæ¥
                    gt_proposals = torch.cat((batched_gt_boxes_with_score, pos_noised_gt_proposals), dim=1)
                    # create attn_mask for gt groups
                    gt_attn_mask = memory.new_ones(
                        (dn_group_num + 1) * max_gt_num, (dn_group_num + 1) * max_gt_num
                    ).bool()  # ï¼ˆ4*max_gt_numï¼Œ4*max_gt_numï¼‰å…¨True
                    for di in range(dn_group_num + 1): # å¯¹è§’éƒ¨åˆ†mask å…¨éƒ¨è®¾ç½®ä¸ºFalseï¼Œç›¸å½“äºè¯´åªå…³æ³¨è‡ªå·±ï¼Œå³æ¯ä¸€æ‰¹gtï¼Œæ— è®ºæœ‰æ— å™ªå£°ï¼Œä»…å…³æ³¨è‡ªèº«ï¼Œå±è”½ç»„ä¹‹é—´çš„å¯è§æ€§
                        gt_attn_mask[
                            di * max_gt_num : (di + 1) * max_gt_num,
                            di * max_gt_num : (di + 1) * max_gt_num,
                        ] = False
                else:
                    gt_proposals = batched_gt_boxes_with_score
                    gt_attn_mask = None

                hs_gt, inter_references_gt = self.decoder_gt( # è¾…åŠ©æ¨¡å‹è¿›è¡Œå¯¹æ¯”å­¦ä¹ ï¼Œç¼“æ…¢è¿½éšdecoderã€‚ è¿”å› (3ï¼ŒB_n, 4*max_gt_num, 256) ä¸ (3ï¼ŒB_n, 4*max_gt_num, 8)
                    None,
                    None,
                    memory, # BoxAttention æå–ç‰¹å¾åç»“åˆå¤šagentåçš„Feature Map ç»“æœä¸º(B_n, H*W, 256)
                    src_shape, # (1, 2)
                    src_start_index, # (0,)
                    gt_proposals, # (B_n, 4*max_gt_num, 8)
                    gt_attn_mask, #ï¼ˆ4*max_gt_numï¼Œ4*max_gt_numï¼‰
                )

            init_reference_out = torch.cat(
                (
                    init_reference_out,
                    gt_proposals[..., :7],
                ),
                dim=1,
            ) # (B_n, pad_size + query_num + 4*max_gt_num, 7)  è¾“å…¥decoderå‰çš„ref window

            hs = torch.cat(
                (
                    hs,
                    hs_gt,
                ),
                dim=2,
            ) # (3, B_n, pad_size + query_num + 4*max_gt_num, 256) æ¯ä¸€å±‚Decoder layerçš„è¾“å‡ºquery
            inter_references = torch.cat(
                (
                    inter_references,
                    inter_references_gt,
                ),
                dim=2,
            ) # (3ï¼ŒB_n, pad_size + query_num + 4*max_gt_num, 7) æ¯ä¸€å±‚Decoder layerçš„å¯¹åº”æ£€æµ‹ç»“æœ

        inter_references_out = inter_references
        '''
        ä»å‰å¾€åä¾æ¬¡è¿”å›: Decoder layeræ¯ä¸€å±‚çš„query, è¾“å…¥Decoderçš„å‚è€ƒæ¡†, Decoder layeræ¯ä¸€å±‚çš„æ£€æµ‹ç»“æœ, Encoderè¾“å‡ºçš„ç‰¹å¾å›¾, åˆå§‹åŒ–çš„å‚è€ƒæ¡†, egoçš„æœ€é«˜query_numçš„ç´¢å¼•
        TODO Encoderè¾“å‡ºçš„ç‰¹å¾å›¾ä¿¡æ¯ä¼šä¸ä¼šä¸è¶³? è¦ä¸è¦è€ƒè™‘å°†queryèåˆåçš„ä¿¡æ¯æ”¾å›å» ğŸŒŸUpdated: Done, å…ˆçœ‹çœ‹æ€§èƒ½
        '''
        result = {
            'hs':hs, # (3, B_n, pad_size + query_num + 4*max_gt_num, 256) æ¯ä¸€å±‚Decoder layerçš„è¾“å‡ºquery
            'init_reference_out': init_reference_out,  # (B_n, pad_size + query_num + 4*max_gt_num, 8)  è¾“å…¥decoderå‰çš„ref window
            'inter_references_out': inter_references_out,  # (3ï¼ŒB_n, pad_size + query_num + 4*max_gt_num, 7) æ¯ä¸€å±‚Decoder layerçš„å¯¹åº”æ£€æµ‹ç»“æœ
            'memory': memory, # åŒ…æ‹¬æ­¤é¡¹çš„ä»¥ä¸‹ä¸‰é¡¹éƒ½æ˜¯ç”¨æ¥ç›‘ç£encoderæ—¶æ‰ä¼šç”¨åˆ°çš„
            'src_anchors': src_anchors,
            'topk_indexes': topk_indexes, # (B_n, query_num, 1) ç´¢å¼•
        }

        fined_query = hs[-1, :, pad_size:pad_size+self.num_queries,:] # (B_n, query_num, 256) æœ€åä¸€å±‚Decoder layerçš„è¾“å‡ºquery
        H, W = src_shape[0,0], src_shape[0,1]

        bboxes_per_layer = bboxes_per_layer[-1, :, pad_size:pad_size+self.num_queries, :] # (B_n, query_num, 8)

        memory_discrete = torch.zeros_like(memory) # (B_n, H*W, 256) 

        memory_discrete = memory_discrete.scatter(1, topk_indexes.repeat(1, 1, memory_discrete.size(-1)), fined_query) # (B_n, H*W, 256) å°†queryæ”¾å…¥åˆ°ä¸€ä¸ªç©ºçš„memoryä¸­
        memory_discrete = memory_discrete.permute(0, 2, 1).reshape(memory.shape[0], memory.shape[-1], H, W) # (B_n, C, H, W) å½¢æˆç¨€ç–çš„ç‰¹å¾å›¾

        # æ–°å»ºä¸€ä¸ªé»˜è®¤å‚è€ƒæ¡†ï¼Œç„¶åå°†decoderæœ€åä¸€æ¬¡é¢„æµ‹çš„å†…å®¹å¡«å……è¿›å»ï¼Œè¿™ä¸ªå°†ä¼šåœ¨ç©ºé—´å˜æ¢åä½œä¸ºåˆ†ç»„ä¾æ®
        boxes_before_trans = copy.deepcopy(src_anchors) # (B_n, HW, 7)
        probs_before_trans = torch.zeros(boxes_before_trans.size(0), boxes_before_trans.size(1), 1).to(boxes_before_trans)
        boxes_before_trans = torch.cat([boxes_before_trans, probs_before_trans], dim=-1) # (B_n, HW, 8)
        boxes_before_trans = boxes_before_trans.scatter(1, topk_indexes.repeat(1, 1, boxes_before_trans.size(-1)), bboxes_per_layer) # (B_n, H*W, 8) å°†bboxæ”¾å…¥åˆ°ä¸€ä¸ªç©ºçš„ç‰¹å¾å›¾ä¸­
        boxes_before_trans = boxes_before_trans.permute(0, 2, 1).reshape(memory.shape[0], 8, H, W) # (B_n, 8, H, W) å½¢æˆç¨€ç–çš„ç‰¹å¾å›¾

        # åˆ›é€ maskæ ‡è®°fined query
        valid_flag = torch.ones(fined_query.shape[0], fined_query.shape[1], 1).to(fined_query) # (B_n, query_num, 1) å…¨1
        memory_mask = torch.zeros(memory.shape[0], memory.shape[1], 1).to(memory) # (B_n, HW, 1)
        memory_mask = memory_mask.scatter(1, topk_indexes.repeat(1, 1, memory_mask.size(-1)), valid_flag) # (B_n, HW, 1)  å°†fined queryç»™æ ‡è®°
        memory_mask = memory_mask.permute(0, 2, 1).reshape(memory_mask.shape[0], 1, H, W) # (B_n, 1, H, W)

        """ # æ‰€æœ‰singleå…ˆå¡ç½®ä¿¡åº¦é˜ˆå€¼, å¾—åˆ°ç­›é€‰åçš„ç»“æœ å› æ­¤éœ€è¦è¿”å›ä¸€ä¸ªç´¢å¼• èƒ½ä»query_numä¸­ç´¢å¼•å‡ºç­›é€‰åçš„query
        # filter_bbox: [(n1,8), (n2,8) ...],  filter_indice: [(n1,), (n2,)...] ç­›é€‰å¯¹åº”çš„ç´¢å¼•
        filter_bbox, filter_indice = self.get_bboxes(bboxes_per_layer)

        memory_discrete = []
        valid_flag = torch.ones(1, fined_query.shape[1], 1).to(fined_query) # (1, query_num, 1) å…¨1
        memory_mask = []
        select_bbox = []
        for bn_i in range(len(memory_discrete)): # 
            memory_discrete_bn_i = torch.zeros(1, memory.shape[-2], memory.shape[-1]).to(memory) # (1, H*W, 256) 
            memory_mask_bn_i = torch.zeros(1, memory.shape[1], 1).to(memory) # (1, HW, 1)
            bbox_bn_i = memory_discrete_bn_i.new_zeros(1, memory.shape[-2], 8) # (1, HW, 8)

            filter_indice_bn_i = filter_indice[bn_i].unsqueeze(-1) # (n, 1) é’ˆå¯¹query_num çš„ç´¢å¼•
            filter_bbox_bn_i = filter_bbox[bn_i].unsqueeze(0) # (1, n, 8)

            select_indexes_bn_i = torch.gather(topk_indexes[bn_i], 0, filter_indice_bn_i.expand(-1, 1)) # ä»(query_num, 1)çš„queryä¸­å–å‡ºç­›é€‰å‡ºæ¥çš„é‚£éƒ¨åˆ† (n, 1) è¿™å°±æ˜¯å…¨å±€ç´¢å¼•äº†
            select_indexes_bn_i = select_indexes_bn_i.unsqueeze(0) # (1, n, 1)
            fined_query_bn_i = torch.gather(fined_query[bn_i], 0, filter_indice_bn_i.expand(-1, fined_query[bn_i].shape[-1])) # (query_num, 256) ä¸­é€‰å‡º n, 256

            bbox_bn_i = bbox_bn_i.scatter(1, select_indexes_bn_i.repeat(1, 1, bbox_bn_i.size(-1)), filter_bbox_bn_i) # å°†(1, n, 8) æ”¾å…¥åˆ° ï¼ˆ1ï¼Œ HWï¼Œ 8ï¼‰
            bbox_bn_i = bbox_bn_i.permute(0, 2, 1).reshape(1, bbox_bn_i.shape[-1], H, W) # (1, 8, H, W) å½¢æˆç¨€ç–çš„ç‰¹å¾å›¾

            memory_discrete_bn_i = memory_discrete_bn_i.scatter(1, select_indexes_bn_i.repeat(1, 1, memory_discrete_bn_i.size(-1)), fined_query_bn_i.unsqueeze(0)) 
            memory_discrete_bn_i = memory_discrete_bn_i.permute(0, 2, 1).reshape(1, memory.shape[-1], H, W) # (1, C, H, W) å½¢æˆç¨€ç–çš„ç‰¹å¾å›¾

            memory_mask_bn_i = memory_mask_bn_i.scatter(1, select_indexes_bn_i.repeat(1, 1, memory_mask_bn_i.size(-1)), valid_flag) # (1, HW, 1)  å°†fined queryç»™æ ‡è®°
            memory_mask_bn_i = memory_mask_bn_i.permute(0, 2, 1).reshape(memory_mask_bn_i.shape[0], 1, H, W) # (1, 1, H, W)

            select_bbox.append(bbox_bn_i)
            memory_discrete.append(memory_discrete_bn_i)
            memory_mask.append(memory_mask_bn_i) 

        select_bbox = torch.cat(select_bbox, dim=0) # (B_n, 8, H, W) ç­›é€‰åçš„é«˜è´¨é‡queryå¯¹åº”çš„bbox
        memory_discrete = torch.cat(memory_discrete, dim=0) # (B_n, C, H, W) ç­›é€‰åçš„é«˜è´¨é‡queryå·²ç»æ”¾å…¥è¿™ä¸ªmemoryä¸­
        memory_mask = torch.cat(memory_mask, dim=0) # (B_n, 1, H, W) è¢«æ”¾å…¥çš„ä½ç½®æ ‡è®°ä¸º1 """

        # åˆ°è¿™é‡Œï¼Œå‡†å¤‡äº† 1ï¸âƒ£ç¦»æ•£ç‰¹å¾å›¾ 2ï¸âƒ£ ç¦»æ•£ç‰¹å¾å›¾å¯¹åº”çš„maskï¼Œç”¨æ¥ç´¢å¼•å’Œæ ‡è®° 3ï¸âƒ£ ç­›é€‰å‡ºæ¥çš„å¯¹åº”bbox
        memory_discrete_batch_lst = self.regroup(memory_discrete, record_len)
        memory_mask_batch_lst = self.regroup(memory_mask, record_len)
        boxes_before_trans_batch_lst = self.regroup(boxes_before_trans, record_len)

        # memory_batch_lst = self.regroup(memory, record_len)
        all_queries = []
        ref_bboxes = []
        for bid in range(len(record_len)):
            N = record_len[bid] # number of valid agent
            t_matrix = pairwise_t_matrix[bid][:N, :N, :, :] # (N, N, 2, 3)
            t_matrix_ref = pairwise_t_matrix_ref[bid][:N, :N, :, :] # (N, N, 4, 4)
            select_bbox_b = boxes_before_trans_batch_lst[bid] # (N, 8, Hï¼ŒW) 
            memory_discrete_b = memory_discrete_batch_lst[bid] # (N, C, H, W)
            memory_mask_b = memory_mask_batch_lst[bid] # (N, 1, H, W)

            # memory_b = memory_batch_lst[bid] # (N, HW, C)
            # memory_b = memory_b.permute(0, 2, 1).reshape(memory_b.shape[0], memory_b.shape[-1], H, W) 

            # neighbor_memory_dense = warp_affine_simple(memory_b, t_matrix[0, :, :, :], (H, W), mode='bilinear') # (N, C, H, W)


            neighbor_memory = warp_affine_simple(memory_discrete_b, t_matrix[0, :, :, :], (H, W), mode='nearest') # (N, C, H, W)
            neighbor_memory_mask = warp_affine_simple(memory_mask_b, t_matrix[0, :, :, :], (H, W), mode='nearest') # (N, 1, H, W)
            neighbor_select_bbox_b = warp_affine_simple(select_bbox_b, t_matrix[0, :, :, :], (H, W), mode='nearest') # (N, 8, Hï¼ŒW) 

            """ import matplotlib.pyplot as plt
            import os
            if self.sample_idx % 20 == 0:
                save_dir = "./feature_vis_heatmap"
                os.makedirs(save_dir, exist_ok=True)
                for b in range(N):
                    confidence = neighbor_select_bbox_b[b, 7, :, :] # (H, W)
                    mask = (confidence > 0.25).float()
                    # mask = mask.unsqueeze(1)
                    feature_map = neighbor_memory[b]
                    feature_map = feature_map.mean(dim=0)
                    feature_mask = neighbor_memory_mask[b]
                    feature_mask = mask

                    # å°†ç‰¹å¾å›¾å½’ä¸€åŒ–åˆ° [0, 255]
                    def normalize_to_image(tensor):
                        tensor = tensor - tensor.min()
                        tensor = tensor / tensor.max()
                        return (tensor * 255).byte()
                    
                    dense_feature = normalize_to_image(feature_map)
                    feature_mask = normalize_to_image(feature_mask)
                    # è½¬ä¸º NumPy æ ¼å¼
                    dense_feature_np = dense_feature.cpu().numpy()
                    feature_mask_np = feature_mask.cpu().numpy()

                    # åˆ›å»ºå¯è§†åŒ–ç”»å¸ƒ
                    fig, axes = plt.subplots(1, 2, figsize=(20, 10))
                    axes[0].imshow(dense_feature_np, cmap="viridis")
                    axes[0].set_title("Dense Feature")
                    axes[0].axis("off")
                    axes[1].imshow(feature_mask_np, cmap="viridis")
                    axes[1].set_title("Sparse Mask")
                    axes[1].axis("off")

                    # plt.figure(figsize=(20, 10))
                    # plt.imshow(dense_feature_np, cmap="viridis")
                    # plt.axis("off")

                    # ä¿å­˜åˆ°æ–‡ä»¶
                    plt.savefig(os.path.join(save_dir, f"trans_feature_map_{self.sample_idx}_{b}.png"), dpi=300, bbox_inches="tight", pad_inches=0)
                    plt.close() 
            self.sample_idx += 1 """
            
            neighbor_memory = neighbor_memory.flatten(2).permute(0, 2, 1) # (N, HW, C)
            neighbor_memory_mask = neighbor_memory_mask.flatten(2).permute(0, 2, 1) # (N, HW, 1) è¿™ä¸ªé‡Œé¢æœ‰0æœ‰1, 1çš„åœ°æ–¹å°±æ˜¯å¯¹åº”å…¶æœ‰æ•ˆçš„query
            neighbor_select_bbox_b = neighbor_select_bbox_b.flatten(2).permute(0, 2, 1) # (N, HW, 8) 

            neighbor_mask = neighbor_memory_mask.squeeze(-1).bool() # (N, HW)
            valid_query_lst = [neighbor_memory[i][neighbor_mask[i]] for i in range(N)] # [(n1, C), (n2, C)...]
            valid_bbox_lst = [neighbor_select_bbox_b[i][neighbor_mask[i]] for i in range(N)] # [(n1, 8), (n2, 8)...] 
            valid_bbox_norm_lst = [] # [(n1, 8), (n2, 8)...] 

            for id in range(len(valid_bbox_lst)):
                valid_box = valid_bbox_lst[id]
                valid_box_center = self.box_decode_func(valid_box[..., :7]) # (n, 7) åå½’ä¸€åŒ– å˜åˆ°ç‚¹äº‘åæ ‡ç³»ä¸­çš„åæ ‡
                valid_box_corner = box_utils.boxes_to_corners_3d(valid_box_center, 'lwh') # (n, 8, 3)
                projected_bbox_corner = box_utils.project_box3d(valid_box_corner.float(), t_matrix_ref[0, id].float())
                projected_bbox_center = box_utils.corners_to_boxes_3d(projected_bbox_corner, 'lwh') # (n, 7)
                projected_bbox_center_norm = self.box_encode_func(projected_bbox_center) # é‡æ–°å½’ä¸€åŒ–

                # projected_bbox_center = torch.cat([projected_bbox_center, valid_box[:, 7:]], dim=-1) # # (n, 8)
                projected_bbox_center_norm = torch.cat([projected_bbox_center_norm, valid_box[:, 7:]], dim=-1) # # (n, 8)

                # valid_bbox_lst[id] = projected_bbox_center # åˆ°è¿™é‡Œåæ‰€æœ‰çš„boxéƒ½ç»Ÿä¸€åˆ°egoåæ ‡ç³»äº† ä¸”æ‰€æœ‰çš„boxéƒ½æ˜¯çœŸå®åæ ‡ç³»ï¼Œéå½’ä¸€åŒ–æ•°å€¼
                valid_bbox_norm_lst.append(projected_bbox_center_norm)

            # neighbor_index = torch.nonzero(neighbor_mask, as_tuple=False) # (N, HW)
                
            # ç”Ÿæˆç½‘æ ¼ç´¢å¼•
            i_indices = torch.arange(H, device=neighbor_mask.device).repeat(W).view(1, -1)  # (1, HW) æ¯Hä¸ªå…ƒç´ å¤åˆ¶ä¸€éï¼Œå¤åˆ¶Wé
            j_indices = torch.arange(W, device=neighbor_mask.device).repeat_interleave(H).view(1, -1)  # (1, HW) # è¿™æ˜¯æ¯ä¸ªå…ƒç´ å¤åˆ¶Hé
            # æ‰©å±•ç´¢å¼•ä»¥åŒ¹é…æ‰¹æ¬¡å¤§å°
            i_indices = i_indices.expand(N, -1)  # (N, HW)
            j_indices = j_indices.expand(N, -1)  # (N, HW)

            # æå–æœ‰æ•ˆä½ç½®çš„ç´¢å¼•
            # valid_i = i_indices[neighbor_mask == 1]  
            # valid_j = j_indices[neighbor_mask == 1]  # æ‰€æœ‰æœ‰æ•ˆä½ç½®çš„ j åæ ‡

            query_info_lst = []
            for i in range(len(valid_query_lst)): # éå†æ¯ä¸ªagent
                n_q = valid_query_lst[i].size(0)
                agent_queries = valid_query_lst[i] # (n, 8)
                # agent_bboxes = valid_bbox_lst[i] # (n, 8)
                agent_bboxes_norm = valid_bbox_norm_lst[i] # (n,8)
                agent_pos_emb = self.pos_embed_layer(agent_bboxes_norm)
                
                valid_mask  = neighbor_mask[i] # (HW,)
                valid_i = i_indices[i][valid_mask == 1] # æ‰€æœ‰æœ‰æ•ˆä½ç½®çš„ i åæ ‡ (n, )
                valid_j = j_indices[i][valid_mask == 1] # æ‰€æœ‰æœ‰æ•ˆä½ç½®çš„ j åæ ‡
                valid_2d_pos = torch.stack([valid_i, valid_j], dim=-1) # (n, 2)
                # print("torch.sum(valid_mask) is ", torch.sum(valid_mask))
                # print("valid_mask is ", valid_mask)
                # print("valid_2d_pos is ", valid_2d_pos)
                for j in range(n_q): # éå†æ¯ä¸ªquery
                    query_info = {
                        "agent_id": i,
                        "box_norm": agent_bboxes_norm[j][:7], # ï¼ˆ7ï¼‰
                        "position": agent_bboxes_norm[j][:2], # (2) cx, cy
                        "bbox_size": agent_bboxes_norm[j][3:5], # (2) l, w
                        # "heading": agent_bboxes[j][6:7],
                        "2d_pos": valid_2d_pos[j], # (2,) 2dåæ ‡
                        "confidence": agent_bboxes_norm[j][7:],
                        "pos_emb": agent_pos_emb[j], # 256
                        "feature": agent_queries[j]
                    }
                    query_info_lst.append(query_info)
            attn_mask, valid_indicies = gaussian_atten_mask_from_bboxes(query_info_lst) # (M, M)çš„Mask
            valid_feat = []
            valid_feat_pos = []
            norm_bboxes = []
            for vid in valid_indicies:
                per_query_feat = query_info_lst[vid]['feature'] + query_info_lst[vid]['pos_emb'] + self.agent_embed[query_info_lst[vid]['agent_id']]
                # per_query_feat_w_pos = query_info_lst[vid]['feature'] + query_info_lst[vid]['pos_emb'] + self.agent_embed(query_info_lst[vid]['agent_id'])
                per_query_pos = query_info_lst[vid]['pos_emb'] + self.agent_embed[query_info_lst[vid]['agent_id']]
                per_query_box = query_info_lst[vid]['box_norm']

                valid_feat.append(per_query_feat.unsqueeze(0)) # (1, D)
                valid_feat_pos.append(per_query_pos.unsqueeze(0)) # (1, D)
                norm_bboxes.append(per_query_box.unsqueeze(0)) # (1, 7)
            valid_feat = torch.cat(valid_feat, dim=0).unsqueeze(0) # (1, M, D)
            valid_feat_pos = torch.cat(valid_feat_pos, dim=0).unsqueeze(0) # (1, M, D)
            norm_bboxes = torch.cat(norm_bboxes, dim=0) # (M, 7)

            fused_query = self.fd_atten(valid_feat, valid_feat_pos, attn_mask)
            # clusters = self.build_local_groups_fast(query_info_lst)
            # fused_query, norm_bboxes = self.fuse_group_features(query_info_lst, clusters, self.group_atten)

            # queries = [q['feature'].unsqueeze(0) for q in fused_query]

            # queries = torch.cat(queries, dim=0) # n_all, 256
            queries = fused_query.squeeze(0) # n_all, 256
            # print("queries shape is ", queries.shape)

            # ref_bbox = torch.cat(valid_bbox_norm_lst, dim=0)[..., :7] # n_all, 8
            ref_bbox = norm_bboxes # n_all, 7

            # print("clusters num is ", len(clusters))
            # print("queries.shape is ", queries.shape)
            # print("ref_bbox.shape is ", ref_bbox.shape)

            all_queries.append(queries)
            ref_bboxes.append(ref_bbox)
            

        return result, all_queries, ref_bboxes

def gaussian_atten_mask_from_bboxes(all_queries, conf_thresh=0.10):

    # 1) å…ˆè¿‡æ»¤ç½®ä¿¡åº¦
    valid_indices = [i for i, q in enumerate(all_queries) if q['confidence'] >= conf_thresh]
    # print("all_queries len is ", len(all_queries))
    # print("valid_indices len is ", len(valid_indices))
    valid_queries = [all_queries[i] for i in valid_indices]

    center_xy = torch.stack([q['position'] for q in valid_queries]) # (M,2)
    boxes_lw = torch.stack([q['bbox_size'] for q in valid_queries]) # (M,2)
    radius = torch.sqrt(boxes_lw[:,0]**2 + boxes_lw[:,1]**2) / 2.0
    sigma = (radius * 2 + 1) / 6.0 # (M. 1)
    distance = ((center_xy.unsqueeze(1) - center_xy.unsqueeze(0)) ** 2).sum(dim=-1) # (M, M)
    gaussian_mask = (-distance / (2 * sigma[:, None] ** 2 + torch.finfo(torch.float32).eps)).exp()
    gaussian_mask[gaussian_mask < torch.finfo(torch.float32).eps] = 0
    attn_mask = gaussian_mask.log()

    return attn_mask, valid_indices

class GroupAttention(nn.Module):
    """
    å¯¹ä¸€ä¸ªç»„å†…çš„ç‰¹å¾åšä¸€æ¬¡è‡ªæ³¨æ„åŠ›(Transformer Encoder çš„ä¸€å±‚ç®€åŒ–ç‰ˆæœ¬)ã€‚
    """
    def __init__(self, d_model, nhead=4, dim_feedforward=256, dropout=0.1, activation='gelu'):
        super().__init__()
        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)
        self.linear1 = nn.Linear(d_model, dim_feedforward)
        self.dropout = nn.Dropout(dropout)
        self.linear2 = nn.Linear(dim_feedforward, d_model)
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.dropout1 = nn.Dropout(dropout)
        self.dropout2 = nn.Dropout(dropout)
        self.activation = get_activation_fn(activation)

    def forward(self, x):
        """
        x: (B, K, D)
           B: batch_size (å¯ç†è§£ä¸ºä¸€æ¬¡å¤„ç†å¤šä¸ª group çš„å¹¶è¡Œï¼Œå¦‚æœåšä¸åˆ°å°±å•ç»„å•ç»„ç®—)
           K: ä¸€ä¸ªç»„å†… Query æ•°é‡
           D: ç‰¹å¾ç»´åº¦
        """
        # Self-Attention
        # Q, K, V å…¨éƒ½æ˜¯ x
        attn_out, _ = self.self_attn(query=x, key=x, value=x)
        x = x + self.dropout1(attn_out)
        x = self.norm1(x)

        # Feed Forward
        ff_out = self.linear2(self.dropout(self.activation(self.linear1(x))))
        x = x + self.dropout2(ff_out)
        x = self.norm2(x)

        return x

class Fusion_Decoder(nn.Module):
    """
    å¯¹ä¸€ä¸ªç»„å†…çš„ç‰¹å¾åšä¸€æ¬¡è‡ªæ³¨æ„åŠ›(Transformer Encoder çš„ä¸€å±‚ç®€åŒ–ç‰ˆæœ¬)ã€‚
    """
    def __init__(self, d_model, nhead=8, dim_feedforward=256, dropout=0.1, activation='gelu'):
        super().__init__()
        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)
        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)
        self.linear1 = nn.Linear(d_model, dim_feedforward)
        self.dropout = nn.Dropout(dropout)
        self.linear2 = nn.Linear(dim_feedforward, d_model)
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.norm3 = nn.LayerNorm(d_model)
        self.dropout1 = nn.Dropout(dropout)
        self.dropout2 = nn.Dropout(dropout)
        self.dropout3 = nn.Dropout(dropout)
        self.activation = get_activation_fn(activation)

    @staticmethod
    def with_pos_embed(tensor, pos):
        return tensor if pos is None else tensor + pos

    def forward(self, x, x_pos_embed, attn_mask):
        """
        x: (B, K, D)
           B: batch_size (å¯ç†è§£ä¸ºä¸€æ¬¡å¤„ç†å¤šä¸ª group çš„å¹¶è¡Œï¼Œå¦‚æœåšä¸åˆ°å°±å•ç»„å•ç»„ç®—)
           K: ä¸€ä¸ªç»„å†… Query æ•°é‡
           D: ç‰¹å¾ç»´åº¦
        """
        # Self-Attention åŒæ—¶ä¹Ÿæœ‰æ•°æ®åˆ†å¸ƒè·¨åŸŸé€‚åº”çš„ä½œç”¨
        query = self.with_pos_embed(x, x_pos_embed)
        q = k = v = query
        query2, _ = self.self_attn(q, k, v)
        query = query + self.dropout(query2)
        query = self.norm1(query)

        # with attn mask
        attn_out, _ = self.multihead_attn(query, k, v, attn_mask=attn_mask)
        query = query + self.dropout1(attn_out)
        query = self.norm2(query)

        # Feed Forward
        ff_out = self.linear2(self.dropout2(self.activation(self.linear1(query))))
        query = query + self.dropout3(ff_out)
        query = self.norm3(query)

        return query


#  def get_bboxes(self, preds, align_num=100):
#         '''
#         preds:  # (B_n, query_num, 8)
#         '''
#         out_prob = preds[..., 7:] # (B, 1000, 1) Båœ¨éªŒè¯æˆ–è€…æµ‹è¯•çš„æ—¶å€™ä¸€å®šæ˜¯ ==1
#         out_bbox = preds[..., :7] # (B, 1000, 7)
#         batch_size = out_prob.shape[0]

#         # out_prob = out_logits.sigmoid() XXX å·²ç»åœ¨decoderä¸­è®¡ç®—è¿‡sigmoid
#         out_prob = out_prob.view(out_prob.shape[0], -1) # (B, 1000)
#         out_bbox = self.box_decode_func(out_bbox)

#         def _process_output(indices, bboxes):
#             topk_boxes = indices.div(out_prob.shape[2], rounding_mode="floor").unsqueeze(-1)
#             labels = indices % out_prob.shape[2] # å¾—åˆ°æ ‡ç­¾
#             boxes = torch.gather(bboxes, 0, topk_boxes.repeat(1, out_bbox.shape[-1]))
#             return labels + 1, boxes, topk_boxes

#         new_ret_dict = []
#         all_bboxes = []
#         all_mask = []
#         topk_indices_list = list() # [(n1,), (n2,)...] ç­›é€‰å¯¹åº”çš„ç´¢å¼•
#         for i in range(batch_size):
#             out_prob_i = out_prob[i] # ï¼ˆ1000*num_classï¼Œ)
#             out_bbox_i = out_bbox[i] # (1000, 7)

#             topk_indices_i = torch.nonzero(out_prob_i >= 0.2, as_tuple=True)[0] # ç­›é€‰ç½®ä¿¡åº¦å¤§äº0.1çš„çš„ç´¢å¼• (n, ) TODO çœ‹ä¸€ä¸‹shape
#             scores = out_prob_i[topk_indices_i] # (n, ) è¿™ä¸ªå› ä¸ºå¤šclsä¹Ÿæ˜¯ç›¸åŒçš„repeat æ‰€ä»¥ä¸ç”¨ä¸Šé¢çš„æ“ä½œ

#             labels, boxes, topk_indices = _process_output(topk_indices_i.view(-1), out_bbox_i) # åˆ†åˆ«å¾—åˆ°æ ‡ç­¾å’Œbbox shape ä¸º (n, ) and (n, 7)

#             topk_indices_list.append(topk_indices)

#             scores_list = list()
#             labels_list = list()
#             boxes_list = list()
            

#             for c in range(self.num_classes):
#                 mask = (labels - 1) == c # å¯¹äºåˆ†ç±»æ— å…³æ¥è¯´å…¶å®æ˜¯å…¨True ï¼Œ(n, ), å¯¹äºå¤šåˆ†ç±»çš„æ¥è¯´å…¶å®å°±æ˜¯ä¾æ¬¡å¤„ç†æ¯ä¸ªåˆ†ç±»ç”¨çš„
#                 scores_temp = scores[mask]
#                 labels_temp = labels[mask]
#                 boxes_temp = boxes[mask]

#                 scores_list.append(scores_temp)
#                 labels_list.append(labels_temp)
#                 boxes_list.append(boxes_temp)

#             scores = torch.cat(scores_list, dim=0) # (n,)
#             labels = torch.cat(labels_list, dim=0) # (n,) åœ¨ç±»åˆ«æ— å…³ä¸­ï¼Œå…¶å®labelæ˜¯å…¨0
#             boxes = torch.cat(boxes_list, dim=0) # (n,7)
#             # ret = dict(pred_boxes=boxes, pred_scores=scores, pred_labels=labels)
#             # new_ret_dict.append(ret)
#             # æˆªæ–­æˆ–è¡¥é›¶
#             boxes = torch.cat([boxes, scores.unsqueeze(-1)], dim=1) # n,8
#             all_bboxes.append(boxes)
#             # n = boxes.size(0)
#             # if n >= align_num:
#             #     aligned_tensor = boxes[:align_num]
#             #     aligned_mask = boxes.new_ones(align_num)  # å…¨æœ‰æ•ˆ
#             # else:
#             #     padding = boxes.new_zeros((align_num - n, 8))
#             #     aligned_tensor = torch.cat([boxes, padding], dim=0)
#             #     aligned_mask = torch.cat([torch.ones(n, dtype=torch.int32), torch.zeros(align_num - n, dtype=torch.int32)])
#             #     aligned_mask = mask.to(boxes)
#             # all_bboxes.append(aligned_tensor)
#             # all_mask.append(aligned_mask.bool())

#         return all_bboxes, topk_indices_list

#     @torch.no_grad()
#     def matcher(self, outputs, targets):

#         pred_logits = outputs["pred_logits"] # (B, 1000, 1)
#         pred_boxes = outputs["pred_boxes"] # (B, 1000, 7)

#         bs, num_queries = pred_logits.shape[:2]
#         # We flatten to compute the cost matrices in a batch
#         out_prob = pred_logits.sigmoid() # (B, 1000, 1)
#         # ([batch_size, num_queries, 6], [batch_size, num_queries, 2])
#         out_bbox = pred_boxes[..., :6]
#         out_rad = pred_boxes[..., 6:7]

#     # Also concat the target labels and boxes
#         # [batch_size, num_target_boxes]
#         tgt_ids = [v["labels"] for v in targets] # [(n1,), (n2,)]
#         # [batch_size, num_target_boxes, 6]
#         tgt_bbox = [v["gt_boxes"][..., :6] for v in targets] # [(n1,6), (n2,6)]
#         # [batch_size, num_target_boxes, 2]
#         tgt_rad = [v["gt_boxes"][..., 6:7] for v in targets] # [(n1,1), (n2,1)]

#         alpha = 0.25
#         gamma = 2.0

#         indices = []

#         for i in range(bs):
#             with torch.cuda.amp.autocast(enabled=False): # ç¦ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦, å¼ºåˆ¶å•ç²¾åº¦è®¡ç®—ï¼Œé€‚åˆé«˜ç²¾åº¦éœ€æ±‚åœºæ™¯
#                 out_prob_i = out_prob[i].float()    # (1000, 1)
#                 out_bbox_i = out_bbox[i].float()    # (1000, 6)
#                 out_rad_i = out_rad[i].float()      # (1000, 1)
#                 tgt_bbox_i = tgt_bbox[i].float()    # (n, 6)
#                 tgt_rad_i = tgt_rad[i].float()      # (n, 1)

#                 # [num_queries, num_target_boxes]
#                 cost_giou = -generalized_box3d_iou(
#                     box_cxcyczlwh_to_xyxyxy(out_bbox[i]),
#                     box_cxcyczlwh_to_xyxyxy(tgt_bbox[i]),
#                 ) # (1000, n) å–è´Ÿæ•°è¡¨ç¤ºGIoUè¶Šå¤§ï¼Œä»£ä»·è¶Šå°
#                 # åˆ†ç±»ä»£ä»·è®¡ç®—æ–¹å¼ç±»ä¼¼Focal Lossï¼Œä¸åŒçš„æ˜¯ï¼Œè¿™æ˜¯
#                 neg_cost_class = (1 - alpha) * (out_prob_i ** gamma) * (-(1 - out_prob_i + 1e-8).log()) # (1000, 1) è´Ÿæ ·æœ¬åˆ†ç±»ä»£ä»· è¡¨ç¤ºå¾—åˆ†è¶Šé«˜ ä»£ä»·è¶Šé«˜
#                 pos_cost_class = alpha * ((1 - out_prob_i) ** gamma) * (-(out_prob_i + 1e-8).log()) # (1000, 1) æ­£æ ·æœ¬ä»£ä»·ï¼Œå¾—åˆ†è¶Šé«˜ï¼Œä»£ä»·è¶Šä½
#                 cost_class = pos_cost_class[:, tgt_ids[i]] - neg_cost_class[:, tgt_ids[i]] # ç»“æœshape (1000, n_idx)ï¼Œtgt_idsä¸ºbatchä¸­æ¯ä¸ªæ ·æœ¬å¯¹åº”çš„gt label[(n1,), (n2,)], åœ¨ç¬¬äºŒç»´åº¦ä¸Šç­›é€‰ï¼Œå³æ¯ä¸ªgtéƒ½è¦è·Ÿæ‰€æœ‰çš„queryå»è®¡ç®—å¯¹åº”çš„labelæŸå¤±

#                 # Compute the L1 cost between boxes
#                 # [num_queries, num_target_boxes]
#                 cost_bbox = torch.cdist(out_bbox_i, tgt_bbox_i, p=1) # p = 1 æ±‚çš„æ˜¯Manhattanè·ç¦»ï¼Œ=2ä¸ºEuclieanè·ç¦»ï¼Œ ä¸ºâ™¾ï¸åˆ™æ˜¯Chebyshevè·ç¦»
#                 cost_rad = torch.cdist(out_rad_i, tgt_rad_i, p=1)

#             # Final cost matrix
#             C_i = (
#                     self.cost_bbox * cost_bbox
#                     + self.cost_class * cost_class
#                     + self.cost_giou * cost_giou
#                     + self.cost_rad * cost_rad
#             ) # ï¼ˆ1000ï¼Œ nï¼‰ä»£ä»·çŸ©é˜µ
#             # [num_queries, num_target_boxes]
#             C_i = C_i.view(num_queries, -1).cpu()
#             indice = linear_sum_assignment(C_i) # åŒˆç‰™åˆ©åŒ¹é…ç®—æ³•æ‰¾åˆ°æœ€å°æˆæœ¬åŒ¹é…ï¼Œè¿”å›çš„æ˜¯ä¸€ä¸ªå…ƒç»„ï¼Œä¸¤ä¸ªå…ƒç´ éƒ½æ˜¯æ•°ç»„ï¼Œåˆ†åˆ«è¡¨ç¤ºæœ€ä½³åŒ¹é…çš„è¡Œ/åˆ—ç´¢å¼•
#             indices.append(indice) # æ‰¹æ¬¡ç»“æœ

#         return [(torch.as_tensor(i, dtype=torch.int64), torch.as_tensor(j, dtype=torch.int64)) for i, j in indices] # ç´¢å¼•æ•°ç»„å˜å¼ é‡ ç”±äºgtæ•°é‡è¿œå°äºobject queryæ•°é‡

#     def fuse_features_by_index(self, index_list, feature_list, fusion_func, extra_future, extra_index):
#         """
#         æ ¹æ®ç´¢å¼•å¯¹ç‰¹å¾è¿›è¡Œèåˆã€‚

#         å‚æ•°:
#         - index_list: list of torch.Tensor, å½¢çŠ¶ä¸º (1, n, 1) çš„ç´¢å¼•å¼ é‡åˆ—è¡¨ï¼Œæ¯ä¸ªè¡¨ç¤ºæœ‰æ•ˆçš„ç´¢å¼•ä½ç½®ã€‚ eg. [(1,300,1), (1,62,1)...]
#         - feature_list: list of torch.Tensor, å½¢çŠ¶ä¸º (1, n, C) çš„ç‰¹å¾å›¾å¼ é‡åˆ—è¡¨ã€‚  eg. [(1,300,C), (1,62,C)...]
#         - fusion_func: Callable, è‡ªå®šä¹‰èåˆå‡½æ•°, æ¥å—è¾“å…¥ (n, k, C)ï¼Œè¿”å›èåˆåçš„å¼ é‡ (n, 1, C),
#                     å…¶ä¸­ k è¡¨ç¤ºå‚ä¸èåˆçš„ç‰¹å¾æ•°é‡ã€‚
#         - extra_future: (1, 200, C), egoè‡ªèº«refineäº†500ä¸ªquery, å…¶ä¸­300ä¸ªå‚ä¸èåˆ, å200ä¸ªç”¨äºä»å‰åˆ°åå¡«å……ä¸é‡å çš„å…¶ä»–agentçš„query 
#         - extra_index: (1, 200, 1)

#         è¿”å›:
#         - fused_features: torch.Tensor, èåˆåçš„ç‰¹å¾å¼ é‡, å½¢çŠ¶ä¸º (1, ego_query_num + extra_query_num, C)ã€‚  eg. (1, 300+200, C)
#         """
#         # æ£€æŸ¥è¾“å…¥åˆæ³•æ€§
#         assert len(index_list) == len(feature_list), "ç´¢å¼•åˆ—è¡¨å’Œç‰¹å¾å›¾åˆ—è¡¨é•¿åº¦ä¸ä¸€è‡´"
        
#         # ç»Ÿä¸€å¤„ç†ç´¢å¼•ï¼Œè·å–æ‰€æœ‰å”¯ä¸€ç´¢å¼•
#         all_indices = torch.cat([idx.squeeze(0) for idx in index_list], dim=0)  # (sum(n), 1)
#         # ç›¸åŒçš„ç´¢å¼•æ„å‘³ç€ç›¸åŒçš„ä½ç½®, (n_unique, ) å’Œé€†æ˜ å°„ (sum(n),) è¡¨ç¤ºæ¯ä¸ªå…ƒç´ åœ¨unique_indicesä¸­çš„ä½ç½®
#         # FIXME ä»€ä¹ˆæƒ…å†µ? å³ä½¿è®¾ç½®ä¸ç”¨æ’åºï¼Œä½†æ˜¯æœ€åç»“æœä¾ç„¶æ’åºï¼Œæƒ³è¦ç¨³å®šå»é‡ï¼Œåªèƒ½è‡ªå·±å†™æ±‚unique
#         # unique_indices, inverse_indices = torch.unique(all_indices, sorted=False, return_inverse=True) 

#         seen = set()
#         unique_vals = []
#         for val in all_indices:
#             scalar_val = val.item() # è¿™é‡Œdebugäº†å¥½ä¹…ï¼Œtensorå¯¹è±¡æ˜¯ä¸å¯å“ˆå¸Œçš„ï¼Œæ²¡ææ˜ç™½ç›´æ¥å¯¼è‡´è¿™é‡Œå»é‡å¤±è´¥ï¼Œè¿˜ä¼šå‡ºç°é‡å¤ï¼Œå› æ­¤å¿…é¡»è½¬ä¸ºpythonæ ‡é‡
#             if scalar_val not in seen:
#                 seen.add(scalar_val)
#                 unique_vals.append(scalar_val)
#         unique_indices = torch.tensor(unique_vals).to(all_indices)

#         # æ„å»ºæ¯ä¸ªç´¢å¼•å¯¹åº”çš„ç‰¹å¾åˆ—è¡¨
#         feature_map = {idx.item(): [] for idx in unique_indices} # eg. {id: [(1, C), ...]}
#         for idx, features in zip(index_list, feature_list):
#             for i, ind in enumerate(idx.squeeze(0).squeeze(-1)): # éå†æ¯ä¸ªagentçš„ç´¢å¼•
#                 feature_map[ind.item()].append(features[:, i, :])  # æŒ‰ç´¢å¼•å­˜å…¥ç‰¹å¾ (1, C)

#         # å¯¹æ¯ä¸ªå”¯ä¸€ç´¢å¼•è¿›è¡Œèåˆ ç„¶åé‡æ–°æ”¾å›å» å½¢æˆ{unique_id: [feature]}
#         fused_features = []  # å­˜å‚¨èåˆåçš„ç‰¹å¾
#         for idx in unique_indices:
#             features_to_fuse = torch.stack(feature_map[idx.item()], dim=1)  # (1, k, C) åŒä¸€ä¸ªç©ºé—´ä½ç½®æœ‰å¤šä¸ªfeature, å¯èƒ½æ˜¯egoå’Œå…¶ä»–agentï¼Œä¹Ÿå¯èƒ½æ˜¯agentä¹‹é—´
#             fused_features.append(fusion_func(features_to_fuse)) # èåˆè¿”å›çš„åº”è¯¥æ˜¯(1, 1, C)
#         fused_features = torch.cat(fused_features, dim=1)  # (1, n_unique, C)

#         # ä» fused_features ä¸­æå–å±äº ego çš„ç‰¹å¾
#         ego_indices = index_list[0].squeeze(0).squeeze(-1)  # ego çš„ç´¢å¼• ï¼ˆn1,ï¼‰ egoçš„ç´¢å¼•ä¸ªæ•°æ˜¯å›ºå®šçš„ï¼Œå°±ç­‰äºquery_num
#         ego_mask = torch.isin(unique_indices, ego_indices)  # æ‰¾åˆ°å±äº ego çš„ç´¢å¼• (n_unique, ) egoå¯¹åº”çš„ç´¢å¼•å°±ä¸º True
#         ego_features = fused_features[:, ego_mask, :]  # æå–å±äº ego çš„éƒ¨åˆ† (1, ego_query_size, C)

#         non_overlap_features = []
#         for idx, features in zip(index_list[1:], feature_list[1:]): # å¿½ç•¥ ego
#             mask = ~torch.isin(idx.squeeze(0), index_list[0].squeeze(0)) # éé‡å éƒ¨åˆ† (n_unique, 1) XXX é¦–å…ˆå®Œå…¨é‡å ä¸å¯èƒ½ï¼Œé‚£åªæœ‰ä¸€ç§å¯èƒ½ï¼Œé‚£å°±æ˜¯agentå’Œegoæ„ŸçŸ¥èŒƒå›´éƒ½ä¸é‡åˆï¼Œæ‰€ä»¥æ ¹æœ¬å°±æ˜¯ç©º
#             selected_features = features[:, mask.squeeze(), :] # æå–éé‡å ç‰¹å¾ (1, k', C)
#             if selected_features.size(1) > 0:
#                 non_overlap_features.append(selected_features)

#         # å°†éé‡å ç‰¹å¾æŒ‰åˆ†æ•°æˆªæ–­å¹¶å¡«å……åˆ°æœ€ç»ˆç»“æœä¸­
#         if len(non_overlap_features) > 0:
#             non_overlap_features = torch.cat(non_overlap_features, dim=1)  # (1, k_all, C)
#             append_num = min(non_overlap_features.size(1), self.extra_query_num) # æœ€å¤§ä¸è¶…è¿‡ extra_query_num
#             extra_future[:, :append_num, :] = non_overlap_features[:,:append_num,:]
#         # else: # é¦–å…ˆèƒ½è¿›å…¥èåˆå‡½æ•°å°±è¯´æ˜æœ‰æŠ•å½±çš„queryå­˜åœ¨ï¼Œç»“æœéé‡å çš„ç‰¹å¾æ˜¯0ï¼Œè¿™å°±è¯´æ˜å…¨éƒ¨æ˜¯é‡å çš„ç‰¹å¾, ç»è¿‡éªŒè¯ï¼Œæ­¤æ—¶æŠ•å½±è¿‡æ¥çš„ç‰¹å¾æ•°é‡å¾ˆå°‘ï¼Œä¸€èˆ¬æ˜¯ä¸ªä½æ•°ï¼Œæå°‘æ•°æ—¶å€™æ˜¯å‡ å
#         #     print("------------------------------------------------")
#         #     print("Oops! All overlap???")
#         #     print("unique_indices shape is ", unique_indices.shape)
#         #     print("agent 1 shape is ", index_list[1].shape)
#         #     print("------------------------------------------------")

#         # æœ€ç»ˆç‰¹å¾: ego + extra_future
#         final_features = torch.cat([ego_features, extra_future], dim=1)  # (1, ego_query_size + etra_query_num, C)

#         unique_indices = unique_indices.unsqueeze(0).unsqueeze(-1) # (1, n_unique, 1)
#         index_num = min(unique_indices.size(1), self.num_queries + self.extra_query_num)
#         assert unique_indices.size(1) >= self.num_queries
#         remain_start = index_num - self.num_queries
#         final_indices = torch.cat([unique_indices[:, :index_num, :], extra_index[:, remain_start:, :]], dim = 1) # 500
#         return final_features, final_indices


# def generalized_box3d_iou(boxes1, boxes2):

#     boxes1 = torch.nan_to_num(boxes1)
#     boxes2 = torch.nan_to_num(boxes2)

#     assert (boxes1[3:] >= boxes1[:3]).all()
#     assert (boxes2[3:] >= boxes2[:3]).all()

#     iou, union = box_iou_wo_angle(boxes1, boxes2)

#     ltb = torch.min(boxes1[:, None, :3], boxes2[:, :3])  # [N,M,3]
#     rbf = torch.max(boxes1[:, None, 3:], boxes2[:, 3:])  # [N,M,3]

#     whl = (rbf - ltb).clamp(min=0)  # [N,M,3]
#     vol = whl[:, :, 0] * whl[:, :, 1] * whl[:, :, 2]

#     return iou - (vol - union) / vol # æ ‡å‡† IoU - (åŒ…å›´ç›’ä½“ç§¯ - å¹¶é›†ä½“ç§¯) / åŒ…å›´ç›’ä½“ç§¯
