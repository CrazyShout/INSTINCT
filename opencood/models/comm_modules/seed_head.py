import copy

import math
import numpy as np
import torch
import torch.distributed as dist
import torch.nn.functional as F
from torch import nn

from opencood.pcdet_utils.roiaware_pool3d import roiaware_pool3d_utils
from opencood.pcdet_utils.iou3d_nms import iou3d_nms_utils
from .target_assigner.hungarian_assigner_qs import HungarianMatcher3d, generalized_box3d_iou, \
    box_cxcyczlwh_to_xyxyxy
from opencood.models.sub_modules.cdn import prepare_for_cdn, dn_post_process_w_ious
from opencood.models.sub_modules.seed_transformer import SEEDTransformer, MLP, get_clones


def inverse_sigmoid(x, eps=1e-5):
    x = x.clamp(min=0, max=1)
    x1 = x.clamp(min=eps)
    x2 = (1 - x).clamp(min=eps)
    return torch.log(x1 / x2)


class PositionEmbeddingSine(nn.Module):
    def __init__(self, num_pos_feats=64, temperature=10000, normalize=False, scale=None):
        super().__init__()
        self.num_pos_feats = num_pos_feats # 128
        self.temperature = temperature
        self.normalize = normalize
        if scale is not None and normalize is False:
            raise ValueError("normalize should be True if scale is passed")
        if scale is None:
            scale = 2 * math.pi
        self.scale = scale

    def forward(self, x, mask=None):
        if mask is not None:
            not_mask = ~mask
            y_embed = not_mask.cumsum(1, dtype=torch.float32)
            x_embed = not_mask.cumsum(2, dtype=torch.float32)
        else:
            size_h, size_w = x.shape[-2:]
            y_embed = torch.arange(1, size_h + 1, dtype=x.dtype, device=x.device)
            x_embed = torch.arange(1, size_w + 1, dtype=x.dtype, device=x.device)
            y_embed, x_embed = torch.meshgrid(y_embed, x_embed)
            x_embed = x_embed.unsqueeze(0).repeat(x.shape[0], 1, 1)
            y_embed = y_embed.unsqueeze(0).repeat(x.shape[0], 1, 1)

        if self.normalize:
            eps = 1e-6
            y_embed = (y_embed - 0.5) / (y_embed[:, -1:, :] + eps) * self.scale
            x_embed = (x_embed - 0.5) / (x_embed[:, :, -1:] + eps) * self.scale

        dim_t = torch.arange(self.num_pos_feats, dtype=torch.float32, device=x.device)
        dim_t = self.temperature ** (2 * dim_t.div(2, rounding_mode="floor") / self.num_pos_feats) # (128, )

        pos_x = x_embed[:, :, :, None] / dim_t # b, h, w, 1 é™¤ä»¥ é¢‘ç‡ç¼©æ”¾å ä¸º b, h, w, 128
        pos_y = y_embed[:, :, :, None] / dim_t
        pos_x = torch.stack((pos_x[:, :, :, 0::2].sin(), pos_x[:, :, :, 1::2].cos()), dim=4).flatten(3) # b, h, w, 128
        pos_y = torch.stack((pos_y[:, :, :, 0::2].sin(), pos_y[:, :, :, 1::2].cos()), dim=4).flatten(3)
        pos = torch.cat((pos_y, pos_x), dim=3).permute(0, 3, 1, 2)

        return pos


class Det3DHead(nn.Module):
    def __init__(self, hidden_dim, num_classes=3, code_size=7, num_layers=1):
        super().__init__()
        class_embed = MLP(hidden_dim, hidden_dim, num_classes, 3) # (B, L, 3)
        bbox_embed = MLP(hidden_dim, hidden_dim, code_size, 3) # (B, L, 7)

        prior_prob = 0.01
        bias_value = -math.log((1 - prior_prob) / prior_prob)
        class_embed.layers[-1].bias.data = torch.ones(num_classes) * bias_value # æœ€åä¸€ä¸ªçº¿æ€§å±‚çš„åç½®è¿›è¡Œåˆå§‹åŒ–
        nn.init.constant_(bbox_embed.layers[-1].weight.data, 0)
        nn.init.constant_(bbox_embed.layers[-1].bias.data, 0)

        self.class_embed = get_clones(class_embed, num_layers)
        self.bbox_embed = get_clones(bbox_embed, num_layers)

        iou_embed = MLP(hidden_dim, hidden_dim, 1, 3) # æ¯ä¸ªé¢„æµ‹æ¡†çš„IoUä¼°è®¡å€¼
        nn.init.constant_(iou_embed.layers[-1].weight.data, 0)
        nn.init.constant_(iou_embed.layers[-1].bias.data, 0)
        self.iou_embed = get_clones(iou_embed, num_layers)

    def forward(self, embed, anchors, layer_idx=0):
        cls_logits = self.class_embed[layer_idx](embed)
        box_coords = (self.bbox_embed[layer_idx](embed) + inverse_sigmoid(anchors)).sigmoid() # è¿™é‡Œç±»ä¼¼é”šæ¡†çš„æœºåˆ¶ï¼Œé€†è½¬å›å®æ•°ç©ºé—´åŠ ä¸Šé¢„æµ‹çš„åç§»ï¼Œæœ€åé‡æ–°å½’ä¸€åŒ–
        pred_iou = (self.iou_embed[layer_idx](embed)).clamp(-1, 1)
        return cls_logits, box_coords, pred_iou


class MaskPredictor(nn.Module):
    def __init__(self, hidden_dim):
        super(MaskPredictor, self).__init__()
        self.hidden_dim = hidden_dim
        self.layer1 = nn.Sequential(
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, hidden_dim),
            nn.GELU()
        )
        self.layer2 = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.GELU(),
            nn.Linear(hidden_dim // 2, hidden_dim // 4),
            nn.GELU(),
            nn.Linear(hidden_dim // 4, 1)
        )

    def forward(self, x):
        b, c, h, w = x.size()
        x = x.reshape([b, c, -1]).permute(0, 2, 1)
        z = self.layer1(x)
        z_local, z_global = torch.split(z, self.hidden_dim // 2, dim=-1) # åˆ†æˆä¸¤éƒ¨åˆ† éƒ½æ˜¯ b,hxw, 128
        z_global = z_global.mean(dim=1, keepdim=True).expand(-1, z_local.shape[1], -1) # å…¨å±€çš„å‡å€¼ å½¢çŠ¶ä¸å˜
        z = torch.cat([z_local, z_global], dim=-1)
        out = self.layer2(z) # b, hxw, 1
        out = out.reshape([b, h, w])
        return out


class SEEDHead(nn.Module):
    def __init__(
            self,
            model_cfg, input_channels, num_class, class_names, grid_size, point_cloud_range, voxel_size,
            predict_boxes_when_training=True, train_flag=True
    ):
        super(SEEDHead, self).__init__()

        self.grid_size = grid_size # [2016, 800, 50]
        self.point_cloud_range = point_cloud_range # [-75.2, -75.2, -2, 75.2, 75.2, 4]
        self.voxel_size = voxel_size # [0.1, 0.1, 0.15]
        self.feature_map_stride = model_cfg['feature_map_stride'] # 8
        self.num_classes = num_class # 1

        self.model_cfg = model_cfg
        self.train_flag = train_flag

        self.hidden_channel = self.model_cfg['hidden_channel'] # 256
        self.num_queries = self.model_cfg['num_queries'] # 1000
        self.aux_loss = self.model_cfg['loss_config']['aux_loss'] # True
        self.keep_ratio = self.model_cfg['keep_ratio'] # 0.3
        self.iou_cls = self.model_cfg['iou_cls'] # [0]
        self.iou_rectifier = self.model_cfg['iou_rectifier'] # 0.68

        num_heads = self.model_cfg['num_heads'] # 8
        dropout = self.model_cfg['dropout'] # 0.0
        activation = self.model_cfg['activation']
        ffn_channel = self.model_cfg['ffn_channel'] # 1024
        num_decoder_layers = self.model_cfg['num_decoder_layers'] # 6
        self.code_size = self.model_cfg['code_size'] # 7

        cp_flag = self.model_cfg['cp'] # True

        self.dn = self.model_cfg['dn']

        self.input_proj = nn.Sequential(
            nn.Conv2d(input_channels, self.hidden_channel, kernel_size=1),
            nn.GroupNorm(32, self.hidden_channel),
        )

        self.pos_embed = PositionEmbeddingSine(self.hidden_channel // 2)

        for module in self.input_proj.modules():
            if isinstance(module, nn.Conv2d):
                nn.init.xavier_uniform_(module.weight, gain=1)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)

        self.mask_predictor = MaskPredictor(self.hidden_channel)

        self.transformer = SEEDTransformer(
            d_model=self.hidden_channel, # 256
            nhead=num_heads, # 8
            nlevel=1,
            num_decoder_layers=num_decoder_layers, # 6
            dim_feedforward=ffn_channel, # 1024
            dropout=dropout, # 0.0
            activation=activation, # gelu
            num_queries=self.num_queries, # 1000
            keep_ratio=self.keep_ratio, # 0.3
            code_size=self.code_size, # 7
            iou_rectifier=self.iou_rectifier, # [ 0.68, 0.71, 0.65 ]
            iou_cls=self.iou_cls, # [0, 1]
            num_classes=num_class, # 3
            cp_flag=cp_flag # True
        )

        self.transformer.proposal_head = Det3DHead(
            self.hidden_channel,
            code_size=self.code_size,
            num_classes=num_class,
            num_layers=1,
        )
        self.transformer.decoder.detection_head = Det3DHead(
            self.hidden_channel,
            code_size=self.code_size,
            num_classes=num_class,
            num_layers=num_decoder_layers,
        )

        if self.train_flag and self.dn['enabled']:
            contras_dim = self.model_cfg['contrastive']['dim'] # 256
            self.eqco = self.model_cfg['contrastive']['eqco'] # 1000
            self.tau = self.model_cfg['contrastive']['tau'] # 0.7
            self.contras_loss_coeff = self.model_cfg['contrastive']['loss_coeff'] # 0.2
            self.projector = nn.Sequential(
                nn.Linear(self.code_size + self.num_classes, contras_dim),
                nn.ReLU(),
                nn.Linear(contras_dim, contras_dim),
            )
            self.predictor = nn.Sequential(
                nn.Linear(contras_dim, contras_dim),
                nn.ReLU(),
                nn.Linear(contras_dim, contras_dim),
            )
            self.similarity_f = nn.CosineSimilarity(dim=2)

            self.transformer.decoder_gt = copy.deepcopy(self.transformer.decoder)
            for param_q, param_k in zip(self.transformer.decoder.parameters(),
                                        self.transformer.decoder_gt.parameters()):
                param_k.data.copy_(param_q.data)  # initialize
                param_k.requires_grad = False  # not update by gradient

        self.assigner = HungarianMatcher3d(
            cost_class=self.model_cfg['target_assigner_config']['hungarian_assigner']['cls_cost'],   # 1.0
            cost_bbox=self.model_cfg['target_assigner_config']['hungarian_assigner']['bbox_cost'],   # 4.0
            cost_giou=self.model_cfg['target_assigner_config']['hungarian_assigner']['iou_cost'],    # 2.0
            cost_rad=self.model_cfg['target_assigner_config']['hungarian_assigner']['rad_cost'],     # 4.0
            decode_bbox_func=self.decode_bbox,
            iou_rectifier = self.iou_rectifier,
            iou_cls=self.iou_cls # [0, 1]
        )

        weight_dict = {
            "loss_ce": self.model_cfg['target_assigner_config']['hungarian_assigner']['cls_cost'],
            "loss_bbox": self.model_cfg['target_assigner_config']['hungarian_assigner']['bbox_cost'],
            "loss_giou": self.model_cfg['target_assigner_config']['hungarian_assigner']['iou_cost'],
            "loss_rad": self.model_cfg['target_assigner_config']['hungarian_assigner']['rad_cost'],
        }
        losses = ["focal_labels", "boxes"]
        self.losses = Det3DLoss(
            matcher=self.assigner,
            weight_dict=weight_dict,
            losses=losses,
            decode_func=self.decode_bbox,
            aux_loss=self.aux_loss
        )

        # setup aux loss weight
        if self.aux_loss:
            aux_weight_dict = {}
            if hasattr(self.losses, "weight_dict"):
                aux_weight_dict.update({k + f"_dn": v for k, v in self.losses.weight_dict.items()}) # å¢åŠ äº†{'loss_ce_dn': 1.0, ...} æ˜¯ç»™dnä½¿ç”¨çš„
                for i in range(num_decoder_layers - 1): # è®¾ç½®5å±‚çš„dnæŸå¤±çš„æƒé‡
                    aux_weight_dict.update({k + f"_dn_{i}": v for k, v in self.losses.weight_dict.items()})
                    aux_weight_dict.update({k + f"_{i}": v for k, v in self.losses.weight_dict.items()})
                self.losses.weight_dict.update(aux_weight_dict)

    def predict(self, batch_dict):
        batch_size = batch_dict['batch_size']
        spatial_features_2d = batch_dict['spatial_features_2d'] # B, 512, H, W

        features = []
        pos_encodings = []
        features.append(self.input_proj(spatial_features_2d)) # æ”¾å…¥ä¸€ä¸ªBï¼Œ256ï¼ŒHï¼ŒW
        pos_encodings.append(self.pos_embed(spatial_features_2d)) # ä½ç½®ç¼–ç  Bï¼Œ256ï¼Œ Hï¼Œ W

        score_mask = self.mask_predictor(features[0]) # B, H, W

        dn = self.dn
        if self.train_flag and dn['enabled'] and dn['dn_number'] > 0:
            gt_boxes = batch_dict['object_bbx_center'] # B, maxnum, 7
            gt_boxes_mask = batch_dict['object_bbx_mask'] # B, maxnum
            targets = list() # åˆ—è¡¨å­˜æ”¾æ¯ä¸ªæ ·æœ¬çš„æ ‡ç­¾
            for batch_idx in range(batch_size):
                target = {}
                gt_bboxes = gt_boxes[batch_idx] # (maxnum, 7)
                gt_bboxes_mask = gt_boxes_mask[batch_idx] # (maxnum, )
                valid_box = gt_bboxes[gt_bboxes_mask.bool()] # ï¼ˆn_idx, 7ï¼‰
                gt_labels = torch.ones(valid_box.size(0), device=valid_box.device, dtype=valid_box.dtype)
                target['gt_boxes'] = self.encode_bbox(valid_box) # ç»™gt boxåšå¥½å½’ä¸€åŒ–å·¥ä½œ
                target['labels'] = gt_labels.long() - 1 # (n_idx, )
                targets.append(target)

            '''
            è‹¥targetsä¸­æ¯ä¸ªæ ·æœ¬çš„gt objet ä¸ªæ•°ä¸º n1, n2 å…¶ä¸­ n2 æœ€å¤§ è®°ä½œ max_gt_num
            input_query_label: (B, pad_size, num_classes) num_classes=1 å…¶å®è¿™é¡¹æ²¡ä»€ä¹ˆæ„ä¹‰ TODO delete
            input_query_bbox: (B, pad_size, 7)
            attn_mask: (1000+pad_size, 1000+pad_size)
            dn_meta: {'pad_size': 2 * max_gt_num * 3, 'num_dn_group': 3}
            å…¶ä¸­2 * max_gt_num * 3 = pad_size, n1 n2æ˜¯batchsize=2æ—¶çš„å‡è®¾, n2>n1, è¿™ä¸ªä¹˜æ³•å¼è¡¨ç¤ºæœ‰ä¸‰ç»„å™ªå£°ï¼Œæ¯ç»„åˆ†æ­£è´Ÿæ ·æœ¬ï¼Œæ­£æ ·æœ¬åšé‡å»ºï¼Œè´Ÿæ ·æœ¬è¦å­¦ä¼šå‰”é™¤
            '''
            input_query_label, input_query_bbox, attn_mask, dn_meta = prepare_for_cdn(
                dn_args=(targets, dn['dn_number'],dn['dn_label_noise_ratio'], dn['dn_box_noise_scale']),
                training=self.train_flag,
                num_queries=self.num_queries,
                num_classes=self.num_classes,
                hidden_dim=self.hidden_channel,
                label_enc=None,
                code_size=self.code_size,
            ) # è¿™ä¸€æ­¥å‡†å¤‡å™ªå£°æ ·æœ¬
        else:
            input_query_bbox = input_query_label = attn_mask = dn_meta = None
            targets = None

        outputs = self.transformer(
            features, # [(B, 256, H, W)]
            pos_encodings, # [(B, 256, H, W)]
            input_query_bbox, # (B, pad_size, 7)
            input_query_label, # (B, pad_size, num_classes) num_classes=1
            attn_mask, # (1000+pad_size, 1000+pad_size)
            targets=targets, # [Sample1:Dict, Sample2:Dict...]
            score_mask=score_mask, # (B, H, W)
        )
        '''
        hidden_state: (6, B, pad_size + 1000 + 4*max_gt_num, 256) pad_sizeå…¶å®ç­‰äº 6*max_gt_num è¿™æ˜¯6å±‚decoderçš„è¾“å‡º
        init_reference: (B, pad_size + 1000 + 4*max_gt_num, 7) 6æ‰¹å™ªå£°gt+åˆå§‹çš„dqså¾—åˆ°çš„1000ä¸ªbox åŠ ä¸Š 4æ‰¹ gt, ç¬¬ä¸€æ‰¹æ˜¯gt,åé¢3æ‰¹ç¤ºå™ªå£°gtæ­£æ ·æœ¬
        inter_references: (6, B, pad_size + 1000 + 4*max_gt_num, 10) pad_sizeå…¶å®ç­‰äº 6*max_gt_numã€‚ è¿™æ˜¯æ¯ä¸€å±‚çš„é¢„æµ‹ç»“æœ
        src_embed: (B, H*W, 256) ç²—æŸ¥è¯¢, ç»è¿‡äº†ä¸€å±‚DGA layeråscatterå›å»
        src_ref_windows: (B, H * W, 7) å‚è€ƒæ¡†ï¼Œç±»ä¼¼äºé”šæ¡†
        src_indexes: (B, 1000, 1) 1000ä¸ªfined dqs query ç´¢å¼•
        '''
        hidden_state, init_reference, inter_references, src_embed, src_ref_windows, src_indexes = outputs

        # decoder
        outputs_classes = []
        outputs_coords = []
        outputs_ious = []
        for idx in range(hidden_state.shape[0]): # è¿™é‡Œæ˜¯éå†6å±‚
            if idx == 0:
                reference = init_reference
            else:
                reference = inter_references[idx - 1]
            outputs_class, outputs_coord, outputs_iou = self.transformer.decoder.detection_head(hidden_state[idx], # æ¯ä¸€å±‚æ˜æ˜å·²ç»äº§å‡ºè¿‡å¯¹åº”çš„ç»“æœäº†ï¼Œä¸ºä»€ä¹ˆæœ‰åˆè¿›è¡Œä¸€éè¾“å‡ºå¤´ï¼Ÿç­”ï¼šå¯¹æ¯”å­¦ä¹ çš„è¾…åŠ©è¾“å‡ºå‚æ•°ä¸åŒæ­¥ï¼Œè¿™é‡Œåº”è¯¥æ˜¯è¿™ä¸ªè€ƒè™‘ï¼Ÿ
                                                                                                reference, idx) # æ ¹æ®æ¯ä¸€å±‚çš„queryç‰¹å¾ï¼Œå’Œreferenceé‡æ–°æ¥ä¸€æ¬¡è¾“å‡ºå¤´ï¼Œä½†æ˜¯ä¸ä¹‹å‰ä¸ä¸€æ ·çš„æ˜¯ï¼Œè¿™æ¬¡ä¼šå¸¦ä¸ŠGTä»¥åŠGTå™ªå£°æ­£æ ·æœ¬ï¼Œ è¿™éƒ¨åˆ†æ¥è‡ªäºå¯¹æ¯”å­¦ä¹ 
            outputs_classes.append(outputs_class)
            outputs_coords.append(outputs_coord)
            outputs_ious.append(outputs_iou)
        outputs_class = torch.stack(outputs_classes) # (6, B, pad_size + 1000 + 4*max_gt_num, 1)
        outputs_coord = torch.stack(outputs_coords) # (6, B, pad_size + 1000 + 4*max_gt_num, 7)
        outputs_iou = torch.stack(outputs_ious) # (6, B, pad_size + 1000 + 4*max_gt_num, 1)

        # dn post process
        '''
        å»å™ªç»„åˆ†å¼€
        outputs_class:  (6, B, 1000 + 4*max_gt_num, 1)
        outputs_coord:  (6, B, 1000 + 4*max_gt_num, 7)
        outputs_iou:    (6, B, 1000 + 4*max_gt_num, 1)
        dn_meta = {
            "pad_size":                 2 * max_gt_num * 3
            "num_dn_group":             3
            "output_known_lbs_bboxes":  {
                "pred_logits":  (B, pad_size, 1) æœ€åä¸€å±‚çš„é¢„æµ‹ç»“æœ è¿™ä¸ªæ˜¯å™ªå£°æ ·æœ¬
                "pred_boxes":   (B, pad_size, 7) 
                "pred_ious":    (B, pad_size, 1) 
                "aux_outputs":  List[Dict{"pred_logits": (B, pad_size, 3), "pred_boxes": (B, pad_size, 7), "pred_ious": (B, pad_size, 1)}, ...] äº”ä¸ªï¼Œè¡¨ç¤ºæ¯ä¸€å±‚çš„å™ªå£°æ ·æœ¬                 
            }
        }
        '''
        if dn['dn_number'] > 0 and dn_meta is not None:
            outputs_class, outputs_coord, outputs_iou = dn_post_process_w_ious(
                outputs_class,
                outputs_coord,
                outputs_iou,
                dn_meta,
                self.aux_loss, # ä½¿ç”¨è¾…åŠ©æŸå¤±
                self._set_aux_loss,
            )

        # only for supervision
        dqs_outputs = None
        if self.train_flag: # é˜²æ­¢æ¢¯åº¦æµè¢«æ±¡æŸ“ï¼ŒDQSåªæ˜¯è¾…åŠ©ç­›é€‰queryï¼Œç­›é€‰æ—¶ä¸èƒ½å‚ä¸æ¢¯åº¦è®¡ç®—ï¼Œå¦åˆ™è®­ç»ƒæ—©æœŸä½è´¨é‡çš„queryä¼šå¤§å¹…åº¦å½±å“ç»“æœï¼Œå› æ­¤åœ¨DQSä¸­å¿…é¡»è¦detach
            dqs_class, dqs_coords, dqs_ious = self.transformer.proposal_head(src_embed, src_ref_windows) # è¿™ä¸ªä¹‹å‰æ˜¯dqsæ‰“åˆ†ç”¨çš„ï¼Œè¿™é‡Œè¾“å…¥çš„æ˜¯å’Œå½“æ—¶ä¸€æ ·çš„è¾“å…¥ï¼Œå³è·å¾—å½“æ—¶çš„æ‰“åˆ†ç»“æœï¼Œæ³¨æ„ï¼Œç­›é€‰æ“ä½œå­˜åœ¨detachæ“ä½œï¼Œåˆ†å¼€åˆ°è¿™é‡ŒåšæŸå¤±å®é™…ä¸Šæ˜¯é˜²æ­¢æ¢¯åº¦æµè¢«æ±¡æŸ“
            dqs_outputs = {
                'topk_indexes': src_indexes,    # (B, 1000, 1) # é€šè¿‡dqsæŒ‘é€‰çš„1000ä¸ªqueryçš„ç´¢å¼•
                'pred_logits': dqs_class,       # (B, H*W, 1)
                'pred_boxes': dqs_coords,       # (B, H*W, 7)
                'pred_ious': dqs_ious           # (B, H*W, 1)
            }

        # compute decoder losses
        outputs = {
            "pred_scores_mask": score_mask, # (B, H, W)
            "pred_logits": outputs_class[-1][:, : self.num_queries],    # (B, 1000, 1) # æœ€åä¸€å±‚
            "pred_boxes": outputs_coord[-1][:, : self.num_queries],     # (B, 1000, 7)
            'pred_ious': outputs_iou[-1][:, : self.num_queries],        # (B, 1000, 1)
            "aux_outputs": self._set_aux_loss(
                outputs_class[:-1, :, : self.num_queries], outputs_coord[:-1, :, : self.num_queries],
                outputs_iou[:-1, :, : self.num_queries],                # List[Dict{"pred_logits": (B, 1000, 3), "pred_boxes": (B, 1000, 7), "pred_ious": (B, 1000, 1)}, ...] 5ä¸ªå…ƒç´  è¡¨ç¤ºå‰äº”å±‚çš„1000ä¸ªquery
            ),
        }
        if self.train_flag:
            '''
            pred_dicts:         {"dqs_outputs":  Dict()
                                "outputs":      Dict()}
            outputs_class:      (6, B, 1000 + 4*max_gt_num, 1)
            outputs_coord:      (6, B, 1000 + 4*max_gt_num, 7)
            outputs_iou:        (6, B, 1000 + 4*max_gt_num, 1)
            dn_meta:            Dict() å»å™ªæ•°æ®
            '''
            pred_dicts = dict(dqs_outputs=dqs_outputs, outputs=outputs)
            return pred_dicts, outputs_class, outputs_coord, outputs_iou, dn_meta
        else:
            pred_dicts = dict(dqs_outputs=dqs_outputs, outputs=outputs)
            return pred_dicts

    def forward(self, batch_dict):
        if self.train_flag:
            pred_dicts, outputs_class, outputs_coord, outputs_iou, dn_meta = self.predict(batch_dict)
        else:
            pred_dicts = self.predict(batch_dict)

        if not self.train_flag:
            bboxes = self.get_bboxes(pred_dicts)
            batch_dict['final_box_dicts'] = bboxes
        else:
            gt_bboxes_3d = batch_dict['object_bbx_center'] # (B, maxnum, 7)
            gt_bboxes_3d_mask = batch_dict['object_bbx_mask'] # (B, maxnum)
            gt_labels_3d = gt_bboxes_3d.new_ones(gt_bboxes_3d_mask.size(0), gt_bboxes_3d_mask.size(1))
            gt_labels_3d = gt_labels_3d.long() - 1 # (B, maxnum)

            loss, tb_dict = self.loss(gt_bboxes_3d, gt_bboxes_3d_mask, gt_labels_3d, pred_dicts, dn_meta, outputs_class, outputs_coord,
                                      outputs_iou)
            batch_dict['loss'] = loss
            batch_dict['tb_dict'] = tb_dict
        return batch_dict

    def get_bboxes(self, pred_dicts):
        outputs = pred_dicts['outputs']
        out_logits = outputs['pred_logits'] # (B, 1000, 1) Båœ¨éªŒè¯æˆ–è€…æµ‹è¯•çš„æ—¶å€™ä¸€å®šæ˜¯ ==1
        out_bbox = outputs['pred_boxes'] # (B, 1000, 7)
        out_iou = (outputs['pred_ious'] + 1) / 2 # (B, 1000, 1) æ˜ å°„åˆ°0-1
        batch_size = out_logits.shape[0]

        out_iou = out_iou.repeat([1, 1, out_logits.shape[-1]])
        out_iou = out_iou.view(out_logits.shape[0], -1) # ï¼ˆB, 1000ï¼‰

        out_prob = out_logits.sigmoid()
        out_prob = out_prob.view(out_logits.shape[0], -1) # (B, 1000)
        out_bbox = self.decode_bbox(out_bbox)

        def _process_output(indices, bboxes):
            topk_boxes = indices.div(out_logits.shape[2], rounding_mode="floor").unsqueeze(-1)
            labels = indices % out_logits.shape[2] # å¾—åˆ°æ ‡ç­¾
            boxes = torch.gather(bboxes, 0, topk_boxes.repeat(1, out_bbox.shape[-1]))
            return labels + 1, boxes, topk_boxes

        new_ret_dict = []
        for i in range(batch_size):
            out_prob_i = out_prob[i] # ï¼ˆ1000ï¼Œï¼‰
            out_bbox_i = out_bbox[i] # (1000, 7)

            out_iou_i = out_iou[i] # (1000, )
            '''
            # out_prob_i_ori = out_prob_i.view(out_bbox_i.shape[0], -1)  # [1000, 3]
            # max_out_prob_i, pred_cls = torch.max(out_prob_i_ori, dim=-1)
            # out_iou_i_ori = out_iou_i.view(out_bbox_i.shape[0], -1)
            #
            # out_prob_i_list = []
            # out_bbox_i_list = []
            # out_iou_i_list = []
            #
            # ONLY_FOR_CAR = True
            #
            # for cls in range(self.num_classes):
            #     cls_mask = pred_cls == cls
            #     if cls_mask.sum() >= 1:
            #         out_prob_i_cls_valid = out_prob_i_ori[cls_mask]
            #         out_bbox_i_cls_valid = out_bbox_i[cls_mask]
            #         out_iou_i_cls_valid = out_iou_i_ori[cls_mask]
            #         max_out_prob_i_cls_valid = max_out_prob_i[cls_mask]
            #
            #         if ONLY_FOR_CAR & (cls == 0):  # 0 is for CAR
            #             out_bbox_i_xy = (out_bbox_i_cls_valid[:, :2] - torch.Tensor(
            #                 self.point_cloud_range[0:2]).unsqueeze(0).type_as(
            #                 out_bbox_i_cls_valid)) * 4  # 4 for large objects, such as car
            #             out_bbox_i_xy = torch.round(out_bbox_i_xy).int()
            #             sort_xy = out_bbox_i_xy[:, 0] * 1000 + out_bbox_i_xy[:, 1]
            #             unq_coords, unq_inv, unq_cnt = torch.unique(sort_xy, return_inverse=True, return_counts=True,
            #                                                         dim=0)
            #
            #             out, valid_mask = scatter_max(max_out_prob_i_cls_valid, unq_inv)
            #
            #             out_prob_i_tmp = out_prob_i_cls_valid[valid_mask].view(-1)
            #             out_bbox_i_tmp = out_bbox_i_cls_valid[valid_mask]
            #             out_iou_i_tmp = out_iou_i_cls_valid[valid_mask].view(-1)
            #
            #         else:
            #             out_bbox_i_xy = (out_bbox_i_cls_valid[:, :2] - torch.Tensor(
            #                 self.point_cloud_range[0:2]).unsqueeze(0).type_as(
            #                 out_bbox_i_cls_valid)) * 20
            #             out_bbox_i_xy = torch.round(out_bbox_i_xy).int()
            #             sort_xy = out_bbox_i_xy[:, 0] * 1000 + out_bbox_i_xy[:, 1]
            #             unq_coords, unq_inv, unq_cnt = torch.unique(sort_xy, return_inverse=True, return_counts=True,
            #                                                         dim=0)
            #
            #             out, valid_mask = scatter_max(max_out_prob_i_cls_valid, unq_inv)
            #
            #             out_prob_i_tmp = out_prob_i_cls_valid[valid_mask].view(-1)
            #             out_bbox_i_tmp = out_bbox_i_cls_valid[valid_mask]
            #             out_iou_i_tmp = out_iou_i_cls_valid[valid_mask].view(-1)
            #
            #         out_prob_i_list.append(out_prob_i_tmp)
            #         out_bbox_i_list.append(out_bbox_i_tmp)
            #         out_iou_i_list.append(out_iou_i_tmp)
            #
            # out_prob_i = torch.cat(out_prob_i_list, dim=0)
            # out_bbox_i = torch.cat(out_bbox_i_list, dim=0)
            # out_iou_i = torch.cat(out_iou_i_list, dim=0)
            '''
            topk_indices_i = torch.nonzero(out_prob_i >= 0.1, as_tuple=True)[0] # ç­›é€‰ç½®ä¿¡åº¦å¤§äº0.1çš„çš„ç´¢å¼• (n, )
            scores = out_prob_i[topk_indices_i] # (n, ) è¿™ä¸ªå› ä¸ºå¤šclsä¹Ÿæ˜¯ç›¸åŒçš„repeat æ‰€ä»¥ä¸ç”¨ä¸Šé¢çš„æ“ä½œ

            labels, boxes, topk_indices = _process_output(topk_indices_i.view(-1), out_bbox_i) # åˆ†åˆ«å¾—åˆ°æ ‡ç­¾å’Œbbox shape ä¸º (n, ) and (n, 7)

            ious = out_iou_i[topk_indices_i] # (n, )

            scores_list = list()
            labels_list = list()
            boxes_list = list()

            for c in range(self.num_classes):
                mask = (labels - 1) == c # å¯¹äºåˆ†ç±»æ— å…³æ¥è¯´å…¶å®æ˜¯å…¨True ï¼Œ(n, ), å¯¹äºå¤šåˆ†ç±»çš„æ¥è¯´å…¶å®å°±æ˜¯ä¾æ¬¡å¤„ç†æ¯ä¸ªåˆ†ç±»ç”¨çš„
                scores_temp = scores[mask]
                ious_temp = ious[mask]
                labels_temp = labels[mask]
                boxes_temp = boxes[mask]

                if c in self.iou_cls:
                    if isinstance(self.iou_rectifier, list):
                        iou_rectifier = torch.tensor(self.iou_rectifier).to(out_prob)[c]
                        scores_temp = torch.pow(scores_temp, 1 - iou_rectifier) * torch.pow(ious_temp,
                                                                                            iou_rectifier)
                    elif isinstance(self.iou_rectifier, float): # ç±»åˆ«æ— å…³ 0.68 è¿™åˆæ˜¯åœ¨ç®—è´¨é‡å¾—åˆ†
                        scores_temp = torch.pow(scores_temp, 1 - self.iou_rectifier) * torch.pow(ious_temp,
                                                                                                 self.iou_rectifier)
                    else:
                        raise TypeError('only list or float')


                scores_list.append(scores_temp)
                labels_list.append(labels_temp)
                boxes_list.append(boxes_temp)

            scores = torch.cat(scores_list, dim=0) # (n,)
            labels = torch.cat(labels_list, dim=0) # (n,) åœ¨ç±»åˆ«æ— å…³ä¸­ï¼Œå…¶å®labelæ˜¯å…¨0
            boxes = torch.cat(boxes_list, dim=0) # (n,7)
            ret = dict(pred_boxes=boxes, pred_scores=scores, pred_labels=labels)
            new_ret_dict.append(ret)

        return new_ret_dict

    def compute_losses(self, outputs, targets, dn_meta=None):
        loss_dict = self.losses(outputs, targets, dn_meta=dn_meta)

        weight_dict = self.losses.weight_dict
        for k, v in loss_dict.items():
            if k in weight_dict:
                loss_dict[k] = v * weight_dict[k]

        return loss_dict

    def compute_score_losses(self, pred_scores_mask, gt_bboxes_3d, gt_bboxes_3d_mask, foreground_mask):
        '''
        pred_scores_mask: å‰æ™¯é¢„æµ‹, (B, H, W)
        gt_bboxes_3d: (B, max_num, 7)
        '''
        gt_bboxes_3d = copy.deepcopy(gt_bboxes_3d)
        grid_size = torch.ceil(torch.from_numpy(self.grid_size).to(gt_bboxes_3d) / self.feature_map_stride) # ç©ºé—´å…«å€ä¸‹é‡‡æ ·åçš„å°ºå¯¸ [252, 100, 50/8]
        pc_range = torch.from_numpy(np.array(self.point_cloud_range)).to(gt_bboxes_3d) # [-100.8, -40, -3.5, 100.8, 40, 1.5] ç‚¹äº‘å°ºå¯¸
        stride = (pc_range[3:5] - pc_range[0:2]) / grid_size[0:2] # å®é™…å°ºå¯¸å’Œç‰¹å¾å›¾çš„å·®è·
        gt_score_map = list()
        yy, xx = torch.meshgrid(torch.arange(grid_size[1]), torch.arange(grid_size[0])) # ä¸¤ä¸ªéƒ½æ˜¯ï¼ˆ100ï¼Œ 252ï¼‰
        points = torch.stack([yy, xx]).permute(1, 2, 0).flip(-1) # (100, 252, 2) æœ€åä¸€ä¸ªåè½¬æ“ä½œå°†å­˜å‚¨æ–¹æ³•è®¾ç½®ä¸º(x,y)æ ¼å¼
        points = torch.cat([points, torch.ones_like(points[..., 0:1]) * 0.5], dim=-1).reshape([-1, 3]) # ï¼ˆ100*252ï¼Œ 3ï¼‰æ–°å¢çš„ç»´åº¦é‡Œé¢å­˜çš„éƒ½æ˜¯0.5 ä¹Ÿå°±æ˜¯zè½´åæ ‡éƒ½æ˜¯0.5
        for i in range(len(gt_bboxes_3d)):
            boxes = gt_bboxes_3d[i] # ï¼ˆmax_num, 7ï¼‰
            boxes_mask = gt_bboxes_3d_mask[i].bool() # (max_num,)
            boxes = boxes[boxes_mask] # (n_i, 7)
            # boxes = boxes[(boxes[:, 3] > 0) & (boxes[:, 4] > 0)] # è¿™ç­›é€‰å‡ºæœ‰æ•ˆçš„éƒ¨åˆ†
            ones = torch.ones_like(boxes[:, 0:1]) # (n_i, 1)
            bev_boxes = torch.cat([boxes[:, 0:2], ones * 0.5, boxes[:, 3:5], ones * 0.5, boxes[:, 6:7]], dim=-1) # å»é™¤zè½´ï¼Œå…¨éƒ¨å¡«å……0.5 (n_i, 7)
            bev_boxes[:, 0:2] -= pc_range[0:2] # å‡å»è¾¹ç•Œæœ€å°å€¼ å¾—åˆ°ç›¸å¯¹åç§»
            bev_boxes[:, 0:2] /= stride # å¾—åˆ°åœ¨ç‰¹å¾å›¾ä¸­çš„ä½ç½®
            bev_boxes[:, 3:5] /= stride # å¾—åˆ°åœ¨ç‰¹å¾å›¾ä¸­çš„é•¿å®½

            box_ids = roiaware_pool3d_utils.points_in_boxes_gpu(
                points[:, 0:3].unsqueeze(dim=0).float().cuda(), # ï¼ˆ1ï¼Œ HWï¼Œ 3ï¼‰
                bev_boxes[:, 0:7].unsqueeze(dim=0).float().cuda() # ï¼ˆ1, n_i, 7ï¼‰
            ).long().squeeze(dim=0).cpu().numpy() # (1, HW) ä¸ç­‰äº-1çš„éƒ¨åˆ†å°±æ˜¯æ²¡æœ‰è½åœ¨ä»»ä½•ä¸€ä¸ªboxä¸­
            box_ids = box_ids.reshape([grid_size[1].long(), grid_size[0].long()]) # (100, 252) 
            mask = torch.from_numpy(box_ids != -1).to(bev_boxes) # (100, 252) 
            gt_score_map.append(mask)
        gt_score_map = torch.stack(gt_score_map) # (B, 100, 252) åœ¨boxçš„éƒ¨åˆ†è¢«æ ‡è®°ä¸ºTrue

        num_pos = max(gt_score_map.eq(1).float().sum().item(), 1) # maxä¿è¯è‡³å°‘ä¸º1ï¼Œè¿™æ˜¯ç®—æ‰€æœ‰ä½ç½®çš„ä¸ªæ•°ï¼Œä¹Ÿå°±æ˜¯æ‰€æœ‰å‰æ™¯ç‚¹çš„ä¸ªæ•°
        
        loss_score = ClassificationLoss.sigmoid_focal_loss(
            pred_scores_mask.flatten(0), # å±•å¹³ (BHW, )
            gt_score_map.flatten(0), # (BHW)
            0.25,
            gamma=2.0,
            reduction="sum",
        )
        loss_score /= num_pos

        return loss_score

    def loss(self, gt_bboxes_3d, gt_bboxes_3d_mask, gt_labels_3d, pred_dicts, dn_meta=None, outputs_class=None, outputs_coord=None,
             outputs_iou=None):
        loss_all = 0
        loss_dict = dict()
        targets = list()

        for batch_idx in range(len(gt_bboxes_3d)): # éå†æ¯ä¸ªæ ·æœ¬
            target = {}
            gt_bboxes = gt_bboxes_3d[batch_idx] # (max_num, 7)
            gt_bboxes_mask = gt_bboxes_3d_mask[batch_idx] # (max_num, )
            gt_labels = gt_labels_3d[batch_idx] # (max_num, )

            valid_bboxes = gt_bboxes[gt_bboxes_mask.bool()]
            valid_labels = gt_labels[gt_bboxes_mask.bool()]

            target['gt_boxes'] = self.encode_bbox(valid_bboxes) # boxesæœ¬èº«æ˜¯torch.float64 è¿™ä¸ªencodeä¼šè®©å®ƒå˜æˆtorch.float32
            target['labels'] = valid_labels
            targets.append(target)

        dqs_outputs = pred_dicts['dqs_outputs']
        bin_targets = copy.deepcopy(targets)
        # [tgt["labels"].fill_(0) for tgt in bin_targets] NOTE è¿™ä¸ªæ˜¯Github Issueæå‡ºçš„ï¼Œæ³¨é‡Šæ‰åå¸¦æ¥äº†0.2-0.3çš„æå‡ï¼Œè¿™æ˜¯ä¸ºä»€ä¹ˆï¼Ÿ å¦‚æœä¸æ³¨é‡Šï¼Œå…¶å®å°±å˜æˆç±»åˆ«æ— å…³é¢„æµ‹
        dqs_losses = self.compute_losses(dqs_outputs, bin_targets) # dqsçš„ç»“æœå…ˆä½œä¸ºdetectè¾“å‡ºç›‘ç£dqsè´¨é‡é€‰æ‹©
        for k, v in dqs_losses.items():
            loss_all += v
            loss_dict.update({k + "_dqs": v.item()})

        outputs = pred_dicts['outputs']
        dec_losses = self.compute_losses(outputs, targets, dn_meta)
        for k, v in dec_losses.items():
            loss_all += v
            loss_dict.update({k: v.item()})  # è¿™é‡ŒåŒ…å«äº†æœ€åä¸€å±‚çš„æ£€æµ‹ç»“æœæŸå¤±ï¼Œè¿˜æœ‰dnçš„å»å™ªæŸå¤±ï¼Œä»¥åŠè¾…åŠ©è¾“å‡ºçš„äº”å±‚çš„ç›¸åº”çš„æ£€æµ‹å’Œå»å™ªæŸå¤±

        # compute contrastive loss
        if dn_meta is not None:
            per_gt_num = [tgt["gt_boxes"].shape[0] for tgt in targets] # [n1, n2, ...]
            max_gt = max(per_gt_num)
            num_gts = sum(per_gt_num)
            if num_gts > 0:
                for li in range(self.model_cfg["num_decoder_layers"]): # 6å±‚decoder
                    contrastive_loss = 0.0
                    projs = torch.cat((outputs_class[li], outputs_coord[li]), dim=-1) # (B, 1000 + 4*max_gt_num, 1+7) æŸä¸€å±‚çš„è¾“å‡º
                    gt_projs = self.projector(projs[:, self.num_queries:].detach()) # gt çº¿æ€§å˜åŒ– # (B, 4*max_gt_num, 256) æ³¨æ„è¿™å››æ‰¹çš„gtå‰ä¸€æ‰¹æ˜¯çœŸgtï¼Œåé¢ä¸‰ä¸ªåˆ™æ˜¯å™ªå£°æ­£æ ·æœ¬ æ³¨æ„ï¼Œè¿™é‡Œdetachæ˜¯å› ä¸ºè¿™é‡Œä¸èƒ½æ¢¯åº¦å›ä¼ ï¼Œè¿™ä¸ªæ˜¯å°†å…¶æ˜ å°„åˆ°é«˜ç»´ç©ºé—´
                    pred_projs = self.predictor(self.projector(projs[:, : self.num_queries])) # (B, 1000, 256) queryéœ€è¦é¢å¤–çš„MLPï¼Œå‡ºè‡ªConQueRè®ºæ–‡ä¸­çš„è®¾è®¡
                    # num_gts x num_locs

                    pos_idxs = list(range(1, dn_meta["num_dn_group"] + 1)) # [1, 2, 3]
                    for bi, idx in enumerate(outputs["matched_indices"]): # è¿™ä¸ªæ˜¯[((n1,), (n1,)), ...]åŒ¹é…ç»“æœ
                        sim_matrix = (
                                self.similarity_f(
                                    gt_projs[bi].unsqueeze(1),
                                    pred_projs[bi].unsqueeze(0),
                                )
                                / self.tau
                        )# æ±‚å¾—ç›¸ä¼¼åº¦çŸ©é˜µ(4*max_gt_num, 1000)
                        matched_pairs = torch.stack(idx, dim=-1) # (n1, 2) ä»¥ç¬¬ä¸€ä¸ªæ ·æœ¬ä¸ºä¾‹ 
                        neg_mask = projs.new_ones(self.num_queries).bool() # ï¼ˆ1000ï¼Œï¼‰
                        neg_mask[matched_pairs[:, 0]] = False # æœ€ä½³åŒ¹é…çš„queryæ ‡è®°æˆFalse, æ¢è¨€ä¹‹ï¼Œæ²¡åŒ¹é…ä¸Šçš„éƒ½æ˜¯True HACK è¿™é‡Œæœ‰ä¸ªé—®é¢˜ï¼Œè´Ÿæ ·æœ¬ä¸åº”è¯¥æ˜¯999ä¸ªå—ï¼Œå®ƒè¿™æ ·ç›¸å½“äºè´Ÿæ ·æœ¬å˜å°‘äº†ï¼Œå³ä½¿åŒ¹é…ä¸Šäº†ï¼Œå½¼æ­¤ä¹‹é—´åº”è¯¥è¿˜æ˜¯è´Ÿæ ·æœ¬
                        for pair in matched_pairs: # éå†é…å¯¹åçš„æ¯ä¸€å¯¹
                            pos_mask = torch.tensor([int(pair[1] + max_gt * pi) for pi in pos_idxs],
                                                    device=sim_matrix.device) # è¿™ä¸ªæ˜¯ç”¨æ¥ç­›é€‰gtçš„ æ˜æ˜æ˜¯4*max_gt_numï¼Œä½†æ˜¯æ˜¯é€‰æ‹©äº†åé¢ä¸‰æ‰¹å¸¦å™ªå£°çš„gtï¼Œä¹Ÿå°±æ˜¯é€‰äº†ä¸‰ä¸ª(3, )
                            pos_pair = sim_matrix[pos_mask, pair[0]].view(-1, 1) # æ­£æ ·æœ¬ ï¼ˆ3ï¼Œ1ï¼‰
                            neg_pairs = sim_matrix[:, neg_mask][pos_mask] # è´Ÿæ ·æœ¬ï¼Œï¼ˆ3ï¼Œ1000-n1ï¼‰ XXX æ³¨æ„è¿™é‡Œæ˜¯ä¸æ˜¯æœ‰é—®é¢˜ï¼Œè¿™æ˜¯ä¸ºäº†ç®€åŒ–é€»è¾‘ï¼Ÿâ“
                            loss_gti = (
                                    torch.log(torch.exp(pos_pair) + torch.exp(neg_pairs).sum(dim=-1, keepdim=True))
                                    - pos_pair
                            ) # ï¼ˆ3ï¼Œ 1ï¼‰ 
                            contrastive_loss += loss_gti.mean() # 3ç»„gtå¯¹æ¯”ï¼Œæ±‚å‡å€¼å†åŠ ä¸Šå»
                    loss_contrastive_dec_li = self.contras_loss_coeff * contrastive_loss / num_gts # ä¹˜ä¸Šç³»æ•°=0.2åè¦é™¤ä»¥gtæ€»æ•°ï¼Œä»¥å‡è¡¡ä¸åŒæ ·æœ¬çš„gtæ•°ä¸åŒå¼•èµ·çš„æ•°å€¼æ³¢åŠ¨
                    loss_all += loss_contrastive_dec_li
                    loss_dict.update({'loss_contrastive_dec_' + str(li): loss_contrastive_dec_li.item()})

        pred_scores_mask = outputs['pred_scores_mask'] # (B, H, W)
        loss_score = self.compute_score_losses(pred_scores_mask, gt_bboxes_3d.to(torch.float32), gt_bboxes_3d_mask, None) # å‰æ™¯é¢„æµ‹æŸå¤±
        loss_all += loss_score
        loss_dict.update({'loss_score': loss_score.item()})

        return loss_all, loss_dict

    def encode_bbox(self, bboxes): # è¾“å…¥çš„æ˜¯n, 7
        z_normalizer = 10
        targets = torch.zeros([bboxes.shape[0], self.code_size]).to(bboxes.device) # n, 7 åŒæ—¶è¿™é‡Œæœ‰ä¸€ä¸ªéšå¼æ•°æ®ç±»å‹è½¬å˜å°†target ç±»å‹ä»torch.float64å˜æˆtorch.float32 å¦‚æœæ²¡æœ‰è¿™ä¸ªè¿‡ç¨‹ï¼Œä¼šæŠ¥å„ç§ç±»å‹é”™è¯¯
        targets[:, 0] = (bboxes[:, 0] - self.point_cloud_range[0]) / (
                self.point_cloud_range[3] - self.point_cloud_range[0])
        targets[:, 1] = (bboxes[:, 1] - self.point_cloud_range[1]) / (
                self.point_cloud_range[4] - self.point_cloud_range[1])
        targets[:, 2] = (bboxes[:, 2] + z_normalizer) / (2 * z_normalizer) # -10 åˆ° 10ä¹‹é—´
        targets[:, 3] = bboxes[:, 3] / (self.point_cloud_range[3] - self.point_cloud_range[0])
        targets[:, 4] = bboxes[:, 4] / (self.point_cloud_range[4] - self.point_cloud_range[1])
        targets[:, 5] = bboxes[:, 5] / (2 * z_normalizer)
        targets[:, 6] = (bboxes[:, 6] + np.pi) / (np.pi * 2)
        if self.code_size > 7:
            targets[:, 7] = (bboxes[:, 7]) / (self.point_cloud_range[3] - self.point_cloud_range[0])
            targets[:, 8] = (bboxes[:, 8]) / (self.point_cloud_range[4] - self.point_cloud_range[1])

        return targets

    def decode_bbox(self, pred_boxes):
        z_normalizer = 10
        pred_boxes[..., 0] = pred_boxes[..., 0] * (self.point_cloud_range[3] - self.point_cloud_range[0]) + \
                             self.point_cloud_range[0]
        pred_boxes[..., 1] = pred_boxes[..., 1] * (self.point_cloud_range[4] - self.point_cloud_range[1]) + \
                             self.point_cloud_range[1]
        pred_boxes[..., 2] = pred_boxes[..., 2] * 2 * z_normalizer + -1 * z_normalizer
        pred_boxes[..., 3] = pred_boxes[..., 3] * (self.point_cloud_range[3] - self.point_cloud_range[0])
        pred_boxes[..., 4] = pred_boxes[..., 4] * (self.point_cloud_range[4] - self.point_cloud_range[1])
        pred_boxes[..., 5] = pred_boxes[..., 5] * 2 * z_normalizer
        pred_boxes[..., -1] = pred_boxes[..., -1] * np.pi * 2 - np.pi
        if self.code_size > 7:
            pred_boxes[:, 7] = (pred_boxes[:, 7]) * (self.point_cloud_range[3] - self.point_cloud_range[0])
            pred_boxes[:, 8] = (pred_boxes[:, 8]) * (self.point_cloud_range[4] - self.point_cloud_range[1])
        return pred_boxes

    def _set_aux_loss(self, outputs_class, outputs_coord, outputs_iou):
        return [{"pred_logits": a, "pred_boxes": b, "pred_ious": c} for a, b, c in
                zip(outputs_class, outputs_coord, outputs_iou)]


class ClassificationLoss(nn.Module):
    def __init__(self, focal_alpha):
        super().__init__()
        self.focal_alpha = focal_alpha
        self.target_classes = None
        self.src_logits = None

    @staticmethod
    def sigmoid_focal_loss(
            logits,
            targets,
            alpha: float = -1,
            gamma: float = 2,
            reduction: str = "none",
    ):
        # è¾“å…¥çš„ä¸¤é¡¹å½¢çŠ¶éƒ½ä¸º (B, H*W, 1) æˆ–è€… detæŸå¤±æ—¶æ˜¯(B, 1000, 1) é¢„æµ‹ç»“æœ & one-hotç¼–ç 
        p = torch.sigmoid(logits)
        # print("p.shape is ", p.shape)
        # print("targets.shape is ", targets.shape)
        # print("targets is ", targets)
        # xxx
        ce_loss = F.binary_cross_entropy(p, targets, reduction="none") # äºŒå…ƒäº¤å‰ç†µ (B, H*W, 1) æˆ–è€… detæŸå¤±æ—¶æ˜¯(B, 1000, 1) 
        p_t = p * targets + (1 - p) * (1 - targets)
        loss = ce_loss * ((1 - p_t) ** gamma) # åŒ…å«è°ƒèŠ‚å› å­ï¼Œåˆæ­¥å½¢æˆfocal loss

        if alpha >= 0:
            alpha_t = alpha * targets + (1 - alpha) * (1 - targets) # æ­£æ ·æœ¬åˆ™è°ƒèŠ‚å› å­ä¸ºalphaï¼Œè´Ÿæ ·æœ¬åˆ™ä¸º1-alpha
            loss = alpha_t * loss # focal loss å®Œæˆï¼Œ (B, H*W, 1)

        if reduction == "mean":
            loss = loss.mean()
        elif reduction == "sum":
            loss = loss.sum() # æ±‚å’Œ å¸¸é‡

        return loss

    def forward(self, outputs, targets, indices, num_boxes):
        outputs["matched_indices"] = indices
        assert "pred_logits" in outputs
        src_logits = outputs["pred_logits"] # dqsæŸå¤±æ—¶æ˜¯ (B, H*W, 1) detæŸå¤±æ—¶ä¸º (B, 1000, 1) 
        target_classes_onehot = torch.zeros_like(src_logits) # (B, H*W, 1) detæŸå¤±æ—¶ä¸º (B, 1000, 1) 

        idx = _get_src_permutation_idx(indices) # è¿”å›ä¸¤ä¸ªç´¢å¼•é‡ï¼Œ[batchç´¢å¼•(n_all, )ï¼Œæœ€ä½³åŒ¹é…queryç´¢å¼•(n_all, )]
        target_classes_o = torch.cat([t["labels"][J] for t, (_, J) in zip(targets, indices)]) # ç´¢å¼•åˆ°æœ€ä½³åŒ¹é…çš„gt label (n_all, )
        # print("indices is ", indices)
        # print("t['labels'] is ", targets[0]['labels'])
        # print("target_classes_o is ", target_classes_o)

        # for metrics calculation
        self.target_classes = target_classes_o

        if "topk_indexes" in outputs.keys(): # è¿™æ˜¯dqsåšæŸå¤±è¦çš„ï¼Œdqsä¹Ÿå’Œæœ€ä½³åŒ¹é…çš„åšæŸå¤±ï¼Œè¦æ±‚æœ€ä½³åŒ¹é…çš„queryçš„ç½®ä¿¡åº¦æ¥è¿‘1
            topk_indexes = outputs["topk_indexes"] # (B, 1000, 1) dqsç»“æœç´¢å¼•
            self.src_logits = torch.gather(src_logits, 1, topk_indexes.expand(-1, -1, src_logits.shape[-1]))[idx] # (B, 1000, 1)
            target_classes_onehot[idx[0], topk_indexes[idx].squeeze(-1), target_classes_o] = 1 # ç´¢å¼•åˆ°å¯¹åº”çš„ä½ç½® æ ¹æ®ä¸åŒçš„ç±»åˆ«ï¼Œç´¢å¼•åä¸º1ï¼Œå½¢æˆäº†one-hotç¼–ç 
            # print('sum target is ', target_classes_onehot.sum())
        else:
            self.src_logits = src_logits[idx]
            # 0 for bg, 1 for fg
            # N, L, C
            target_classes_onehot[idx[0], idx[1], target_classes_o] = 1

        loss_ce = (
                self.sigmoid_focal_loss(
                    src_logits, # é¢„æµ‹ï¼ŒdqsæŸå¤±æ—¶æ˜¯ (B, H*W, 1) detæŸå¤±æ—¶ä¸º (B, 1000, 1) 
                    target_classes_onehot, # dqsæŸå¤±æ—¶æ˜¯ (B, H*W, 1) detæŸå¤±æ—¶ä¸º (B, 1000, 1) åŒ¹é…ä¸Šçš„query
                    alpha=self.focal_alpha, # 0.25
                    gamma=2.0,
                    reduction="sum"
                )
                / num_boxes
        ) # focal loss å–meanç»“æœ

        losses = {
            "loss_ce": loss_ce,
        }

        return losses


class RegressionLoss(nn.Module):
    def __init__(self, decode_func=None):
        super().__init__()
        self.decode_func = decode_func

    def forward(self, outputs, targets, indices, num_boxes):
        assert "pred_boxes" in outputs
        ''''
        outputs: Dict, DQSç»“æœæˆ–è€…æ˜¯æ¨¡å‹è¾“å‡ºçš„ç»“æœ
        targets: List [Dict{}, Dict{}...] batchä¸­æŒ‰æ ·æœ¬åˆ†ç»“æœ
        indices: List [((n,), (n,)), ...] æœ€å°æˆæœ¬åŒ¹é…ç´¢å¼• æˆ–è€…æ˜¯ å»å™ªgtæ ·æœ¬ç´¢å¼•
        num_boxes: batchä¸­æ‰€æœ‰gtæ•°æ€»å’Œ
        '''
        idx = _get_src_permutation_idx(indices) # è¿”å›ä¸¤ä¸ªç´¢å¼•é‡ï¼Œ[batchç´¢å¼•(n_all, )ï¼Œæœ€ä½³åŒ¹é…queryç´¢å¼•(n_all, )] å…¶ä¸­ç¬¬äºŒä¸ªä¹Ÿå¯èƒ½æ˜¯å»å™ªæ­£æ ·æœ¬ï¼ˆ3*(n1-1) +  3*(n2-1), ....), ï¼‰

        if "topk_indexes" in outputs.keys():
            pred_boxes = torch.gather(
                outputs["pred_boxes"],
                1,
                outputs["topk_indexes"].expand(-1, -1, outputs["pred_boxes"].shape[-1]),
            ) # ï¼ˆB, 1000, 7ï¼‰
            pred_ious = torch.gather(
                outputs["pred_ious"],
                1,
                outputs["topk_indexes"].expand(-1, -1, outputs["pred_ious"].shape[-1]),
            ) # ï¼ˆB, 1000, 1ï¼‰

        else:
            pred_boxes = outputs["pred_boxes"] # ï¼ˆB, 1000, 7ï¼‰å¦‚æœæ˜¯å»å™ªgt ï¼ˆB, pad_size, 7ï¼‰
            pred_ious = outputs["pred_ious"] # ï¼ˆB, 1000, 1ï¼‰

        target_boxes = torch.cat([t["gt_boxes"][i] for t, (_, i) in zip(targets, indices)], dim=0) # ç´¢å¼•åˆ°æœ€ä½³åŒ¹é…çš„gt (n1+n2+..., 7) ä¹Ÿå¯èƒ½æ˜¯å»å™ªæ­£æ ·æœ¬ï¼ˆ3*(n1-1) +  3*(n2-1), ....), ï¼‰

        src_boxes, src_rads = pred_boxes[idx].split(6, dim=-1) # (n_all, 6), (n_all, 1)
        target_boxes, target_rads = target_boxes.split(6, dim=-1)

        loss_bbox = F.l1_loss(src_boxes, target_boxes, reduction="none")
        loss_rad = F.l1_loss(src_rads, target_rads, reduction="none")

        gt_iou = torch.diag(
            generalized_box3d_iou(
                box_cxcyczlwh_to_xyxyxy(src_boxes), # æœ€ä½³åŒ¹é…çš„query
                box_cxcyczlwh_to_xyxyxy(target_boxes), # æœ€ä½³åŒ¹é…çš„gt
            )
        ) # è¿”å›ä¸€ä¸ªä¸€ç»´å¼ é‡ (n_all, )å³æœ€ä½³åŒ¹é…ä¹‹é—´çš„giou

        loss_giou = 1 - gt_iou

        losses = {
            "loss_bbox": loss_bbox.sum() / num_boxes,
            "loss_giou": loss_giou.sum() / num_boxes,
            "loss_rad": loss_rad.sum() / num_boxes,
        }

        pred_ious = pred_ious[idx] # ï¼ˆn_all, 1ï¼‰
        box_preds = self.decode_func(torch.cat([src_boxes, src_rads], dim=-1)) # åå½’ä¸€åŒ–
        box_target = self.decode_func(torch.cat([target_boxes, target_rads], dim=-1))
        iou_target = iou3d_nms_utils.paired_boxes_iou3d_gpu(box_preds, box_target) # (n_all, ) iou
        iou_target = iou_target * 2 - 1 # (0, 1) map åˆ° (-1, 1)
        iou_target = iou_target.detach()
        loss_iou = F.l1_loss(pred_ious, iou_target.unsqueeze(-1), reduction="none")
        losses.update({"loss_iou": loss_iou.sum() / num_boxes})

        return losses


class Det3DLoss(nn.Module):
    def __init__(self, matcher, weight_dict, losses, decode_func, aux_loss=True):
        super().__init__()

        self.matcher = matcher # åŒˆç‰™åˆ©åŒ¹é…æŸå¤±
        self.weight_dict = weight_dict # æŸå¤±æƒé‡
        self.losses = losses # ["focal_labels", "boxes"]

        self.aux_loss = aux_loss

        self.det3d_losses = nn.ModuleDict()
        for loss in losses:
            if loss == "boxes":
                self.det3d_losses[loss] = RegressionLoss(decode_func=decode_func)
            elif loss == "focal_labels":
                self.det3d_losses[loss] = ClassificationLoss(0.25) # alpha=0.25
            else:
                raise ValueError(f"Only boxes|focal_labels are supported for det3d losses. Found {loss}")

    @staticmethod
    def get_world_size() -> int: # è·å–åˆ†å¸ƒå¼è®­ç»ƒæ—¶çš„è¿›ç¨‹æ€»æ•°
        if not dist.is_available():
            return 1
        if not dist.is_initialized():
            return 1
        return dist.get_world_size()

    def get_target_classes(self):
        for k in self.det3d_losses.keys():
            if "labels" in k:
                return self.det3d_losses[k].src_logits, self.det3d_losses[k].target_classes

    def prep_for_dn(self, dn_meta):
        output_known_lbs_bboxes = dn_meta["output_known_lbs_bboxes"] # Dict å­˜çš„GTå™ªå£°ç»„åœ¨æœ€åä¸€å±‚çš„é¢„æµ‹ç»“æœï¼ŒåŒæ—¶è¿˜æœ‰å‰äº”å±‚çš„ç»“æœ
        num_dn_groups, pad_size = dn_meta["num_dn_group"], dn_meta["pad_size"] # 3ï¼Œ 2 * max_gt_num * 3
        assert pad_size % num_dn_groups == 0
        single_pad = pad_size // num_dn_groups # 2 * max_gt_num

        return output_known_lbs_bboxes, single_pad, num_dn_groups

    def forward(self, outputs, targets, dn_meta=None):
        '''
        outputs: Dict, DQSç»“æœæˆ–è€…æ˜¯æ¨¡å‹è¾“å‡ºçš„ç»“æœ
        targets: List [Dict{}, Dict{}...] batchä¸­æŒ‰æ ·æœ¬åˆ†ç»“æœ
        '''
        # Compute the average number of target boxes accross all nodes, for normalization purposes
        num_boxes = sum([len(t["labels"]) for t in targets]) # æ‰€æœ‰æ ·æœ¬ä¸­çš„GT objectä¸ªæ•°
        num_boxes = torch.as_tensor([num_boxes], dtype=torch.float, device=next(iter(outputs.values())).device) # è½¬å¼ é‡ åˆ‡æ¢è®¾å¤‡
        if self.get_world_size() > 1:
            torch.distributed.all_reduce(num_boxes) # ä¼šå°†æ‰€æœ‰åˆ†å¸ƒç»“æœèšåˆï¼Œç„¶ååŒæ­¥
        num_boxes = torch.clamp(num_boxes / self.get_world_size(), min=1).item()

        losses = {}

        if dn_meta is not None: # å»å™ªæŸå¤±
            # prepare for computing denosing loss
            output_known_lbs_bboxes, single_pad, scalar = self.prep_for_dn(dn_meta) # Dictå­˜æ”¾æ¯ä¸€å±‚è¾“å‡ºç»“æœï¼Œ2 * max_gt_num æ¯ç»„çš„gtæ•°ï¼Œ 3 ä¹Ÿå³ç»„æ•°
            dn_pos_idx = []
            dn_neg_idx = []
            for i in range(len(targets)): # batchéå†æ ·æœ¬
                if len(targets[i]["labels"]) > 0: # è¿™ä¸ªæ ·æœ¬æœ‰æ ‡ç­¾
                    t = torch.arange(0, len(targets[i]["labels"]) - 1).long().cuda() # ï¼ˆn-1ï¼Œ ï¼‰ BUG 0åˆ°n-2 ï¼Ÿ ä¸ºä»€ä¹ˆä¸æ˜¯0 åˆ° n-1??? é‚£ä¸æ˜¯æœ€åæœ‰ä¸€ä¸ªå»å™ªä¸¢äº†ï¼Ÿä¸è§£ğŸ¤”
                    t = t.unsqueeze(0).repeat(scalar, 1) # (3, n-1) è¿™ä¸ªå…¶å®å°±æ˜¯æ¯ä¸€ç»„å†…éƒ¨çš„ç´¢å¼•
                    tgt_idx = t.flatten() # ï¼ˆ3*(n-1), ï¼‰
                    output_idx = (torch.tensor(range(scalar)) * single_pad).long().cuda().unsqueeze(1) + t # æ¯ä¸€ç»„çš„èµ·å§‹ç´¢å¼•ï¼ŒåŠ ä¸Šå†…éƒ¨ç´¢å¼•ï¼Œå¾—åˆ°äº†ä¸‰ç»„ä¸­æœ‰æ•ˆgtçš„épadçš„éƒ¨åˆ†çš„ç´¢å¼• ï¼ˆ3ï¼Œn-1ï¼‰
                    output_idx = output_idx.flatten() #ï¼ˆ3*(n-1), ï¼‰
                else:
                    output_idx = tgt_idx = torch.tensor([]).long().cuda()

                dn_pos_idx.append((output_idx, tgt_idx)) # æ¯ä¸€ç»„åˆ†æ­£è´Ÿæ ·æœ¬ï¼Œæ­£æ ·æœ¬gtçš„ç´¢å¼• åˆ†ä¸ºä¸¤ä¸ªè½´ï¼Œä¸€ä¸ªè¡¨å¾é¢„æµ‹ä¸­çš„å¯¹åº”çš„ç´¢å¼•ï¼Œå¦ä¸€ä¸ªåˆ™æ˜¯çœŸå€¼gtä¸­çš„ç´¢å¼•
                dn_neg_idx.append((output_idx + single_pad // 2, tgt_idx)) # å‘ååç§»

            l_dict = {}
            for loss in self.losses:
                l_dict.update(
                    self.det3d_losses[loss](
                        output_known_lbs_bboxes, # Dictå­˜æ”¾æ¯ä¸€å±‚è¾“å‡ºç»“æœï¼Œä½†è¿™é‡Œåº”è¯¥åªèƒ½ç”¨åˆ°æœ€åä¸€å±‚ï¼Œè¾…åŠ©è¾“å‡ºä¼šåœ¨åé¢å¦è¡Œå¤„ç†
                        targets, # Dict å­˜å‚¨gt
                        dn_pos_idx,
                        num_boxes * scalar,
                    )
                )
            l_dict = {k + "_dn": v for k, v in l_dict.items()}
            losses.update(l_dict)

        # In case of auxiliary losses, we repeat this process with the output of each intermediate layer.
        if self.aux_loss and "aux_outputs" in outputs:
            # print('outputs["aux_outputs"]', outputs["aux_outputs"])
            for i, aux_outputs in enumerate(outputs["aux_outputs"]): # å¾ªç¯5æ¬¡ï¼Œè¡¨ç¤ºå‰äº”å±‚çš„è¾“å‡º
                indices = self.matcher(aux_outputs, targets) # åšåŒˆç‰™åˆ©åŒ¹é…ï¼Œå¾—åˆ°åŒ¹é…ç»“æœ
                for loss in self.losses:
                    l_dict = self.det3d_losses[loss](aux_outputs, targets, indices, num_boxes)
                    l_dict = {k + f"_{i}": v for k, v in l_dict.items()}
                    losses.update(l_dict)

                if dn_meta is not None:
                    aux_outputs_known = output_known_lbs_bboxes["aux_outputs"][i]
                    l_dict = {}
                    for loss in self.losses:
                        l_dict.update(
                            self.det3d_losses[loss](
                                aux_outputs_known,
                                targets,
                                dn_pos_idx,
                                num_boxes * scalar,
                            )
                        )

                    l_dict = {k + f"_dn_{i}": v for k, v in l_dict.items()}
                    losses.update(l_dict)

        # Retrieve the matching between the outputs of the last layer and the targets
        indices = self.matcher(outputs, targets) # List[((n1),(n1)), ...] åŒ¹é…ç»“æœç´¢å¼•ï¼Œæ³¨æ„ï¼Œè¿™æ˜¯1000ä¸ªqueryä¸gtçš„åŒ¹é…
        for loss in self.losses: # ["focal_labels", "boxes"]
            losses.update(self.det3d_losses[loss](outputs, targets, indices, num_boxes))

        return losses


def _get_src_permutation_idx(indices):
    ''''
    indices: List [((n,), (n,)), ...] æœ€å°æˆæœ¬åŒ¹é…ç´¢å¼• 
    '''
    # permute predictions following indices
    batch_idx = torch.cat([torch.full_like(src, i) for i, (src, _) in enumerate(indices)]) # æ ‡è®°å¥½batch id (n1+n2+...) å½¢çŠ¶ä¸ºbatchä¸­æ‰€æœ‰çš„gtä¸ªæ•°
    src_idx = torch.cat([src for (src, _) in indices]) # (n1+n2+...)  æ‰€æœ‰çš„gtçš„é€‰æ‹©çš„å¯¹åº”çš„æœ€ä½³åŒ¹é…queryçš„id æˆ–è€… å¦‚æœæ˜¯dnéƒ¨åˆ†ç´¢å¼•ï¼Œåˆ™è¿™é‡Œä¸ºï¼ˆ3*(n1-1) +  3*(n2-1), ....), ï¼‰ä¹Ÿå°±æ˜¯ä¸‰ç»„gtå™ªå£°ä¸­çš„æ­£æ ·æœ¬ç´¢å¼•
    return batch_idx, src_idx


def _get_tgt_permutation_idx(indices):
    # permute targets following indices
    batch_idx = torch.cat([torch.full_like(tgt, i) for i, (_, tgt) in enumerate(indices)])
    tgt_idx = torch.cat([tgt for (_, tgt) in indices])
    return batch_idx, tgt_idx
